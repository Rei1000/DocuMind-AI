"""
KI-QMS FastAPI Main Application

Enterprise-grade Quality Management System (QMS) API for medical device companies.
Provides comprehensive RESTful endpoints for ISO 13485, EU MDR, and FDA 21 CFR Part 820 compliance.
"""

import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

"""
This module serves as the central FastAPI application, orchestrating all QMS operations
through a robust, scalable, and secure API architecture designed for production environments.

API Architecture:
    ‚Ä¢ RESTful design following OpenAPI 3.0.3 specification
    ‚Ä¢ Automatic Swagger UI and ReDoc documentation generation
    ‚Ä¢ Comprehensive error handling with standardized HTTP status codes
    ‚Ä¢ Request/response validation using Pydantic v2 schemas
    ‚Ä¢ Async-first architecture for high-performance operations

Core Business Domains:
    1. Interest Groups Management (13 stakeholder-oriented groups)
    2. User Management & Authentication (JWT-based RBAC)
    3. Document Management (25+ QMS-specific document types)
    4. Standards & Compliance (ISO 13485, MDR, FDA CFR Part 820)
    5. Equipment & Calibration Management (ISO 17025 compliant)
    6. Full-text Search & AI-powered Text Extraction
    7. Workflow Engine for automated QM processes

Security Features:
    ‚Ä¢ OAuth2 with JWT Bearer token authentication
    ‚Ä¢ Role-based access control (RBAC) with granular permissions
    ‚Ä¢ Password hashing using bcrypt with configurable rounds
    ‚Ä¢ CORS middleware for secure cross-origin requests
    ‚Ä¢ File upload validation with MIME type checking
    ‚Ä¢ SQL injection protection via SQLAlchemy ORM

Performance & Scalability:
    ‚Ä¢ Async I/O operations for file handling and database access
    ‚Ä¢ Connection pooling and query optimization
    ‚Ä¢ Pagination support for large data sets
    ‚Ä¢ Background task processing for resource-intensive operations
    ‚Ä¢ Caching strategies for frequently accessed data

Data Validation & Type Safety:
    ‚Ä¢ Comprehensive Pydantic v2 schemas with field validators
    ‚Ä¢ Type hints throughout the codebase for IDE support
    ‚Ä¢ Custom validators for business rule enforcement
    ‚Ä¢ Automatic request/response serialization and deserialization

File Management:
    ‚Ä¢ Secure file upload with size and type validation (max 50MB)
    ‚Ä¢ Intelligent text extraction from PDF, DOC, DOCX, TXT, MD, XLS, XLSX
    ‚Ä¢ Automated keyword extraction for search optimization
    ‚Ä¢ SHA-256 integrity checking and duplicate detection
    ‚Ä¢ Organized storage structure by document type

Compliance Implementation:
    ‚Ä¢ ISO 13485:2016 document control workflows
    ‚Ä¢ EU MDR 2017/745 technical documentation requirements
    ‚Ä¢ FDA 21 CFR Part 820 quality system regulations
    ‚Ä¢ Complete audit trails for all operations
    ‚Ä¢ Automated calibration schedule management per ISO 17025

Technology Stack:
    Backend Framework: FastAPI 0.110+ (Python 3.12+)
    ORM: SQLAlchemy 2.0+ with async support
    Database: SQLite (development), PostgreSQL (production)
    Validation: Pydantic v2 with custom validators
    Authentication: python-jose for JWT, passlib for password hashing
    File I/O: aiofiles for async file operations
    Documentation: Automatic OpenAPI schema generation

Development Standards:
    ‚Ä¢ Google-style docstrings for all public functions
    ‚Ä¢ Type hints for all function signatures
    ‚Ä¢ Comprehensive error handling with custom exceptions
    ‚Ä¢ Unit tests with pytest and async test clients
    ‚Ä¢ Code formatting with Black and linting with Ruff
    ‚Ä¢ Pre-commit hooks for code quality enforcement

API Endpoint Categories:
    /health                     - System health and monitoring
    /api/auth/*                 - Authentication and authorization
    /api/users/*                - User management and profiles
    /api/interest-groups/*      - Stakeholder group management
    /api/documents/*            - Document lifecycle management
    /api/equipment/*            - Equipment and asset management
    /api/calibrations/*         - Calibration scheduling and tracking
    /api/norms/*                - Standards and compliance management

Error Handling:
    Standardized error responses with detailed messages, error codes,
    and contextual information for debugging and user feedback.

Example Usage:
    >>> import requests
    >>> # Login and get token
    >>> response = requests.post('/api/auth/login', 
    ...                         json={'email': 'user@company.com', 'password': 'secure123'})
    >>> token = response.json()['access_token']
    >>> # Use API with token
    >>> headers = {'Authorization': f'Bearer {token}'}
    >>> documents = requests.get('/api/documents', headers=headers).json()

Authors: KI-QMS Development Team
Version: 2.0.0 (Production Ready)
Created: December 2024
License: MIT License
Last Updated: 2024-12-20
"""

from fastapi import FastAPI, Depends, HTTPException, status, UploadFile, File, Form, Request, Query
from .config import get_uploads_dir, get_prompts_dir, get_available_providers, get_default_provider, get_provider_fallback_chain, get_quality_threshold, get_prompt_filename
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv
import os
import hashlib
import aiofiles
import base64
import json
import tempfile
from pathlib import Path
import mimetypes
from datetime import datetime, timedelta
import time
import shutil
from fastapi.responses import JSONResponse
import logging

# Enhanced Logging Setup f√ºr besseres Debugging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] [%(name)s] %(message)s',
    handlers=[
        logging.FileHandler('../logs/backend.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("KI-QMS")

# Separate Logger f√ºr verschiedene Bereiche
upload_logger = logging.getLogger("KI-QMS.Upload")
rag_logger = logging.getLogger("KI-QMS.RAG")
ai_logger = logging.getLogger("KI-QMS.AI")
frontend_logger = logging.getLogger("KI-QMS.Frontend")

upload_logger.setLevel(logging.DEBUG)
rag_logger.setLevel(logging.DEBUG)
ai_logger.setLevel(logging.DEBUG)
frontend_logger.setLevel(logging.DEBUG)

# Lade Environment Variables aus .env Datei
import pathlib
# Suche .env Datei im KI-QMS Root-Verzeichnis des Projekts
root_path = pathlib.Path(__file__).parent.parent.parent  # backend/app -> backend -> KI-QMS
env_path = root_path / ".env"
load_dotenv(dotenv_path=env_path, override=True, verbose=True)

from .database import get_db, create_tables
from .models import (
    InterestGroup as InterestGroupModel, 
    User as UserModel, 
    UserGroupMembership as UserGroupMembershipModel,
    Document as DocumentModel,
    Norm as NormModel,
    Equipment as EquipmentModel,
    Calibration as CalibrationModel,
    DocumentType,
    DocumentStatus
)
from .schemas import (
    InterestGroup, InterestGroupCreate, InterestGroupUpdate,
    User, UserCreate, UserUpdate,
    UserGroupMembership, UserGroupMembershipCreate,
    Document, DocumentCreate, DocumentUpdate,
    DocumentStatusChange, DocumentStatusHistory, NotificationInfo,
    Norm, NormCreate, NormUpdate,
    Equipment, EquipmentCreate, EquipmentUpdate,
    Calibration, CalibrationCreate, CalibrationUpdate,
    FileUploadResponse, DocumentWithFileCreate,
    GenericResponse,
    PasswordChangeRequest, AdminPasswordResetRequest, 
    UserProfileResponse, PasswordResetResponse
)
from .text_extraction import extract_text_from_file, extract_keywords
from .auth import (
    authenticate_user, create_access_token, get_current_active_user,
    get_user_permissions, get_user_groups as auth_get_user_groups, get_password_hash,
    Token, LoginRequest, UserInfo,
    require_qms_admin, require_system_admin, require_admin_or_qm,
    is_qms_admin, is_system_admin
)
from .workflow_engine import get_workflow_engine, WorkflowTask
from .ai_engine import ai_engine
from .vision_ocr_engine import VisionOCREngine
# RAG Engine mit Qdrant (Enterprise Grade mit Advanced AI)
try:
    # UPGRADE zu Advanced RAG System
    from .advanced_rag_engine import (
        advanced_rag_engine as qdrant_rag_engine,
        index_document_advanced as index_all_documents_old,
        search_documents_advanced,
        get_advanced_stats
    )
    # Fallback zu altem System f√ºr Kompatibilit√§t
    from .qdrant_rag_engine import search_documents_semantic
    RAG_AVAILABLE = True
    print("‚úÖ Advanced RAG Engine (Enterprise Grade) erfolgreich geladen")
    print("üöÄ Features: Hierarchical Chunking, LangChain, Enhanced Metadata")
except Exception as e:
    print(f"‚ö†Ô∏è  Advanced RAG Engine nicht verf√ºgbar: {str(e)}")
    print("üìÑ Fallback zu Basic Qdrant Engine...")
    try:
        from .qdrant_rag_engine import qdrant_rag_engine, index_all_documents, search_documents_semantic
        RAG_AVAILABLE = True
        print("‚úÖ Basic Qdrant RAG Engine geladen (Fallback)")
    except Exception as e2:
        print(f"‚ö†Ô∏è  Alle RAG Engines fehlgeschlagen: {str(e2)}")
        RAG_AVAILABLE = False

# AI-Enhanced Features
try:
    from .ai_metadata_extractor import extract_document_metadata
    from .ai_endpoints import extract_metadata_endpoint, upload_document_with_ai, chat_with_documents_endpoint, get_rag_stats
    AI_FEATURES_AVAILABLE = True
    print("‚úÖ AI-Enhanced Features erfolgreich geladen")
except Exception as e:
    print(f"‚ö†Ô∏è  AI-Enhanced Features nicht verf√ºgbar: {str(e)}")
    AI_FEATURES_AVAILABLE = False

# Enhanced AI Features (Enterprise Grade v3.1.0)
try:
    from .enhanced_metadata_extractor import (
        extract_enhanced_metadata,
        get_enhanced_extractor,
        validate_enhanced_metadata
    )
    from .schemas_enhanced import (
        EnhancedDocumentMetadata,
        EnhancedMetadataResponse,
        normalize_document_type
    )
    from .json_parser import EnhancedJSONParser
    from .rag_prompts import get_prompt_config
    ENHANCED_AI_AVAILABLE = True
    print("‚úÖ Enhanced AI System (Enterprise Grade v3.1.0) geladen")
    print("üéØ Features: Enhanced Schemas, JSON Parser, Temperature=0 Prompts")
except Exception as e:
    print(f"‚ö†Ô∏è Enhanced AI System nicht verf√ºgbar: {e}")
    ENHANCED_AI_AVAILABLE = False

# Advanced AI Features (Enterprise Grade 2024)
try:
    from .advanced_rag_engine import (
        advanced_rag_engine, 
        index_document_advanced, 
        search_documents_advanced, 
        get_advanced_stats
    )
    from .advanced_ai_endpoints import advanced_ai_router
    ADVANCED_AI_AVAILABLE = True
    print("‚úÖ Advanced AI System (Enterprise Grade) geladen")
    print("üöÄ Features: Hierarchical Chunking, Multi-Layer Analysis, Query Enhancement")
    if ENHANCED_AI_AVAILABLE:
        print("üéØ Enhanced Integration: Advanced RAG + Enhanced Metadata")
except Exception as e:
    print(f"‚ö†Ô∏è Advanced AI System nicht verf√ºgbar: {e}")
    ADVANCED_AI_AVAILABLE = False
    
    # Mock-Funktionen f√ºr fehlende RAG Engine
    class MockRAGEngine:
        def __init__(self):
            self.collection = None
        
        def search_documents(self, query, max_results=5):
            return {"error": "RAG Engine nicht verf√ºgbar", "results": []}
        
        def index_document(self, *args, **kwargs):
            return {"error": "RAG Engine nicht verf√ºgbar", "status": "skipped"}
        
        def chat_with_documents(self, query, *args, **kwargs):
            return {"error": "RAG Engine nicht verf√ºgbar", "message": "Bitte verwenden Sie die normale AI-Analyse"}
        
        async def get_system_stats(self):
            return {
                "status": "unavailable", 
                "reason": "ChromaDB/NumPy Kompatibilit√§tsproblem",
                "documents_indexed": 0,
                "embeddings_model": "nicht verf√ºgbar",
                "vector_database": "nicht verf√ºgbar", 
                "last_indexing": "nie",
                "available_features": [],
                "fix_instructions": "Dependency-Konflikt l√∂sen oder alternatives RAG System verwenden"
            }
    
    rag_engine = MockRAGEngine()
    
    def index_all_documents(*args, **kwargs):
        return {"error": "RAG Engine nicht verf√ºgbar", "indexed": 0}

from .intelligent_workflow import intelligent_workflow_engine
INTELLIGENT_WORKFLOW_AVAILABLE = True

# ===== DATEI-UPLOAD KONFIGURATION =====
UPLOAD_DIR = Path("uploads")  # Relativer Pfad vom backend/ Verzeichnis aus
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

# Maximale Dateigr√∂√üe: 50MB
MAX_FILE_SIZE = 50 * 1024 * 1024

# Erlaubte MIME-Types f√ºr QMS-Dokumente
ALLOWED_MIME_TYPES = {
    "application/pdf",                    # PDF-Dokumente
    "application/msword",                 # DOC (Legacy Word)
    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",  # DOCX
    "text/plain",                         # TXT-Dateien
    "text/markdown",                      # MD-Dateien
    "application/vnd.ms-excel",           # XLS (Legacy Excel)
    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",  # XLSX
    "application/octet-stream",           # Fallback f√ºr DOCX/PDF (wird von manchen Systemen verwendet)
    "image/png",                          # PNG-Bilder (f√ºr Multi-Visio)
    "image/jpeg",                         # JPEG-Bilder
    "image/jpg",                          # JPG-Bilder
    "image/gif",                          # GIF-Bilder
    "image/bmp",                          # BMP-Bilder
    "image/tiff",                         # TIFF-Bilder
    "image/webp"                          # WebP-Bilder
}

# ===== HILFSFUNKTIONEN F√úR DATEI-VERARBEITUNG =====

async def save_uploaded_file(file: UploadFile, document_type: str, upload_method: str = "ocr") -> FileUploadResponse:
    """
    Speichert eine hochgeladene Datei mit Validierung und Metadaten-Extraktion.
    
    F√ºhrt umfassende Validierung durch und speichert die Datei in einer
    organisierten Verzeichnisstruktur nach Dokumenttyp. Generiert
    eindeutige Dateinamen und berechnet Checksummen f√ºr Integrit√§t.
    
    Args:
        file (UploadFile): FastAPI UploadFile object mit Datei-Content
        document_type (str): QMS-Dokumenttyp f√ºr Ordnerorganisation
        
    Returns:
        FileUploadResponse: Vollst√§ndige Datei-Metadaten inklusive:
            - file_path: Relativer Pfad zur gespeicherten Datei
            - file_name: Original-Dateiname
            - file_size: Dateigr√∂√üe in Bytes
            - file_hash: SHA-256 Checksum f√ºr Integrit√§t
            - mime_type: MIME-Type der Datei
            - uploaded_at: Zeitpunkt des Uploads
        
    Raises:
        HTTPException: 
            - 400: Ung√ºltiger Dateiname oder MIME-Type
            - 413: Datei zu gro√ü (> 50MB)
            - 500: Speicher-Fehler
            
    Validierungen:
        - Dateiname vorhanden und nicht leer
        - MIME-Type in ALLOWED_MIME_TYPES
        - Dateigr√∂√üe unter MAX_FILE_SIZE
        - Erfolgreiche Speicherung im Dateisystem
        
    Sicherheitsfeatures:
        - Eindeutige Dateinamen (Timestamp + Hash) gegen Kollisionen
        - SHA-256 Hash f√ºr Integrit√§t-Pr√ºfung
        - Ordnerstruktur nach Dokumenttyp f√ºr Organisation
        - Async I/O f√ºr bessere Performance
        
    File Organization:
        uploads/
        ‚îú‚îÄ‚îÄ QM_MANUAL/
        ‚îú‚îÄ‚îÄ SOP/
        ‚îú‚îÄ‚îÄ WORK_INSTRUCTION/
        ‚îî‚îÄ‚îÄ ...
    """
    # Validierungen
    if not file.filename:
        raise HTTPException(status_code=400, detail="Dateiname fehlt")
    
    # MIME-Type pr√ºfen
    mime_type = file.content_type
    if mime_type not in ALLOWED_MIME_TYPES:
        raise HTTPException(
            status_code=400, 
            detail=f"Dateityp nicht erlaubt: {mime_type}. Erlaubt: PDF, DOC, DOCX, TXT, MD, XLS, XLSX"
        )
    
    # Datei-Content lesen
    content = await file.read()
    file_size = len(content)
    
    # Gr√∂√üe pr√ºfen
    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"Datei zu gro√ü: {file_size} Bytes. Maximum: {MAX_FILE_SIZE} Bytes"
        )
    
    # Hash berechnen f√ºr Integrit√§t
    file_hash = hashlib.sha256(content).hexdigest()
    
    # Eindeutigen Dateinamen generieren
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_filename = f"{timestamp}_{file_hash[:8]}_{file.filename}"
    
    # Ordnerstruktur nach Dokumenttyp
    type_dir = UPLOAD_DIR / document_type
    type_dir.mkdir(exist_ok=True)
    
    file_path = type_dir / safe_filename
    
    # Datei speichern
    async with aiofiles.open(file_path, 'wb') as f:
        await f.write(content)
    
    # Relative Pfad f√ºr Datenbank (fix f√ºr das --reload Problem)
    relative_path = str(file_path)
    
    return FileUploadResponse(
        file_path=relative_path,
        file_name=file.filename,
        file_size=file_size,
        file_hash=file_hash,
        mime_type=mime_type,
        uploaded_at=datetime.utcnow()
    )
def extract_smart_title_and_description(text: str, filename: str) -> tuple[str, str]:
    """
    Extrahiert intelligenten Titel und Beschreibung aus Dokumenttext mit KI-Logik.
    
    Verwendet Pattern-Matching und Heuristiken um aussagekr√§ftige Titel
    und Beschreibungen aus Dokumentinhalten zu extrahieren. Besonders
    optimiert f√ºr QMS-Dokumente, Normen und technische Dokumentation.
    
    Pattern-Erkennung:
    - ISO/IEC/DIN/EN Normen-Nummern mit Versionserkennung
    - Medizinprodukte-spezifische Begriffe und Standards
    - QMS-Dokumenttypen (SOP, Arbeitsanweisungen, etc.)
    - Titel-Strukturen in technischen Dokumenten
    - Mehrsprachige Unterst√ºtzung (DE/EN)
    
    Args:
        text (str): Extrahierter Dokumenttext (erste 3000 Zeichen f√ºr Performance)
        filename (str): Original-Dateiname als Fallback-Titel
        
    Returns:
        tuple[str, str]: (extracted_title, extracted_description)
            - title: Erkannter oder generierter Titel (max 200 Zeichen)
            - description: Intelligente Beschreibung oder Fallback
            
    Heuristiken:
        1. Normen-Pattern: ISO 13485:2016, IEC 62304, DIN EN ISO 14971
        2. Titel-Erkennung: Erste signifikante Zeile ohne Metadaten
        3. Beschreibung: Erster Absatz oder extrahierte Zusammenfassung
        4. Fallback: Bereinigter Dateiname wenn keine Pattern erkannt
        
    Performance:
        - Nur erste 3000 Zeichen analysiert f√ºr Geschwindigkeit
        - Optimierte Regex-Pattern f√ºr h√§ufige Formate
        - Caching f√ºr wiederverwendbare Pattern
        
    Examples:
        >>> extract_smart_title_and_description(
        ...     "ISO 13485:2016 Medical devices - Quality management systems",
        ...     "iso_13485_2016.pdf"
        ... )
        ("ISO 13485:2016 - Medical devices - Quality management systems", 
         "International standard for medical device quality management systems")
    """
    import re
    
    if not text or len(text.strip()) < 10:
        # Fallback zu Dateiname
        clean_name = filename.replace('.pdf', '').replace('.docx', '').replace('.doc', '')
        return clean_name[:200], "Automatisch generiert aus Dateiname"
    
    # Erst 3000 Zeichen f√ºr Performance
    text_sample = text[:3000]
    lines = [line.strip() for line in text_sample.split('\n') if line.strip()]
    
    # Pattern f√ºr Normen-Titel (ISO, DIN, IEC, EN, etc.)
    norm_patterns = [
        r'((?:ISO|IEC|DIN|EN)\s+(?:ISO\s+)?[\d\-]+(?:\:\d+)?(?:\+\w+\s+\d+)?(?:\+\w+\s+\d+)?)',
        r'(ISO\s+\d+(?:\-\d+)*(?:\:\d+)?)',
        r'(IEC\s+\d+(?:\-\d+)*(?:\:\d+)?)',
        r'(DIN\s+EN\s+(?:ISO\s+)?\d+(?:\-\d+)*(?:\:\d+)?)',
        r'(EN\s+(?:ISO\s+)?\d+(?:\-\d+)*(?:\:\d+)?)'
    ]
    
    extracted_title = ""
    extracted_description = ""
    
    # Suche nach Norm-Nummer
    norm_number = ""
    for pattern in norm_patterns:
        for line in lines[:20]:  # Erste 20 Zeilen
            match = re.search(pattern, line, re.IGNORECASE)
            if match:
                norm_number = match.group(1).strip()
                break
        if norm_number:
            break
    
    # Suche nach Titel-Zeilen (oft nach der Norm-Nummer)
    title_candidates = []
    for i, line in enumerate(lines[:25]):  # Erste 25 Zeilen
        line_clean = line.strip()
        
        # Skip sehr kurze oder sehr lange Zeilen
        if len(line_clean) < 10 or len(line_clean) > 200:
            continue
            
        # Skip Zeilen mit nur Zahlen/Codes
        if re.match(r'^[\d\s\-\+\.]+$', line_clean):
            continue
            
        # Bevorzuge Zeilen mit QMS/Medizinprodukte-Keywords
        qms_keywords = ['medizinprodukte', 'medical device', 'qualit√§tsmanagement', 'quality management', 
                       'risk management', 'software', 'validation', 'sterilisation', 'biokompatibilit√§t']
        
        # Priorisiere Zeilen mit Norm-Nummer
        if norm_number and norm_number.lower() in line_clean.lower():
            title_candidates.append((line_clean, 100))  # H√∂chste Priorit√§t
        elif any(keyword in line_clean.lower() for keyword in qms_keywords):
            title_candidates.append((line_clean, 80))   # Hohe Priorit√§t
        elif len(line_clean) > 20 and len(line_clean) < 150:
            title_candidates.append((line_clean, 50))   # Mittlere Priorit√§t
    
    # Besten Titel w√§hlen
    if title_candidates:
        title_candidates.sort(key=lambda x: x[1], reverse=True)
        extracted_title = title_candidates[0][0]
        
        # Kombiniere mit Norm-Nummer falls verf√ºgbar
        if norm_number and norm_number.lower() not in extracted_title.lower():
            extracted_title = f"{norm_number} - {extracted_title}"
    else:
        # Fallback: Verwende Norm-Nummer oder Dateiname
        extracted_title = norm_number if norm_number else filename.replace('.pdf', '').replace('.docx', '')
    
    # Beschreibung generieren
    description_lines = []
    for line in lines[1:15]:  # Zeilen 2-15 f√ºr Beschreibung
        if len(line) > 20 and len(line) < 300:
            if line.lower() not in extracted_title.lower():  # Avoid duplicate
                description_lines.append(line)
                if len(description_lines) >= 3:  # Max 3 Zeilen
                    break
    
    extracted_description = " ".join(description_lines)[:500] if description_lines else "Automatisch extrahiert aus Dokumentinhalt"
    
    # Titel k√ºrzen falls zu lang
    if len(extracted_title) > 200:
        extracted_title = extracted_title[:197] + "..."
        
    return extracted_title, extracted_description

def extract_text_from_file(file_path: Path, mime_type: str) -> str:
    """
    Extrahiert Text aus Dateien f√ºr RAG-Indexierung.
    
    Args:
        file_path: Pfad zur Datei
        mime_type: MIME-Type der Datei
        
    Returns:
        Extrahierter Text oder leerer String
    """
    try:
        if mime_type == "text/plain" or mime_type == "text/markdown":
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        
        elif mime_type == "application/pdf":
            try:
                import PyPDF2
                with open(file_path, 'rb') as file:
                    reader = PyPDF2.PdfReader(file)
                    text = ""
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
                    return text.strip()
            except Exception as pdf_error:
                return f"[PDF-Extraktion fehlgeschlagen: {str(pdf_error)}]"
        
        elif mime_type in ["application/msword", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"]:
            try:
                from docx import Document
                doc = Document(file_path)
                
                text_parts = []
                # Abs√§tze extrahieren
                for paragraph in doc.paragraphs:
                    if paragraph.text.strip():
                        text_parts.append(paragraph.text)
                
                # Tabellen extrahieren
                for table in doc.tables:
                    for row in table.rows:
                        row_text = " | ".join(cell.text for cell in row.cells)
                        text_parts.append(row_text)
                        
                return "\n".join(text_parts)
            except Exception as word_error:
                return f"[Word-Extraktion fehlgeschlagen: {str(word_error)}]"
        
        elif mime_type in ["application/vnd.ms-excel", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"]:
            try:
                import openpyxl
                workbook = openpyxl.load_workbook(file_path)
                text_parts = []
                
                for sheet_name in workbook.sheetnames:
                    sheet = workbook[sheet_name]
                    text_parts.append(f"=== {sheet_name} ===")
                    
                    for row in sheet.iter_rows(values_only=True):
                        row_text = " | ".join(str(cell) if cell is not None else "" for cell in row)
                        if row_text.strip():
                            text_parts.append(row_text)
                
                return "\n".join(text_parts)
            except Exception as excel_error:
                return f"[Excel-Extraktion fehlgeschlagen: {str(excel_error)}]"
        
        else:
            return f"[Text-Extraktion f√ºr {mime_type} noch nicht implementiert]"
        
    except Exception as e:
        return f"[Fehler bei Text-Extraktion: {str(e)}]"

def generate_document_number(document_type: str) -> str:
    """
    Generiert eine eindeutige Dokumentennummer.
    
    Format: [TYPE]-[YYYY]-[COUNTER]
    Beispiel: SOP-2024-001, QM_MANUAL-2024-001
    """
    from datetime import datetime
    current_year = datetime.now().year
    
    # Typ-Abk√ºrzungen f√ºr Dokumentnummern
    type_prefixes = {
        "QM_MANUAL": "QMH",
        "SOP": "SOP",
        "WORK_INSTRUCTION": "WI",
        "FORM": "FRM",
        "SPECIFICATION": "SPEC",
        "RISK_ASSESSMENT": "RA",
        "VALIDATION_PROTOCOL": "VAL",
        "CALIBRATION_PROCEDURE": "CAL",
        "AUDIT_REPORT": "AUD",
        "CAPA_DOCUMENT": "CAPA",
        "TRAINING_MATERIAL": "TRN",
        "STANDARD_NORM": "STD",
        "REGULATION": "REG",
        "OTHER": "DOC"
    }
    
    prefix = type_prefixes.get(document_type, "DOC")
    
    # Einfacher Counter (f√ºr MVP - sp√§ter aus DB)
    import random
    counter = random.randint(1, 999)
    
    return f"{prefix}-{current_year}-{counter:03d}"

# ===== ANWENDUNGSINITIALISIERUNG =====

app = FastAPI(
    title="KI-QMS API",
    description="""
    ## KI-gest√ºtztes Qualit√§tsmanagementsystem f√ºr Medizinprodukte
    
    Ein modulares Backend-System f√ºr ISO 13485 und MDR-konforme QMS-Prozesse.
    
    ### Hauptfunktionen:
    - **13 Interessensgruppen-System**: Von Einkauf bis externe Auditoren
    - **Dokumentenmanagement**: 14 QMS-spezifische Dokumenttypen
    - **Kalibrierungsmanagement**: Equipment-√úberwachung und Fristencontrolling
    - **Normen-Compliance**: ISO 13485, MDR, ISO 14971 Integration
    - **Benutzer-/Rollenverwaltung**: Granulare Berechtigungssteuerung
    
    ### Technischer Stack:
    - **Backend**: FastAPI mit SQLAlchemy ORM
    - **Datenbank**: SQLite (MVP) / PostgreSQL (Production)
    - **Authentifizierung**: Token-basiert (JWT geplant)
    - **API-Dokumentation**: OpenAPI 3.0 / Swagger UI
    """,
    version="1.0.0",
    terms_of_service="https://example.com/terms/",
    contact={
        "name": "KI-QMS Support",
        "url": "https://example.com/contact/",
        "email": "support@ki-qms.de",
    },
    license_info={
        "name": "MIT License",
        "url": "https://opensource.org/licenses/MIT",
    },
)

# ===== CORS-KONFIGURATION =====
# Erlaubt Frontend-Zugriff von Streamlit und React Development Server
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000", "http://127.0.0.1:3000",  # React Frontend
        "http://localhost:8501", "http://127.0.0.1:8501",  # Streamlit Frontend
        "http://192.168.178.160:8501"  # Streamlit Network URL
    ],
    allow_credentials=True,
    allow_methods=["*"],  # GET, POST, PUT, DELETE, OPTIONS
    allow_headers=["*"],  # Content-Type, Authorization, etc.
)

# ===== STARTUP/SHUTDOWN EVENTS =====

@app.on_event("startup")
async def startup_event():
    """
    Anwendungsstart-Event.
    
    F√ºhrt beim Backend-Start notwendige Initialisierungen durch:
    - Pr√ºft Datenbankverbindung
    - Erstellt fehlende Tabellen
    - Initialisiert Standard-User und Interessensgruppen
    - Loggt Systemzustand
    """
    create_tables()
    
    # ‚úÖ NEU: Initialisiere Standard-User und Interessensgruppen
    await initialize_default_data()
    
    print("üöÄ KI-QMS MVP Backend gestartet!")
    print("üìä 13-Interessensgruppen-System ist bereit!")


async def initialize_default_data():
    """
    Initialisiert Standard-Daten f√ºr das QMS-System.
    
    Erstellt:
    - QMS Admin User (qms.admin@company.com)
    - Standard-Interessensgruppen
    - Basis-Konfiguration
    """
    try:
        db = next(get_db())
        
        # 1. Pr√ºfe ob QMS Admin bereits existiert
        existing_admin = db.query(UserModel).filter(
            UserModel.email == "qms.admin@company.com"
        ).first()
        
        if not existing_admin:
            print("üîß Erstelle QMS Admin User...")
            
            # QMS Admin User erstellen
            from .auth import get_password_hash
            
            admin_user = UserModel(
                email="qms.admin@company.com",
                full_name="QMS System Administrator",
                employee_id="QMS001",
                organizational_unit="Qualit√§tsmanagement",
                hashed_password=get_password_hash("admin123"),
                individual_permissions='["system_administration", "user_management", "document_management"]',
                is_department_head=True,
                approval_level=4,
                is_active=True
            )
            
            db.add(admin_user)
            db.commit()
            db.refresh(admin_user)
            
            print(f"‚úÖ QMS Admin erstellt: {admin_user.email} (ID: {admin_user.id})")
        else:
            print(f"‚úÖ QMS Admin bereits vorhanden: {existing_admin.email}")
        
        # 2. Pr√ºfe ob Standard-Interessensgruppen existieren
        existing_groups = db.query(InterestGroupModel).count()
        
        if existing_groups == 0:
            print("üîß Erstelle Standard-Interessensgruppen...")
            
            # Standard-Interessensgruppen erstellen
            default_groups = [
                {
                    "name": "Qualit√§tsmanagement",
                    "code": "QM",
                    "description": "Zentrale QM-Abteilung f√ºr Systemadministration und Compliance"
                },
                {
                    "name": "Entwicklung",
                    "code": "DEV",
                    "description": "Produktentwicklung und Design"
                },
                {
                    "name": "Produktion",
                    "code": "PROD",
                    "description": "Produktionsabteilung und Fertigung"
                }
            ]
            
            for group_data in default_groups:
                group = InterestGroupModel(
                    name=group_data["name"],
                    code=group_data["code"],
                    description=group_data["description"],
                    is_active=True
                )
                db.add(group)
            
            db.commit()
            print(f"‚úÖ {len(default_groups)} Standard-Interessensgruppen erstellt")
        else:
            print(f"‚úÖ {existing_groups} Interessensgruppen bereits vorhanden")
        
        db.close()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Fehler bei der Initialisierung: {e}")
        # Nicht kritisch - System kann trotzdem starten

# ===== HEALTH & STATUS ENDPOINTS =====

@app.get("/", tags=["System"])
async def root():
    """
    Root-Endpoint f√ºr grundlegende API-Informationen.
    
    Returns:
        dict: Basis-Informationen √ºber die API
        
    Example Response:
        ```json
        {
            "message": "KI-QMS API v1.0",
            "status": "running",
            "docs_url": "/docs",
            "health_check": "/health"
        }
        ```
    """
    return {
        "message": "KI-QMS API v1.0", 
        "status": "running",
        "docs_url": "/docs",
        "health_check": "/health"
    }

@app.get("/health", tags=["System"])
async def health_check():
    """
    Health-Check-Endpoint f√ºr Monitoring und Load Balancer.
    
    Pr√ºft:
    - API-Verf√ºgbarkeit
    - Datenbankverbindung (implizit)
    - Systemzustand
    
    Returns:
        dict: Health-Status mit Zeitstempel
        
    Example Response:
        ```json
        {
            "status": "healthy",
            "timestamp": "2024-01-15T10:30:00Z",
            "version": "1.0.0"
        }
        ```
    """
    from datetime import datetime
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "version": "1.0.0"
    }

# === AUTHENTICATION ENDPOINTS ===

@app.post("/api/auth/login", response_model=Token, tags=["Authentication"])
async def login(login_data: LoginRequest, db: Session = Depends(get_db)):
    """
    Benutzer-Login mit Email und Passwort.
    
    Erstellt einen JWT-Token f√ºr authentifizierten Zugriff auf das QMS.
    Der Token enth√§lt Benutzer-ID, Gruppen und Berechtigungen.
    
    Args:
        login_data: Email und Passwort
        db: Datenbankverbindung
        
    Returns:
        Token: JWT Access Token mit Benutzer-Informationen
        
    Example Request:
        ```json
        {
            "email": "maria.qm@company.com",
            "password": "secure_password"
        }
        ```
        
    Example Response:
        ```json
        {
            "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
            "token_type": "bearer",
            "expires_in": 1800,
            "user_id": 2,
            "user_name": "Dr. Maria Qualit√§t",
            "groups": ["quality_management"],
            "permissions": ["final_approval", "system_administration"]
        }
        ```
        
    Raises:
        HTTPException: 401 bei ung√ºltigen Anmeldedaten
    """
    
    # Benutzer authentifizieren
    user = authenticate_user(db, login_data.email, login_data.password)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Ung√ºltige Email oder Passwort",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # Benutzer-Gruppen und Berechtigungen laden
    user_groups = auth_get_user_groups(db, user)
    user_permissions = get_user_permissions(db, user)
    
    # JWT Token erstellen
    access_token = create_access_token(data={"sub": str(user.id)})
    
    return Token(
        access_token=access_token,
        token_type="bearer",
        expires_in=1800,  # 30 Minuten
        user_id=user.id,
        user_name=user.full_name,
        groups=user_groups,
        permissions=user_permissions
    )

@app.get("/api/auth/me", response_model=UserInfo, tags=["Authentication"])
async def get_current_user_info(
    current_user: UserModel = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Aktuelle Benutzer-Informationen abrufen.
    
    Liefert detaillierte Informationen √ºber den authentifizierten Benutzer
    inklusive Gruppen und Berechtigungen. F√ºr Benutzer-Profile und UI-Personalisierung.
    
    Args:
        current_user: Authentifizierter Benutzer (aus JWT Token)
        db: Datenbankverbindung
        
    Returns:
        UserInfo: Vollst√§ndige Benutzer-Informationen
        
    Example Response:
        ```json
        {
            "id": 2,
            "email": "maria.qm@company.com",
            "full_name": "Dr. Maria Qualit√§t",
            "organizational_unit": "Qualit√§tsmanagement",
            "is_department_head": true,
            "approval_level": 4,
            "groups": ["quality_management"],
            "permissions": ["final_approval", "gap_analysis", "system_administration"]
        }
        ```
        
    Note:
        - Erfordert g√ºltigen Bearer Token
        - Gruppenzugeh√∂rigkeiten werden live aus DB geladen
        - Berechtigungen werden aus Gruppen + individuellen Rechten zusammengestellt
    """
    
    user_groups = auth_get_user_groups(db, current_user)
    user_permissions = get_user_permissions(db, current_user)
    
    return UserInfo(
        id=current_user.id,
        email=current_user.email,
        full_name=current_user.full_name,
        organizational_unit=current_user.organizational_unit,
        is_department_head=current_user.is_department_head,
        approval_level=current_user.approval_level,
        groups=user_groups,
        permissions=user_permissions
    )
@app.post("/api/auth/logout", response_model=dict, tags=["Authentication"])
async def logout():
    """
    Benutzer-Logout (Token invalidieren).
    
    Da JWT-Tokens stateless sind, erfolgt das Logout client-seitig
    durch L√∂schen des Tokens. Dieser Endpoint dient als formaler Logout-Trigger.
    
    Returns:
        dict: Logout-Best√§tigung
        
    Example Response:
        ```json
        {
            "message": "Successfully logged out",
            "logged_out_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Note:
        - Client muss Token aus Local Storage/Session Storage l√∂schen
        - Server-seitige Token-Blacklist optional f√ºr h√∂here Sicherheit
        - F√ºr stateful Sessions w√ºrde hier Session gel√∂scht werden
    """
    
    return {
        "message": "Successfully logged out",
        "logged_out_at": datetime.utcnow().isoformat() + "Z"
    }

# === INTEREST GROUPS API ===

@app.get("/api/interest-groups", response_model=List[InterestGroup], tags=["Interest Groups"])
async def get_interest_groups(
    skip: int = 0,
    limit: int = 20,
    include_inactive: bool = False,
    db: Session = Depends(get_db)
):
    """
    Alle Interessensgruppen abrufen (standardm√§√üig nur aktive).
    
    Das 13-Interessensgruppen-System bildet die organisatorische Grundlage
    des QMS ab - von internen Stakeholdern (Einkauf, Produktion, QM) bis
    zu externen Partnern (Auditoren, Lieferanten).
    
    Args:
        skip (int): Anzahl zu √ºberspringender Datens√§tze (Pagination). Default: 0
        limit (int): Maximale Anzahl zur√ºckzugebender Datens√§tze. Default: 20, Max: 100
        include_inactive (bool): Auch deaktivierte Gruppen einschlie√üen. Default: False
        db (Session): Datenbankverbindung (automatisch injiziert)
    
    Returns:
        List[InterestGroup]: Liste der Interessensgruppen
        
    Example Response:
        ```json
        [
            {
                "id": 2,
                "name": "Qualit√§tsmanagement (QM)",
                "code": "quality_management",
                "description": "Alle Rechte, finale Freigabe, Gap-Analyse - Herzst√ºck des QMS",
                "permissions": ["all_rights", "final_approval", "gap_analysis"],
                "ai_functionality": "Gap-Analyse & Normpr√ºfung",
                "typical_tasks": "QM-Freigaben, CAPA-Management, interne Audits",
                "is_external": false,
                "is_active": true,
                "created_at": "2024-01-15T10:30:00Z"
            },
            {
                "id": 11,
                "name": "Auditor (extern)",
                "code": "external_auditor", 
                "description": "Read-only extern, Gap-API, Remote-Zugriff",
                "permissions": ["read_only_external", "gap_api", "remote_access"],
                "ai_functionality": "Read-only extern, Gap-API",
                "typical_tasks": "Externe Audits, Compliance-Pr√ºfungen",
                "is_external": true,
                "is_active": true,
                "created_at": "2024-01-15T10:30:00Z"
            }
        ]
        ```
    
    Raises:
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Soft-Delete: Gel√∂schte Gruppen haben is_active=false
        - Externe Gruppen (is_external=true): Auditoren, Lieferanten
        - Permissions sind als JSON-Array gespeichert
    """
    query = db.query(InterestGroupModel)
    
    # Standardm√§√üig nur aktive Gruppen anzeigen
    if not include_inactive:
        query = query.filter(InterestGroupModel.is_active == True)
    
    groups = query.offset(skip).limit(limit).all()
    
    # JSON-Strings in Listen konvertieren f√ºr Response-Validierung
    for group in groups:
        if group.group_permissions and isinstance(group.group_permissions, str):
            try:
                import json
                group.group_permissions = json.loads(group.group_permissions)
            except (json.JSONDecodeError, TypeError):
                group.group_permissions = []
    
    return groups

@app.get("/api/interest-groups/{group_id}", response_model=InterestGroup, tags=["Interest Groups"])
async def get_interest_group(group_id: int, db: Session = Depends(get_db)):
    """
    Eine spezifische Interessensgruppe abrufen.
    
    L√§dt eine einzelne Interessensgruppe mit allen Details,
    einschlie√ülich Berechtigungen und KI-Funktionalit√§ten.
    
    Args:
        group_id (int): Eindeutige ID der Interessensgruppe (1-13 f√ºr Standard-Gruppen)
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        InterestGroup: Detaillierte Informationen der Interessensgruppe
        
    Example Response:
        ```json
        {
            "id": 5,
            "name": "Entwicklung",
            "code": "development",
            "description": "Design-Control, Normpr√ºfung",
            "permissions": ["design_control", "norm_verification", "technical_documentation"],
            "ai_functionality": "Design-Control, Normpr√ºfung",
            "typical_tasks": "Produktentwicklung, Design-FMEA, technische Dokumentation",
            "is_external": false,
            "is_active": true,
            "created_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Interessensgruppe nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Auch deaktivierte Gruppen werden zur√ºckgegeben (f√ºr Admin-Zwecke)
        - Permissions als JSON-Array f√ºr flexible Berechtigungssteuerung
    """
    group = db.query(InterestGroupModel).filter(InterestGroupModel.id == group_id).first()
    if not group:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Interessensgruppe mit ID {group_id} nicht gefunden"
        )
    
    # JSON-String in Liste konvertieren f√ºr Response-Validierung
    if group.group_permissions and isinstance(group.group_permissions, str):
        try:
            import json
            group.group_permissions = json.loads(group.group_permissions)
        except (json.JSONDecodeError, TypeError):
            group.group_permissions = []
    
    return group

@app.post("/api/interest-groups", response_model=InterestGroup, tags=["Interest Groups"])
async def create_interest_group(
    group: InterestGroupCreate,
    db: Session = Depends(get_db)
):
    """
    Neue Interessensgruppe erstellen.
    
    Erstellt eine neue Interessensgruppe im System. Typischerweise f√ºr
    kundenspezifische Erweiterungen des Standard-13-Gruppen-Systems.
    
    Args:
        group (InterestGroupCreate): Daten der neuen Interessensgruppe
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        InterestGroup: Die erstellte Interessensgruppe mit generierter ID
        
    Example Request:
        ```json
        {
            "name": "Regulatorische Angelegenheiten",
            "code": "regulatory_affairs",
            "description": "FDA-Submissions, CE-Kennzeichnung, Marktzulassungen",
            "permissions": ["regulatory_submissions", "market_approval", "documentation_review"],
            "ai_functionality": "Regulatorische Dokumentenanalyse",
            "typical_tasks": "FDA-Antr√§ge, CE-Dokumentation, Marktzulassungsverfahren",
            "is_external": false
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 14,
            "name": "Regulatorische Angelegenheiten",
            "code": "regulatory_affairs",
            "description": "FDA-Submissions, CE-Kennzeichnung, Marktzulassungen",
            "permissions": ["regulatory_submissions", "market_approval", "documentation_review"],
            "ai_functionality": "Regulatorische Dokumentenanalyse",
            "typical_tasks": "FDA-Antr√§ge, CE-Dokumentation, Marktzulassungsverfahren",
            "is_external": false,
            "is_active": true,
            "created_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 409 wenn Code bereits existiert
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Code muss eindeutig sein (wird f√ºr API-Zugriff verwendet)
        - is_active wird automatisch auf true gesetzt
        - created_at wird automatisch gesetzt
    """
    # Pr√ºfen ob Code bereits existiert
    existing_group = db.query(InterestGroupModel).filter(
        InterestGroupModel.code == group.code
    ).first()
    if existing_group:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Interessensgruppe mit Code '{group.code}' existiert bereits"
        )
    
    # Daten vorbereiten und group_permissions zu JSON konvertieren
    group_data = group.dict()
    if 'group_permissions' in group_data and isinstance(group_data['group_permissions'], list):
        import json
        group_data['group_permissions'] = json.dumps(group_data['group_permissions'])
    
    db_group = InterestGroupModel(**group_data)
    db.add(db_group)
    db.commit()
    db.refresh(db_group)
    return db_group

@app.put("/api/interest-groups/{group_id}", response_model=InterestGroup, tags=["Interest Groups"])
async def update_interest_group(
    group_id: int,
    group_update: InterestGroupUpdate,
    db: Session = Depends(get_db)
):
    """
    Interessensgruppe aktualisieren.
    
    Aktualisiert eine bestehende Interessensgruppe. Besonders n√ºtzlich f√ºr:
    - Anpassung von Berechtigungen
    - Aktivierung/Deaktivierung von Gruppen
    - Aktualisierung von KI-Funktionalit√§ten
    
    Args:
        group_id (int): ID der zu aktualisierenden Interessensgruppe
        group_update (InterestGroupUpdate): Zu aktualisierende Felder (partial update)
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        InterestGroup: Die aktualisierte Interessensgruppe
        
    Example Request (Gruppe reaktivieren):
        ```json
        {
            "is_active": true,
            "description": "Wieder aktiviert nach Umstrukturierung"
        }
        ```
        
    Example Request (Berechtigungen erweitern):
        ```json
        {
            "permissions": ["existing_permission", "new_ai_feature", "advanced_analytics"],
            "ai_functionality": "Erweitert um pr√§diktive Analysen"
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 1,
            "name": "Einkauf",
            "code": "procurement",
            "description": "Wieder aktiviert nach Umstrukturierung",
            "permissions": ["supplier_evaluation", "purchase_notifications"],
            "ai_functionality": "Lieferantenbewertung, Benachrichtigungen",
            "typical_tasks": "Lieferantenqualifikation, Einkaufsprozesse",
            "is_external": false,
            "is_active": true,
            "created_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Interessensgruppe nicht gefunden
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Nur √ºbermittelte Felder werden aktualisiert (partial update)
        - updated_at wird automatisch gesetzt
        - Code und ID k√∂nnen nicht ge√§ndert werden
    """
    db_group = db.query(InterestGroupModel).filter(InterestGroupModel.id == group_id).first()
    if not db_group:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Interessensgruppe mit ID {group_id} nicht gefunden"
        )
    
    # Nur √ºbermittelte Felder aktualisieren
    update_data = group_update.dict(exclude_unset=True)
    
    # Pr√ºfen ob Code-Update zu Konflikt f√ºhren w√ºrde
    if 'code' in update_data and update_data['code'] != db_group.code:
        existing_code = db.query(InterestGroupModel).filter(
            InterestGroupModel.code == update_data['code'],
            InterestGroupModel.id != group_id
        ).first()
        if existing_code:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"Code '{update_data['code']}' wird bereits von einer anderen Gruppe verwendet"
            )
    
    # Group permissions zu JSON-String konvertieren, falls vorhanden
    if 'group_permissions' in update_data and isinstance(update_data['group_permissions'], list):
        import json
        update_data['group_permissions'] = json.dumps(update_data['group_permissions'])
    
    for field, value in update_data.items():
        setattr(db_group, field, value)
    
    db.commit()
    db.refresh(db_group)
    return db_group

@app.delete("/api/interest-groups/{group_id}", response_model=GenericResponse, tags=["Interest Groups"])
async def delete_interest_group(group_id: int, db: Session = Depends(get_db)):
    """
    Interessensgruppe l√∂schen (Soft Delete).
    
    F√ºhrt einen Soft Delete durch (is_active = false). Echtes L√∂schen wird
    vermieden, da Interessensgruppen in User-Memberships referenziert werden.
    
    Args:
        group_id (int): ID der zu l√∂schenden Interessensgruppe
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        GenericResponse: Best√§tigung der L√∂schung
        
    Example Response:
        ```json
        {
            "message": "Interessensgruppe 'Einkauf' wurde deaktiviert",
            "success": true
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Interessensgruppe nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Soft Delete: is_active wird auf false gesetzt
        - Daten bleiben in DB erhalten (f√ºr Audit-Trail)
        - User-Memberships bleiben bestehen
        - Reaktivierung √ºber PUT-Endpoint m√∂glich
        
    Warning:
        - Standard-Gruppen (ID 1-13) sollten nicht gel√∂scht werden
        - Pr√ºfe User-Memberships vor L√∂schung
    """
    db_group = db.query(InterestGroupModel).filter(InterestGroupModel.id == group_id).first()
    if not db_group:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Interessensgruppe mit ID {group_id} nicht gefunden"
        )
    
    # Soft Delete: is_active auf false setzen
    db_group.is_active = False
    db.commit()
    return GenericResponse(message=f"Interessensgruppe '{db_group.name}' wurde deaktiviert")

# === USERS API ===
# Benutzerverwaltung mit Rollen- und Interessensgruppen-Zuordnung

@app.get("/api/users", response_model=List[User], tags=["Users"])
async def get_users(
    skip: int = 0, 
    limit: int = 20, 
    current_user: UserModel = Depends(require_admin_or_qm),
    db: Session = Depends(get_db)
):
    """
    Alle Benutzer abrufen.
    
    L√§dt eine paginierte Liste aller Benutzer im System mit ihren
    Rollen und Metadaten. F√ºr Admin- und HR-Funktionen.
    
    Args:
        skip (int): Anzahl zu √ºberspringender Datens√§tze (Pagination). Default: 0
        limit (int): Maximale Anzahl zur√ºckzugebender Datens√§tze. Default: 20, Max: 100
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[User]: Liste aller Benutzer im System
        
    Example Response:
        ```json
        [
            {
                "id": 1,
                "email": "max.einkauf@company.com",
                "full_name": "Max Kaufmann",
                "employee_id": "EK001",
                "department": "Einkauf",
                "permissions": [],
                "is_department_head": false,
                "approval_level": 1,
                "is_active": true,
                "created_at": "2025-06-08T16:49:51.763170"
            },
            {
                "id": 2,
                "email": "maria.qm@company.com",
                "full_name": "Dr. Maria Qualit√§t",
                "employee_id": "QM001",
                "department": "Qualit√§tsmanagement",
                "permissions": [
                    "final_approval",
                    "system_administration",
                    "audit_management"
                ],
                "is_department_head": true,
                "approval_level": 4,
                "is_active": true,
                "created_at": "2025-06-08T16:49:51.763716"
            }
        ]
        ```
        
    Raises:
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Keine Passwort-Hashes in Response
        - Sortierung nach created_at (neueste zuerst)
        - F√ºr User-Management-Interfaces gedacht
    """
    users = db.query(UserModel).offset(skip).limit(limit).all()
    
    # JSON-Strings in Listen konvertieren f√ºr Response-Validierung
    for user in users:
        if user.individual_permissions and isinstance(user.individual_permissions, str):
            try:
                import json
                user.individual_permissions = json.loads(user.individual_permissions)
            except (json.JSONDecodeError, TypeError):
                user.individual_permissions = []
    
    return users
@app.get("/api/users/{user_id}", response_model=User, tags=["Users"])
async def get_user(user_id: int, db: Session = Depends(get_db)):
    """
    Einen spezifischen Benutzer abrufen.
    
    L√§dt einen einzelnen Benutzer mit allen Details (au√üer Passwort).
    F√ºr Profil-Anzeige und Admin-Funktionen.
    
    Args:
        user_id (int): Eindeutige ID des Benutzers
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        User: Detaillierte Benutzerinformationen
        
    Example Response:
        ```json
        {
            "id": 5,
            "email": "dr.mueller@company.com",
            "full_name": "Dr. Peter M√ºller",
            "employee_id": "EN001",
            "department": "Entwicklung",
            "permissions": [
                "design_approval",
                "change_management"
            ],
            "is_department_head": true,
            "approval_level": 3,
            "is_active": true,
            "created_at": "2025-06-08T16:49:51.765091"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Benutzer nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Passwort-Hash wird niemals zur√ºckgegeben
        - Auch deaktivierte Benutzer werden angezeigt (f√ºr Admin)
    """
    user = db.query(UserModel).filter(UserModel.id == user_id).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Benutzer mit ID {user_id} nicht gefunden"
        )
    
    # JSON-String in Liste konvertieren f√ºr Response-Validierung
    if user.individual_permissions and isinstance(user.individual_permissions, str):
        try:
            import json
            user.individual_permissions = json.loads(user.individual_permissions)
        except (json.JSONDecodeError, TypeError):
            user.individual_permissions = []
    
    return user

@app.post("/api/users", response_model=User, tags=["Users"])
async def create_user(
    user: UserCreate, 
    current_user: UserModel = Depends(require_qms_admin),
    db: Session = Depends(get_db)
):
    """
    Neuen Benutzer erstellen.
    
    Erstellt einen neuen Benutzer im System mit verschl√ºsseltem Passwort.
    F√ºr Admin-Funktionen und Benutzer-Onboarding.
    
    Args:
        user (UserCreate): Daten des neuen Benutzers
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        User: Der erstellte Benutzer (ohne Passwort-Hash)
        
    Example Request:
        ```json
        {
            "email": "lisa.wagner@medtech-company.de",
            "password": "SecurePassword123!",
            "full_name": "Lisa Wagner",
            "employee_id": "LW001",
            "department": "Fertigung",
            "permissions": ["production_oversight"],
            "is_department_head": false,
            "approval_level": 2
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 12,
            "email": "lisa.wagner@medtech-company.de",
            "full_name": "Lisa Wagner",
            "employee_id": "LW001",
            "department": "Fertigung",
            "permissions": ["production_oversight"],
            "is_department_head": false,
            "approval_level": 2,
            "is_active": true,
            "created_at": "2025-06-08T17:30:00.000000"
        }
        ```
        
    Raises:
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 409 wenn Username oder Email bereits existiert
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Passwort wird gehasht gespeichert (bcrypt)
        - Email muss eindeutig sein (verwendet als Login)
        - is_active wird automatisch auf true gesetzt
        - Passwort-Richtlinien werden validiert
        - Berechtigungen k√∂nnen individuell und √ºber Interessensgruppen vergeben werden
        - Automatische Abteilungszuordnung basierend auf organizational_unit
        
    Security:
        - Passwort-Hashing mit bcrypt
        - Email-Validierung durch Pydantic
        - SQL-Injection-Schutz durch SQLAlchemy
    """
    # Pr√ºfen ob Email bereits existiert
    existing_email = db.query(UserModel).filter(UserModel.email == user.email).first()
    if existing_email:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Email-Adresse '{user.email}' ist bereits registriert"
        )
    
    # Password hashen mit bcrypt
    hashed_password = get_password_hash(user.password)
    
    # Individual permissions als JSON-String serialisieren
    import json
    individual_permissions_json = json.dumps(user.individual_permissions) if user.individual_permissions else "[]"
    
    db_user = UserModel(
        email=user.email,
        hashed_password=hashed_password,
        full_name=user.full_name,
        employee_id=user.employee_id,
        organizational_unit=user.organizational_unit,
        individual_permissions=individual_permissions_json,
        is_department_head=user.is_department_head,
        approval_level=user.approval_level
    )
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
    
    # === AUTOMATISCHE ABTEILUNGSZUORDNUNG ===
    # Mapping von organizational_unit Namen zu Interest Group IDs
    department_mapping = {
        "System Administration": 1,  # Team/Eingangsmodul (verwende f√ºr System Admin)
        "Team/Eingangsmodul": 1,
        "Qualit√§tsmanagement": 2,
        "Entwicklung": 3,
        "Einkauf": 4,
        "Produktion": 5,
        "HR/Schulung": 6,
        "Dokumentation": 7,
        "Service/Support": 8,
        "Vertrieb": 9,
        "Regulatory Affairs": 10,
        "IT-Abteilung": 11,
        "Externe Auditoren": 12,
        "Lieferanten": 13
    }
    
    # Automatische Zuordnung zur passenden Interest Group
    if user.organizational_unit in department_mapping:
        interest_group_id = department_mapping[user.organizational_unit]
        
        # UserGroupMembership erstellen
        new_membership = UserGroupMembershipModel(
            user_id=db_user.id,
            interest_group_id=interest_group_id,
            approval_level=user.approval_level,
            role_in_group=f"Level {user.approval_level}",
            is_department_head=user.is_department_head,
            assigned_by_id=1,  # System erstellt automatisch (qms.admin@company.com)
            notes=f"Automatisch zugeordnet bei User-Erstellung f√ºr '{user.organizational_unit}'"
        )
        
        db.add(new_membership)
        db.commit()
        db.refresh(new_membership)
        
        print(f"‚úÖ User '{user.full_name}' automatisch der Abteilung '{user.organizational_unit}' zugeordnet (Level {user.approval_level})")
    else:
        print(f"‚ö†Ô∏è User '{user.full_name}': Keine automatische Abteilungszuordnung f√ºr '{user.organizational_unit}' m√∂glich")
    
    return db_user

@app.put("/api/users/{user_id}", response_model=User, tags=["Users"])
async def update_user(
    user_id: int,
    user_update: UserUpdate,
    current_user: UserModel = Depends(require_admin_or_qm),
    db: Session = Depends(get_db)
):
    """
    Benutzer aktualisieren.
    
    Aktualisiert einen bestehenden Benutzer. F√ºr Profil-Updates,
    Rollen-√Ñnderungen und Admin-Funktionen.
    
    Args:
        user_id (int): ID des zu aktualisierenden Benutzers
        user_update (UserUpdate): Zu aktualisierende Felder (partial update)
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        User: Der aktualisierte Benutzer
        
    Example Request (Rolle √§ndern):
        ```json
        {
            "role": "QM_MANAGER",
            "department": "Qualit√§tsmanagement"
        }
        ```
        
    Example Request (Berechtigungen und Level √§ndern):
        ```json
        {
            "permissions": ["design_approval", "change_management"],
            "is_department_head": true,
            "approval_level": 3,
            "department": "Produktentwicklung"
        }
        ```
        
    Example Request (Benutzer deaktivieren):
        ```json
        {
            "is_active": false
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 7,
            "email": "tom.schneider@medtech-company.de",
            "full_name": "Tom Schneider",
            "employee_id": "TS001",
            "department": "Produktentwicklung",
            "permissions": ["design_approval", "change_management"],
            "is_department_head": true,
            "approval_level": 3,
            "is_active": true,
            "created_at": "2025-01-15T10:30:00.000000"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Benutzer nicht gefunden
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 409 bei Konflikten (Email bereits vergeben)
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Nur √ºbermittelte Felder werden aktualisiert
        - Passwort-Updates erfordern separaten Endpoint
        - Email muss eindeutig bleiben
        - Berechtigungs√§nderungen werden auditiert
        
    Security:
        - Berechtigung erforderlich (in echtem System)
        - Audit-Log wird erstellt
    """
    db_user = db.query(UserModel).filter(UserModel.id == user_id).first()
    if not db_user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Benutzer mit ID {user_id} nicht gefunden"
        )
    
    # Nur √ºbermittelte Felder aktualisieren
    update_data = user_update.dict(exclude_unset=True)
    
    # Pr√ºfen auf Email-Konflikte (falls ge√§ndert)
    if "email" in update_data:
        existing_email = db.query(UserModel).filter(
            UserModel.email == update_data["email"],
            UserModel.id != user_id
        ).first()
        if existing_email:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"Email-Adresse '{update_data['email']}' ist bereits registriert"
            )
    
    # Permissions als JSON-String serialisieren (falls vorhanden)
    if "permissions" in update_data and update_data["permissions"] is not None:
        import json
        update_data["permissions"] = json.dumps(update_data["permissions"])
    
    for field, value in update_data.items():
        setattr(db_user, field, value)
    
    db.commit()
    db.refresh(db_user)
    return db_user

@app.delete("/api/users/{user_id}", response_model=GenericResponse, tags=["Users"])
async def delete_user(user_id: int, db: Session = Depends(get_db)):
    """
    Benutzer l√∂schen (Soft Delete).
    
    Deaktiviert einen Benutzer anstatt ihn komplett zu l√∂schen, um
    referentielle Integrit√§t und Audit-Trail zu bewahren.
    
    Args:
        user_id (int): ID des zu l√∂schenden Benutzers
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        GenericResponse: Best√§tigung der L√∂schung
        
    Example Response:
        ```json
        {
            "message": "Benutzer 'Max Kaufmann' (EK001) wurde erfolgreich deaktiviert",
            "success": true
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Benutzer nicht gefunden
        HTTPException: 400 wenn Benutzer bereits deaktiviert
        HTTPException: 409 bei Abh√§ngigkeits-Konflikten (z.B. laufende Kalibrierungen)
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - **Soft Delete**: User wird nur deaktiviert (is_active = false)
        - **Referenzen bleiben:** Dokumente, Kalibrierungen etc. bleiben erhalten
        - **Audit-Trail:** √Ñnderung wird protokolliert
        - **Reaktivierung m√∂glich:** Kann sp√§ter wieder aktiviert werden
        
    Business Logic:
        - Pr√ºft aktive Abh√§ngigkeiten (laufende Kalibrierungen)
        - Entfernt aus allen Interessensgruppen
        - Setzt is_active = false
        - Beh√§lt alle historischen Daten
        
    Security:
        - Admin-Berechtigung erforderlich (in echtem System)
        - Selbstl√∂schung wird verhindert
        - Audit-Log wird erstellt
    """
    db_user = db.query(UserModel).filter(UserModel.id == user_id).first()
    if not db_user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Benutzer mit ID {user_id} nicht gefunden"
        )
    
    # Pr√ºfen ob bereits deaktiviert
    if not db_user.is_active:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Benutzer '{db_user.full_name}' ist bereits deaktiviert"
        )
    
    # Pr√ºfen auf aktive Abh√§ngigkeiten (z.B. laufende Kalibrierungen)
    from app.models import Calibration as CalibrationModel
    active_calibrations = db.query(CalibrationModel).filter(
        CalibrationModel.responsible_user_id == user_id,
        CalibrationModel.status == "valid"
    ).count()
    
    if active_calibrations > 0:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Benutzer kann nicht deaktiviert werden: {active_calibrations} aktive Kalibrierungen zugeordnet"
        )
    
    # Aus allen Interessensgruppen entfernen
    from app.models import UserGroupMembership as UserGroupMembershipModel
    db.query(UserGroupMembershipModel).filter(
        UserGroupMembershipModel.user_id == user_id
    ).delete()
    
    # Soft Delete: nur deaktivieren
    db_user.is_active = False
    
    db.commit()
    
    return GenericResponse(
        message=f"Benutzer '{db_user.full_name}' ({db_user.employee_id or 'ohne ID'}) wurde erfolgreich deaktiviert",
        success=True
    )

@app.delete("/api/users/{user_id}/hard-delete", response_model=GenericResponse, tags=["Users"])
async def hard_delete_user(
    user_id: int, 
    confirm_deletion: bool = False,
    db: Session = Depends(get_db)
):
    """
    Benutzer permanent l√∂schen (Hard Delete) - DSGVO Compliance.
    
    **WARNUNG:** Unwiderrufliche L√∂schung! Nur f√ºr DSGVO-Anfragen oder Compliance.
    L√∂scht alle Benutzerdaten und anonymisiert referenzierte Datens√§tze.
    
    Args:
        user_id (int): ID des zu l√∂schenden Benutzers
        confirm_deletion (bool): Sicherheitsbest√§tigung (muss true sein)
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        GenericResponse: Best√§tigung der permanenten L√∂schung
        
    Example Request:
        ```
        DELETE /api/users/7/hard-delete?confirm_deletion=true
        ```
        
    Example Response:
        ```json
        {
            "message": "Benutzer permanent gel√∂scht. Referenzen anonymisiert: 3 Dokumente, 5 Kalibrierungen",
            "success": true
        }
        ```
        
    Raises:
        HTTPException: 400 wenn confirm_deletion nicht gesetzt
        HTTPException: 404 wenn Benutzer nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - **Unwiderruflich:** Daten k√∂nnen nicht wiederhergestellt werden
        - **DSGVO-konform:** Erf√ºllt "Recht auf Vergessenwerden"
        - **Anonymisierung:** Referenzen werden zu "Gel√∂schter Benutzer" 
        - **Audit-Log:** L√∂schung wird protokolliert (ohne Personendaten)
        
    Business Logic:
        1. Sicherheitscheck: confirm_deletion muss explizit true sein
        2. Anonymisiert alle referenzierten Datens√§tze
        3. L√∂scht User-Gruppenzugeh√∂rigkeiten
        4. L√∂scht Benutzerdatensatz permanent
        
    DSGVO Compliance:
        - Art. 17 DSGVO (Recht auf Vergessenwerden)
        - Vollst√§ndige Entfernung personenbezogener Daten
        - Audit-Trail ohne Personenbezug
        
    Security:
        - Superadmin-Berechtigung erforderlich
        - Explizite Best√§tigung notwendig
        - Umfassendes Logging (anonymisiert)
    """
    if not confirm_deletion:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Hard Delete erfordert explizite Best√§tigung: confirm_deletion=true"
        )
    
    db_user = db.query(UserModel).filter(UserModel.id == user_id).first()
    if not db_user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Benutzer mit ID {user_id} nicht gefunden"
        )
    
    # Statistiken f√ºr Audit-Log sammeln (vor der Anonymisierung)
    user_name = db_user.full_name  # F√ºr Response (wird danach gel√∂scht)
    
    # 1. Dokumente anonymisieren (Creator-Referenzen)
    from app.models import Document as DocumentModel
    affected_documents = db.query(DocumentModel).filter(
        DocumentModel.creator_id == user_id
    ).count()
    
    db.query(DocumentModel).filter(
        DocumentModel.creator_id == user_id
    ).update({"creator_id": None})  # NULL = Anonymisiert
    
    # 2. Kalibrierungen anonymisieren  
    from app.models import Calibration as CalibrationModel
    affected_calibrations = db.query(CalibrationModel).filter(
        CalibrationModel.responsible_user_id == user_id
    ).count()
    
    db.query(CalibrationModel).filter(
        CalibrationModel.responsible_user_id == user_id
    ).update({"responsible_user_id": None})  # NULL = Anonymisiert
    
    # 3. User-Group-Memberships l√∂schen
    from app.models import UserGroupMembership as UserGroupMembershipModel
    db.query(UserGroupMembershipModel).filter(
        UserGroupMembershipModel.user_id == user_id
    ).delete()
    
    # 4. Benutzer permanent l√∂schen
    db.delete(db_user)
    db.commit()
    
    return GenericResponse(
        message=f"Benutzer permanent gel√∂scht. Referenzen anonymisiert: {affected_documents} Dokumente, {affected_calibrations} Kalibrierungen",
        success=True
    )

# === USER GROUP MEMBERSHIPS API ===
# Zuordnung von Benutzern zu Interessensgruppen (Many-to-Many Relationship)

@app.get("/api/user-group-memberships", response_model=List[UserGroupMembership], tags=["User Group Memberships"])
async def get_memberships(skip: int = 0, limit: int = 50, db: Session = Depends(get_db)):
    """
    Alle Benutzer-Gruppen-Zuordnungen abrufen.
    
    Zeigt alle Zuordnungen zwischen Benutzern und Interessensgruppen.
    F√ºr Admin-√úbersichten und Berechtigungsmanagement.
    
    Args:
        skip (int): Anzahl zu √ºberspringender Datens√§tze. Default: 0
        limit (int): Maximale Anzahl zur√ºckzugebender Datens√§tze. Default: 50, Max: 200
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[UserGroupMembership]: Liste aller Benutzer-Gruppen-Zuordnungen
        
    Example Response:
        ```json
        [
            {
                "id": 1,
                "user_id": 2,
                "interest_group_id": 2,
                "role_in_group": "QM_LEAD",
                "joined_at": "2024-01-15T10:30:00Z",
                "is_active": true
            },
            {
                "id": 5,
                "user_id": 3,
                "interest_group_id": 5,
                "role_in_group": "DEVELOPMENT_ENGINEER",
                "joined_at": "2024-01-15T10:30:00Z",
                "is_active": true
            }
        ]
        ```
        
    Raises:
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Many-to-Many: Ein User kann mehreren Gruppen angeh√∂ren
        - role_in_group definiert spezifische Rolle in der Gruppe
        - Nur aktive Memberships werden standardm√§√üig angezeigt
    """
    memberships = db.query(UserGroupMembershipModel).offset(skip).limit(limit).all()
    return memberships

@app.post("/api/user-group-memberships", response_model=UserGroupMembership, tags=["User Group Memberships"])
async def create_membership(
    membership: UserGroupMembershipCreate,
    db: Session = Depends(get_db)
):
    """
    Benutzer einer Interessensgruppe zuordnen.
    
    Erstellt eine neue Zuordnung zwischen einem Benutzer und einer
    Interessensgruppe mit spezifischer Rolle.
    
    Args:
        membership (UserGroupMembershipCreate): Daten der neuen Zuordnung
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        UserGroupMembership: Die erstellte Zuordnung
        
    Example Request:
        ```json
        {
            "user_id": 7,
            "interest_group_id": 3,
            "role_in_group": "PRODUCTION_SUPERVISOR"
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 23,
            "user_id": 7,
            "interest_group_id": 3,
            "role_in_group": "PRODUCTION_SUPERVISOR", 
            "joined_at": "2024-01-15T10:30:00Z",
            "is_active": true
        }
        ```
        
    Raises:
        HTTPException: 400 bei ung√ºltigen user_id oder interest_group_id
        HTTPException: 409 wenn Zuordnung bereits existiert
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Pr√ºft Existenz von User und Interest Group
        - Verhindert doppelte Zuordnungen
        - joined_at wird automatisch gesetzt
        - is_active ist standardm√§√üig true
        
    Business Logic:
        - Ein User kann mehreren Gruppen angeh√∂ren
        - Verschiedene Rollen in verschiedenen Gruppen m√∂glich
        - Externe Auditoren nur in externen Gruppen
    """
    # Pr√ºfen ob User existiert
    user_exists = db.query(UserModel).filter(UserModel.id == membership.user_id).first()
    if not user_exists:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Benutzer mit ID {membership.user_id} existiert nicht"
        )
    
    # Pr√ºfen ob Interest Group existiert
    group_exists = db.query(InterestGroupModel).filter(InterestGroupModel.id == membership.interest_group_id).first()
    if not group_exists:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Interessensgruppe mit ID {membership.interest_group_id} existiert nicht"
        )
    
    # Pr√ºfen ob Zuordnung bereits existiert
    existing_membership = db.query(UserGroupMembershipModel).filter(
        UserGroupMembershipModel.user_id == membership.user_id,
        UserGroupMembershipModel.interest_group_id == membership.interest_group_id
    ).first()
    if existing_membership:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="Diese Benutzer-Gruppen-Zuordnung existiert bereits"
        )
    
    db_membership = UserGroupMembershipModel(**membership.dict())
    db.add(db_membership)
    db.commit()
    db.refresh(db_membership)
    return db_membership

@app.delete("/api/user-group-memberships/{membership_id}", response_model=GenericResponse, tags=["User Group Memberships"])
async def delete_user_group_membership(membership_id: int, db: Session = Depends(get_db)):
    """
    Benutzer-Gruppen-Zuordnung l√∂schen.
    
    Entfernt einen Benutzer aus einer Interessensgruppe durch L√∂schen
    der entsprechenden Membership-Zuordnung.
    
    Args:
        membership_id (int): ID der zu l√∂schenden Zuordnung
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        GenericResponse: Best√§tigung der L√∂schung
        
    Example Response:
        ```json
        {
            "message": "Benutzer 'Anna Schmidt' wurde aus Interessensgruppe 'Entwicklung' entfernt",
            "success": true
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Membership nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Hard Delete: Zuordnung wird permanent entfernt
        - Benutzer und Interessensgruppe bleiben erhalten
        - F√ºr Reorganisation von Team-Strukturen
        
    Business Logic:
        - Pr√ºfe ob Benutzer Admin-Rechte in der Gruppe hatte
        - Benachrichtigung an betroffene Teams
        - Audit-Log f√ºr Nachverfolgbarkeit
    """
    membership = db.query(UserGroupMembershipModel).filter(UserGroupMembershipModel.id == membership_id).first()
    if not membership:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Benutzer-Gruppen-Zuordnung mit ID {membership_id} nicht gefunden"
        )
    
    user = db.query(UserModel).filter(UserModel.id == membership.user_id).first()
    group = db.query(InterestGroupModel).filter(InterestGroupModel.id == membership.interest_group_id).first()
    
    db.delete(membership)
    db.commit()
    return GenericResponse(message=f"Benutzer '{user.full_name}' wurde aus Interessensgruppe '{group.name}' entfernt")

# === HELPER ENDPOINTS ===

@app.get("/api/users/{user_id}/groups", response_model=List[InterestGroup], tags=["User Group Memberships"])
async def get_user_groups(user_id: int, db: Session = Depends(get_db)):
    """
    Alle Interessensgruppen eines Benutzers abrufen.
    
    Zeigt alle Interessensgruppen an, denen ein spezifischer
    Benutzer zugeordnet ist. F√ºr Benutzer-Profile und Berechtigungs√ºbersichten.
    
    Args:
        user_id (int): Eindeutige ID des Benutzers
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[InterestGroup]: Liste aller Gruppen des Benutzers
        
    Example Response:
        ```json
        [
            {
                "id": 5,
                "name": "Entwicklung",
                "code": "development",
                "description": "Design-Control, Normpr√ºfung",
                "permissions": ["design_control", "norm_verification"],
                "ai_functionality": "Design-Control, Normpr√ºfung",
                "typical_tasks": "Produktentwicklung, Design-FMEA",
                "is_external": false,
                "is_active": true,
                "created_at": "2024-01-15T10:30:00Z"
            },
            {
                "id": 2,
                "name": "Qualit√§tsmanagement (QM)",
                "code": "quality_management", 
                "description": "Alle Rechte, finale Freigabe",
                "permissions": ["all_rights", "final_approval"],
                "ai_functionality": "Gap-Analyse & Normpr√ºfung",
                "typical_tasks": "QM-Freigaben, CAPA-Management",
                "is_external": false,
                "is_active": true,
                "created_at": "2024-01-15T10:30:00Z"
            }
        ]
        ```
        
    Raises:
        HTTPException: 404 wenn Benutzer nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Nur aktive Interessensgruppen werden angezeigt
        - Sortierung nach Gruppennamen (alphabetisch)
        - F√ºr Berechtigungsmatrix-Darstellung geeignet
        
    Use Cases:
        - Benutzer-Profil anzeigen
        - Berechtigungen pr√ºfen
        - Team-Zugeh√∂rigkeiten verwalten
    """
    user = db.query(UserModel).filter(UserModel.id == user_id).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Benutzer mit ID {user_id} nicht gefunden"
        )
    
    # Join √ºber UserGroupMembership um nur aktive Gruppen zu holen
    groups = db.query(InterestGroupModel).join(UserGroupMembershipModel).filter(
        UserGroupMembershipModel.user_id == user_id,
        InterestGroupModel.is_active == True
    ).all()
    
    # JSON-Strings in Listen konvertieren f√ºr Response-Validierung
    for group in groups:
        if group.group_permissions and isinstance(group.group_permissions, str):
            try:
                import json
                group.group_permissions = json.loads(group.group_permissions)
            except (json.JSONDecodeError, TypeError):
                group.group_permissions = []
    
    return groups

@app.get("/api/interest-groups/{group_id}/users", response_model=List[User], tags=["User Group Memberships"])
async def get_group_users(group_id: int, db: Session = Depends(get_db)):
    """
    Alle Benutzer einer Interessensgruppe abrufen.
    
    Zeigt alle Benutzer an, die einer spezifischen Interessensgruppe
    zugeordnet sind. F√ºr Team-√úbersichten und Kontaktlisten.
    
    Args:
        group_id (int): Eindeutige ID der Interessensgruppe
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[User]: Liste aller Benutzer in der Gruppe
        
    Example Response:
        ```json
        [
            {
                "id": 3,
                "username": "anna.schmidt",
                "email": "anna.schmidt@medtech-company.de",
                "full_name": "Anna Schmidt",
                "role": "DEVELOPMENT_ENGINEER",
                "department": "Produktentwicklung",
                "is_active": true,
                "created_at": "2024-01-15T10:30:00Z"
            },
            {
                "id": 8,
                "username": "tom.werner",
                "email": "tom.werner@medtech-company.de",
                "full_name": "Tom Werner",
                "role": "SENIOR_DEVELOPER",
                "department": "Produktentwicklung",
                "is_active": true,
                "created_at": "2024-01-12T14:20:00Z"
            }
        ]
        ```
        
    Raises:
        HTTPException: 404 wenn Interessensgruppe nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Nur aktive Benutzer werden angezeigt
        - Sortierung nach Benutzernamen (alphabetisch)
        - Passwort-Hashes werden niemals zur√ºckgegeben
        
    Use Cases:
        - Team-Kontaktlisten erstellen
        - Zust√§ndigkeiten identifizieren
        - Benachrichtigungen an ganze Gruppen senden
    """
    group = db.query(InterestGroupModel).filter(InterestGroupModel.id == group_id).first()
    if not group:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Interessensgruppe mit ID {group_id} nicht gefunden"
        )
    
    # Join √ºber UserGroupMembership um nur aktive Benutzer zu holen
    users = db.query(UserModel).join(UserGroupMembershipModel).filter(
        UserGroupMembershipModel.interest_group_id == group_id,
        UserModel.is_active == True
    ).all()
    
    # JSON-Strings in Listen konvertieren f√ºr Response-Validierung
    for user in users:
        if user.individual_permissions and isinstance(user.individual_permissions, str):
            try:
                import json
                user.individual_permissions = json.loads(user.individual_permissions)
            except (json.JSONDecodeError, TypeError):
                user.individual_permissions = []
    
    return users

# === DOCUMENTS API ===
# Dokumentenmanagement mit 14 QMS-spezifischen Dokumenttypen

@app.get("/api/documents", response_model=List[Document], tags=["Documents"])
async def get_documents(
    skip: int = 0,
    limit: int = 20,
    document_type: Optional[str] = None,
    status: Optional[str] = None,
    search: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    Alle Dokumente abrufen mit erweiterten Filteroptionen.
    
    L√§dt eine paginierte Liste aller QMS-Dokumente mit optionalen Filtern
    f√ºr Typ, Status und Volltextsuche.
    """
    try:
        query = db.query(DocumentModel)
        
        # Filter nach Dokumenttyp
        if document_type:
            try:
                doc_type_enum = DocumentType(document_type)
                query = query.filter(DocumentModel.document_type == doc_type_enum)
            except ValueError:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"Ung√ºltiger Dokumenttyp: {document_type}"
                )
        
        # Filter nach Status
        if status:
            try:
                status_enum = DocumentStatus(status)
                query = query.filter(DocumentModel.status == status_enum)
            except ValueError:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"Ung√ºltiger Status: {status}"
                )
        
        # Volltextsuche
        if search:
            search_filter = f"%{search}%"
            query = query.filter(
                (DocumentModel.title.ilike(search_filter)) |
                (DocumentModel.content.ilike(search_filter))
            )
        
        documents = query.order_by(DocumentModel.created_at.desc()).offset(skip).limit(limit).all()
        
        # Debug-Ausgabe
        print(f"‚úÖ Gefunden: {len(documents)} Dokumente")
        for doc in documents[:3]:
            print(f"  - {doc.id}: {doc.title} ({doc.document_type})")
            
        return documents
        
    except Exception as e:
        print(f"‚ùå FEHLER in get_documents: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Datenbankfehler: {str(e)}"
        )

@app.get("/api/documents/types", response_model=List[str], tags=["Documents"])
async def get_document_types():
    """
    Alle verf√ºgbaren Dokumenttypen abrufen.
    
    Liefert eine Liste aller im System definierten Dokumenttypen.
    F√ºr Dropdown-Men√ºs und Validierung in Frontend-Anwendungen.
    
    Returns:
        List[str]: Liste aller Dokumenttyp-Enum-Werte
        
    Example Response:
        ```json
        [
            "QM_MANUAL",
            "SOP", 
            "WORK_INSTRUCTION",
            "FORM",
            "USER_MANUAL",
            "SERVICE_MANUAL",
            "RISK_ASSESSMENT",
            "VALIDATION_PROTOCOL",
            "CALIBRATION_PROCEDURE",
            "AUDIT_REPORT",
            "CAPA_DOCUMENT",
            "TRAINING_MATERIAL",
            "SPECIFICATION",
            "OTHER"
        ]
        ```
        
    Note:
        - Statische Liste basierend auf DocumentType Enum
        - F√ºr Frontend-Dropdown-Men√ºs optimiert
        - Alphabetisch sortiert f√ºr bessere UX
        
    Use Cases:
        - Formulare mit Dokumenttyp-Auswahl
        - Validierung von API-Eingaben
        - Filter-Optionen in Such-Interfaces
    """
    return [doc_type.value for doc_type in DocumentType]

# === VISIO-PROMPT ENDPOINTS ===

@app.get("/api/visio-prompts/types", response_model=Dict[str, Dict[str, str]], tags=["Visio Prompts"])
async def get_visio_prompt_types():
    """Gibt alle verf√ºgbaren Visio-Prompts mit Metadaten zur√ºck"""
    from .visio_prompts import get_available_document_types
    return get_available_document_types()

@app.get("/api/visio-prompts/{document_type}", response_model=Dict[str, Any], tags=["Visio Prompts"])
async def get_visio_prompt_for_type(document_type: str):
    """Gibt den Prompt f√ºr einen bestimmten Dokumenttyp mit erweiterten Metadaten zur√ºck"""
    from .visio_prompts import get_prompt_for_document_type
    return get_prompt_for_document_type(document_type)

@app.get("/api/visio-prompts/{document_type}/debug", response_model=Dict[str, str], tags=["Visio Prompts"])
async def get_visio_prompt_debug_info(document_type: str):
    """Gibt Debug-Informationen f√ºr einen Prompt zur√ºck"""
    from .visio_prompts import get_prompt_debug_info
    return get_prompt_debug_info(document_type)

@app.get("/api/visio-prompts/validate", response_model=Dict[str, bool], tags=["Visio Prompts"])
async def validate_visio_prompts():
    """Validiert alle Visio-Prompts"""
    from .visio_prompts import validate_all_prompts
    return validate_all_prompts()

@app.get("/api/visio-prompts/{document_type}/confirm", response_model=Dict[str, Any], tags=["Visio Prompts"])
async def confirm_visio_prompt_usage(document_type: str):
    """Best√§tigt die Verwendung eines Prompts mit Hash und Version f√ºr Audit-Zwecke"""
    from .visio_prompts import get_prompt_for_document_type
    import hashlib
    from datetime import datetime
    
    try:
        prompt_data = get_prompt_for_document_type(document_type)
        
        if not prompt_data.get("success"):
            return {
                "success": False,
                "error": f"Prompt f√ºr {document_type} konnte nicht geladen werden",
                "timestamp": datetime.utcnow().isoformat() + "Z"
            }
        
        # Erstelle zus√§tzliche Best√§tigung
        confirmation_hash = hashlib.sha256(
            f"{prompt_data['hash']}:{prompt_data['version']}:{datetime.utcnow().isoformat()}".encode('utf-8')
        ).hexdigest()[:16]
        
        return {
            "success": True,
            "prompt_confirmation": {
                "document_type": document_type,
                "prompt_version": prompt_data["version"],
                "prompt_hash": prompt_data["hash"],
                "confirmation_hash": confirmation_hash,
                "metadata": prompt_data["metadata"],
                "audit_info": prompt_data["audit_info"],
                "verification": {
                    "hash_verified": True,
                    "version_verified": True,
                    "prompt_loaded_successfully": True,
                    "confirmation_timestamp": datetime.utcnow().isoformat() + "Z"
                }
            },
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Fehler bei Prompt-Best√§tigung: {str(e)}",
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }

@app.get("/api/documents/{document_id}", response_model=Document, tags=["Documents"])
async def get_document(document_id: int, db: Session = Depends(get_db)):
    """
    Ein spezifisches Dokument abrufen.
    
    L√§dt ein einzelnes Dokument mit allen Details f√ºr die Dokumentanzeige.
    
    Args:
        document_id (int): Eindeutige ID des Dokuments
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Document: Detaillierte Dokumentinformationen
        
    Example Response:
        ```json
        {
            "id": 5,
            "title": "Risikoanalyse - Herzschrittmacher Modell XYZ",
            "document_type": "RISK_ASSESSMENT",
            "description": "ISO 14971 konforme Risikoanalyse f√ºr das Herzschrittmacher-System",
            "version": "1.0",
            "status": "APPROVED",
            "file_path": "/documents/risk-assessment-pacemaker-xyz-v1.0.pdf",
            "created_by": 5,
            "approved_by": 2,
            "created_at": "2024-01-12T11:45:00Z",
            "approved_at": "2024-01-25T09:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Dokument nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Enth√§lt alle Metadaten des Dokuments
        - file_path f√ºr Datei-Download
        - Audit-Trail durch created_by und approved_by
    """
    document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Dokument mit ID {document_id} nicht gefunden"
        )
    return document

# === DOKUMENT-VORSCHAU ENDPOINT ===

@app.post("/api/documents/preview", tags=["Documents"])
async def preview_document_processing(
    upload_method: str = Form("ocr"),
    document_type: str = Form("OTHER"),
    file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """
    Vorschau der Dokumentverarbeitung ohne finale Speicherung.
    
    Zeigt die Ergebnisse der OCR- oder Visio-Verarbeitung zur √úberpr√ºfung
    vor der finalen Freigabe und Indexierung.
    
    Args:
        upload_method: Verarbeitungsmethode - "ocr" oder "visio"
        document_type: Dokumenttyp f√ºr kontextspezifische Verarbeitung
        file: Upload-Datei
        
    Returns:
        Vorschau-Daten je nach Methode:
        - OCR: Extrahierter Text, erkannte Metadaten
        - Visio: Bilder, Wortliste, strukturierte Analyse, Validierung
    """
    try:
        upload_logger.info(f"üëÅÔ∏è Dokument-Vorschau: method={upload_method}, type={document_type}, file={file.filename}")
        
        # Validiere Upload-Methode
        if upload_method not in ['ocr', 'visio', 'multi-visio']:
            raise HTTPException(status_code=400, detail=f"Ung√ºltige Upload-Methode: {upload_method}")
        
        # Tempor√§re Datei speichern
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_path = Path(tmp_file.name)
        
        try:
            if upload_method == "ocr":
                # === OCR-VORSCHAU ===
                # Text extrahieren
                mime_type = file.content_type or "application/octet-stream"
                extracted_text = extract_text_from_file(tmp_path, mime_type)
                
                # KEIN FALLBACK: OCR-Text wird so verwendet wie er ist
                
                # Metadaten extrahieren (vereinfacht f√ºr Vorschau)
                preview_metadata = {
                    "text_length": len(extracted_text),
                    "estimated_pages": len(extracted_text) // 3000 + 1,
                    "has_content": len(extracted_text.strip()) > 50,
                    "preview_text": extracted_text[:2000] + "..." if len(extracted_text) > 2000 else extracted_text
                }
                
                # Kapitel und Abschnitte erkennen
                chapters = re.findall(r'^\d+\.?\d*\s+[A-Z].*$', extracted_text, re.MULTILINE)
                if chapters:
                    preview_metadata["detected_chapters"] = chapters[:10]  # Erste 10 Kapitel
                
                return {
                    "upload_method": "ocr",
                    "success": True,
                    "extracted_text": extracted_text,
                    "metadata": preview_metadata,
                    "message": "OCR-Verarbeitung erfolgreich. Bitte √ºberpr√ºfen Sie den extrahierten Text."
                }
                
            elif upload_method == "visio":
                # === VISIO-VORSCHAU ===
                from .vision_ocr_engine import VisionOCREngine
                from .visio_prompts import get_prompt_for_document_type
                
                vision_engine = VisionOCREngine()
                
                # 1. Prompts laden (direkt aus visio_prompts Ordner)
                prompt_data = get_prompt_for_document_type(document_type)
                prompt1 = prompt_data["prompt"]
                
                # 2. Zu Bildern konvertieren (MIT CACHING - SCHNELLE PNG-VORSCHAU)
                logger.info(f"üñºÔ∏è Erstelle PNG-Vorschau f√ºr {file.filename}")
                
                # ‚úÖ NEU: Verwende Cached Image Conversion f√ºr bessere Performance
                images = await vision_engine._get_or_convert_images(tmp_path)
                if not images:
                    raise HTTPException(status_code=500, detail="Dokument konnte nicht zu PNG konvertiert werden")
                
                # PNG-Vorschau erstellen (erste Seite)
                preview_image = None
                if images:
                    preview_image = base64.b64encode(images[0]).decode('utf-8')
                    logger.info(f"‚úÖ PNG-Vorschau erstellt: {len(images[0])} Bytes")
                
                # NEU: Vereinfachte R√ºckgabe - nur PNG-Vorschau
                return {
                    "upload_method": "visio",
                    "success": True,
                    "preview_image": preview_image,
                    "page_count": len(images),
                    "message": "PNG-Vorschau erfolgreich erstellt (OpenAI API-Aufrufe deaktiviert)",
                    "workflow_status": {
                        "step1_png_preview": "completed",
                        "step2_word_extraction": "disabled",
                        "step3_structured_analysis": "disabled"
                    },
                    "debug_info": {
                        "file_size_bytes": len(content),
                        "png_size_bytes": len(images[0]) if images else 0,
                        "pages_converted": len(images),
                        "timestamp": datetime.now().isoformat()
                    }
                }
                
                # Initialisiere Validierung
                validation = {
                    "status": "PENDING",
                    "coverage": 0,
                    "missing_words": [],
                    "total_missing": 0,
                    "validation_details": {}
                }
                
            elif upload_method == "multi-visio":
                # === MULTI-VISIO-VORSCHAU ===
                from .multi_visio_engine import MultiVisioEngine
                
                # Multi-Visio Engine initialisieren
                multi_visio_engine = MultiVisioEngine()
                
                # 1. Prompts f√ºr alle 5 Stufen laden (mit korrekten Keys)
                prompts = {
                    "expert_induction": multi_visio_engine.prompts.get("context_setup", ""),
                    "structured_analysis": multi_visio_engine.prompts.get("structured_analysis", ""),
                    "word_coverage": multi_visio_engine.prompts.get("text_extraction", ""),
                    "norm_compliance": multi_visio_engine.prompts.get("norm_compliance", "")
                }
                
                # Debug: Prompt-L√§ngen f√ºr Audit Trail
                logger.info(f"üîç MULTI-VISIO PROMPT AUDIT:")
                for key, prompt_content in prompts.items():
                    logger.info(f"   {key}: {len(prompt_content)} Zeichen")
                    if key == "structured_analysis":
                        logger.info(f"   üìù Structured Analysis Vorschau: {prompt_content[:100]}...")
                
                # Verifiziere dass ein g√ºltiger Analyse-Prompt geladen wurde (versionsunabh√§ngig)
                if len(prompts["structured_analysis"]) > 0:
                    # Inhaltsbezogene Validierung statt hardcodierte Version
                    has_system_role = "System:" in prompts["structured_analysis"]
                    has_json_schema = "process_steps" in prompts["structured_analysis"]
                    has_iso_reference = "ISO 13485" in prompts["structured_analysis"]
                    
                    if has_system_role and has_json_schema and has_iso_reference:
                        logger.info(f"‚úÖ G√ºltiger Multi-Visio Analyse-Prompt geladen ({len(prompts['structured_analysis'])} Zeichen)")
                        logger.info(f"üîç Inhaltspr√ºfung: System-Rolle ‚úì, JSON-Schema ‚úì, ISO-Referenz ‚úì")
                    else:
                        logger.warning(f"‚ö†Ô∏è Prompt-Inhalt unvollst√§ndig: System={has_system_role}, JSON={has_json_schema}, ISO={has_iso_reference}")
                else:
                    logger.error("‚ùå Structured_analysis Prompt ist leer!")
                
                # 2. Zu Bildern konvertieren (PNG-Vorschau)
                from .vision_ocr_engine import VisionOCREngine
                vision_engine = VisionOCREngine()
                
                logger.info(f"üñºÔ∏è Erstelle PNG-Vorschau f√ºr Multi-Visio: {file.filename}")
                images = await vision_engine._get_or_convert_images(tmp_path)
                if not images:
                    raise HTTPException(status_code=500, detail="Dokument konnte nicht zu PNG konvertiert werden")
                
                # PNG-Vorschau erstellen (erste Seite)
                preview_image = None
                if images:
                    preview_image = base64.b64encode(images[0]).decode('utf-8')
                    logger.info(f"‚úÖ PNG-Vorschau f√ºr Multi-Visio erstellt: {len(images[0])} Bytes")
                
                # 3. Multi-Visio Workflow-Status mit Audit Trail
                workflow_status = {
                    "step1_expert_induction": {
                        "status": "pending",
                        "description": "Experten-Einweisung des KI-Modells",
                        "prompt_preview": prompts["expert_induction"][:300] + "..." if len(prompts["expert_induction"]) > 300 else prompts["expert_induction"],
                        "prompt_length": len(prompts["expert_induction"]),
                        "prompt_source": "01_expert_induction.txt"
                    },
                    "step2_structured_analysis": {
                        "status": "pending", 
                        "description": f"Strukturierte JSON-Analyse f√ºr {document_type}",
                        "prompt_preview": prompts["structured_analysis"][:300] + "..." if len(prompts["structured_analysis"]) > 300 else prompts["structured_analysis"],
                        "prompt_length": len(prompts["structured_analysis"]),
                        "prompt_source": "02_structured_analysis.txt",
                        "audit_validation": len(prompts["structured_analysis"]) > 1000 and "System:" in prompts["structured_analysis"]
                    },
                    "step3_word_coverage_validation": {
                        "status": "pending",
                        "description": "Zweistufige Wortextraktion (LLM + OCR)",
                        "prompt_preview": prompts["word_coverage"][:300] + "..." if len(prompts["word_coverage"]) > 300 else prompts["word_coverage"],
                        "prompt_length": len(prompts["word_coverage"]),
                        "prompt_source": "03_word_coverage.txt"
                    },
                    "step4_verification": {
                        "status": "pending",
                        "description": "Backend-Verifikation (JSON vs. W√∂rter)",
                        "prompt_preview": "Backend-Logik: Fuzzy-Matching zwischen strukturierter JSON und extrahierten W√∂rtern",
                        "prompt_length": 0,
                        "prompt_source": "Backend-Algorithmus"
                    },
                    "step5_norm_compliance_check": {
                        "status": "pending",
                        "description": "Normkonformit√§ts-Check (ISO 13485 + MDR)",
                        "prompt_preview": prompts["norm_compliance"][:300] + "..." if len(prompts["norm_compliance"]) > 300 else prompts["norm_compliance"],
                        "prompt_length": len(prompts["norm_compliance"]),
                        "prompt_source": "05_norm_compliance.txt"
                    }
                }
                
                return {
                    "upload_method": "multi-visio",
                    "success": True,
                    "preview_image": preview_image,
                    "page_count": len(images),
                    "message": "Multi-Visio 4-Stufen-Pipeline vorbereitet",
                    "workflow_status": workflow_status,
                    "pipeline_info": {
                        "total_stages": 4,
                        "estimated_processing_time": "2-5 Minuten",
                        "features": [
                            "Experten-Einweisung f√ºr QM-Kontext",
                            "Strukturierte JSON-Analyse",
                            "Wortabdeckungs-Validierung (80% Mindestabdeckung)",
                            "ISO 13485 + MDR Compliance-Check"
                        ],
                        "validation_requirements": {
                            "word_coverage_minimum": "80%",
                            "compliance_check": "ISO 13485 + MDR",
                            "quality_threshold": "Hoch"
                        }
                    },
                    "debug_info": {
                        "file_size_bytes": len(content),
                        "png_size_bytes": len(images[0]) if images else 0,
                        "pages_converted": len(images),
                        "prompts_loaded": len(prompts),
                        "timestamp": datetime.now().isoformat()
                    }
                }
                
        finally:
            # Tempor√§re Datei l√∂schen
            tmp_path.unlink(missing_ok=True)
            
    except HTTPException:
        raise
    except Exception as e:
        upload_logger.error(f"‚ùå Vorschau-Fehler: {e}")
        raise HTTPException(status_code=500, detail=f"Vorschau-Verarbeitung fehlgeschlagen: {str(e)}")

@app.post("/api/documents/process-with-prompt", tags=["Documents"])
async def process_document_with_prompt(
    upload_method: str = Form("visio"),
    document_type: str = Form("SOP"),
    file: UploadFile = File(...),
    confirm_prompt: bool = Form(False),  # Best√§tigung f√ºr Prompt-Ausf√ºhrung
    preferred_provider: str = Form("auto"),  # NEU: Provider-Auswahl
    exact_prompt: Optional[str] = Form(None),  # NEU: Exakter Prompt vom Frontend
    db: Session = Depends(get_db)
):
    """
    üöÄ OPTIMIERTER WORKFLOW mit vollst√§ndiger Transparenz
    
    NEUE FEATURES:
    - ‚úÖ API-Verbindungstest vor dem Aufruf
    - ‚úÖ Detailliertes Logging aller Schritte
    - ‚úÖ Robusteres JSON-Parsing mit Fallback
    - ‚úÖ Transparente Workflow-Schritte
    - ‚úÖ 95% Wortabdeckungs-Validierung
    - ‚úÖ Vollst√§ndiger Audit-Trail
    """
    upload_logger = logging.getLogger("document_upload")
    upload_logger.info(f"üöÄ Optimierter Workflow gestartet: {file.filename}")
    
    try:
        # 1. Datei tempor√§r speichern
        file_extension = file.filename.split('.')[-1] if '.' in file.filename else 'txt'
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_extension}") as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_path = Path(tmp_file.name)
        
        try:
            # 2. Vision Engine initialisieren
            vision_engine = VisionOCREngine()
            
            # 3. AI Provider Status pr√ºfen (verwendet bew√§hrte ai_engine.py Logik)
            upload_logger.info("üîç Pr√ºfe AI Provider Status...")
            from .ai_engine import ai_engine
            
            # Verf√ºgbare Provider pr√ºfen
            available_providers = []
            for provider_name, provider in ai_engine.ai_providers.items():
                try:
                    if hasattr(provider, 'is_available'):
                        available = await provider.is_available()
                        if available:
                            available_providers.append(provider_name)
                            upload_logger.info(f"‚úÖ Provider verf√ºgbar: {provider_name}")
                        else:
                            upload_logger.warning(f"‚ö†Ô∏è Provider nicht verf√ºgbar: {provider_name}")
                except Exception as e:
                    upload_logger.warning(f"‚ö†Ô∏è Provider-Test fehlgeschlagen f√ºr {provider_name}: {e}")
            
            # Rule-based Provider ist immer verf√ºgbar
            available_providers.append("rule_based")
            
            if not available_providers:
                raise HTTPException(
                    status_code=500, 
                    detail="Keine AI Provider verf√ºgbar. Bitte konfigurieren Sie mindestens einen Provider."
                )
            
            upload_logger.info(f"‚úÖ AI Provider Status gepr√ºft: {available_providers}")
            
            # API-Test-Ergebnis f√ºr Frontend
            api_test_result = {
                "success": True,
                "status": "providers_available",
                "available_providers": available_providers,
                "message": f"AI Provider verf√ºgbar: {', '.join(available_providers)}"
            }
            
            # 4. PNG-Vorschau erstellen
            upload_logger.info("üñºÔ∏è Erstelle PNG-Vorschau...")
            
            # Pr√ºfe Dateityp
            file_extension = file.filename.lower().split('.')[-1] if '.' in file.filename else 'txt'
            is_image = file_extension in ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff']
            
            if is_image:
                # F√ºr Bild-Dateien: Direkt verwenden
                with open(tmp_path, 'rb') as f:
                    image_bytes = f.read()
                images = [image_bytes]
                upload_logger.info(f"‚úÖ Bild-Datei direkt verwendet: {len(image_bytes)} Bytes")
            else:
                # F√ºr Dokumente: Konvertieren (mit Caching)
                images = await vision_engine._get_or_convert_images(tmp_path)
                if not images:
                    raise HTTPException(status_code=500, detail="Keine Bilder erstellt")
                upload_logger.info(f"‚úÖ Dokument konvertiert: {len(images)} Bilder")
            
            # Base64 f√ºr Vorschau - korrektes Format f√ºr Frontend
            preview_image = f"data:image/png;base64,{base64.b64encode(images[0]).decode('utf-8')}"
            upload_logger.info(f"‚úÖ PNG-Vorschau erstellt: {len(images[0])} Bytes")
            
            # üéØ NEU: PNG-Metadaten speichern (erstes Bild)
            if images and len(images) > 0:
                # ‚úÖ KORRIGIERT: PNG-Datei physisch speichern
                import os
                
                # Erstelle PNG-Dateiname basierend auf Original-Dokument
                original_filename = Path(upload_result.file_path).stem
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                png_filename = f"{timestamp}_{original_filename}_preview.png"
                
                # Speichere PNG im uploads Ordner mit Dokumenttyp-Unterordner
                uploads_dir = get_uploads_dir() / document_type
                png_path_local = uploads_dir / png_filename
                
                # Stelle sicher, dass der uploads Ordner existiert
                uploads_dir.mkdir(exist_ok=True, parents=True)
                
                # Speichere PNG-Bytes als Datei
                with open(png_path_local, 'wb') as png_file:
                    png_file.write(images[0])
                
                # Setze PNG-Metadaten f√ºr Datenbank
                png_preview_path = str(png_path_local)
                png_preview_size = png_path_local.stat().st_size
                png_generation_timestamp = datetime.now()
                png_generation_method = "vision_engine_convert"
                
                # PNG-Hash berechnen
                png_preview_hash = hashlib.sha256(images[0]).hexdigest()
                
                upload_logger.info(f"‚úÖ PNG-Vorschau gespeichert: {png_preview_path} ({png_preview_size} Bytes)")
                
                # Wichtig: Variablen wurden gesetzt f√ºr Datenbank-Speicherung
            
            # 5. PROMPT-SICHERHEIT: Verwende exakten Prompt vom Frontend oder lade aus zentraler Verwaltung
            if exact_prompt:
                # ‚úÖ PROMPT-SICHERHEIT: Verwende den exakten Prompt vom Frontend
                prompt1 = exact_prompt
                upload_logger.info(f"üîí PROMPT-SICHERHEIT: Verwende exakten Prompt vom Frontend: {len(prompt1)} Zeichen")
                upload_logger.info(f"üìù DOKUMENTTYP: {document_type}")
            else:
                # Fallback: Direkte Prompt-Verwaltung verwenden
                from .visio_prompts import get_prompt_for_document_type
                prompt_data = get_prompt_for_document_type(document_type)
                prompt1 = prompt_data["prompt"]
                upload_logger.info(f"üìù Zentrale Prompts geladen f√ºr {document_type}: {len(prompt1)} Zeichen")
            
            # 6. Wenn keine Best√§tigung: Nur Vorschau + Prompt zur√ºckgeben
            if not confirm_prompt:
                return {
                    "upload_method": "visio",
                    "success": True,
                    "preview_image": preview_image,
                    "page_count": len(images),
                    "prompt_to_use": prompt1,  # Einheitlicher Prompt
                    "prompt_source": "frontend_exact" if exact_prompt else "central_management",  # NEU: Prompt-Herkunft
                    "message": "PNG-Vorschau erstellt. Bitte best√§tigen Sie die Prompt-Ausf√ºhrung.",
                    "workflow_status": {
                        "step1_png_preview": "completed",
                        "step2_api_connection_test": "completed",
                        "step3_prompt_confirmation": "pending",
                        "step4_api_call": "pending",
                        "step5_validation": "pending"
                    },
                    "api_connection_status": api_test_result,
                    "next_step": "confirm_prompt=true f√ºr API-Aufruf"
                }
            
            # 7. Wenn best√§tigt: Vision API-Aufruf mit Provider-Auswahl
            upload_logger.info(f"üöÄ F√ºhre Vision API-Aufruf mit Provider '{preferred_provider}' aus")
            
            # Verwende Vision Engine mit Provider-Auswahl
            upload_logger.info(f"üì° Sende PNG-Bild an Vision API: {preferred_provider}")
            
            # ZENTRALE VISION-ANALYSE: Verwende NUR die API-Prompt-Funktion - KEIN FALLBACK!
            analysis_result = await vision_engine.analyze_document_with_api_prompt(
                images=images,
                document_type=document_type,
                preferred_provider=preferred_provider
            )
            
            # Logge Prompt-Best√§tigung f√ºr Audit
            if analysis_result.get('success') and 'prompt_confirmation' in analysis_result:
                prompt_conf = analysis_result['prompt_confirmation']
                upload_logger.info(f"üîê PROMPT-BEST√ÑTIGUNG F√úR AUDIT:")
                upload_logger.info(f"   Dokumenttyp: {prompt_conf.get('prompt_metadata', {}).get('document_type')}")
                upload_logger.info(f"   Version: {prompt_conf.get('prompt_version')}")
                upload_logger.info(f"   Hash: {prompt_conf.get('prompt_hash')}")
                upload_logger.info(f"   L√§nge: {prompt_conf.get('prompt_metadata', {}).get('prompt_length')} Zeichen")
                upload_logger.info(f"   Verifiziert: {prompt_conf.get('prompt_verification', {}).get('hash_verified')}")
            
            # Provider-Info hinzuf√ºgen
            analysis_result['provider'] = preferred_provider
            analysis_result['enhanced'] = True
            
            # üîß WICHTIG: Die Vision API gibt bereits das perfekte JSON zur√ºck!
            # KEINE weitere Verpackung in content-Feld!
            # Die Vision API gibt direkt das gew√ºnschte JSON zur√ºck
            if not analysis_result.get('success', True):
                # Fehler bei der Analyse
                analysis_result = {
                    'success': False,
                    'error': analysis_result.get('error', 'Unbekannter Fehler'),
                    'provider': analysis_result.get('provider', 'unknown')
                }
            else:
                # ‚úÖ Erfolgreiche Vision API-Antwort - direkt verwenden!
                # Die Vision API gibt bereits das perfekte JSON zur√ºck
                # KEINE weitere Verpackung in content-Feld!
                upload_logger.info(f"‚úÖ Vision API erfolgreich: {len(str(analysis_result))} Zeichen")
            
            if not analysis_result or not analysis_result.get('success'):
                error_msg = analysis_result.get('error', 'Unbekannter Fehler') if analysis_result else 'Keine Antwort erhalten'
                upload_logger.error(f"‚ùå API-Analyse fehlgeschlagen: {error_msg}")
                raise HTTPException(
                    status_code=500, 
                    detail=f"API-Analyse fehlgeschlagen: {error_msg}"
                )
            
            upload_logger.info("‚úÖ API-Antwort erfolgreich erhalten")
            
            # 8. Robusteres JSON-Parsing mit Fallback
            upload_logger.info("üîç Parse JSON-Antwort...")
            
            # Bei PROMPT_TEST: Gib strukturierte JSON zur√ºck (wie bei anderen Dokumenttypen)
            if document_type == "PROMPT_TEST":
                upload_logger.info("üîß PROMPT_TEST-Modus: Verwende direkte Vision API-Antwort")
                
                # ‚úÖ REINE KI-ANTWORT: Verwende NUR die originale KI-Antwort ohne Verpackung!
                # Die Vision Engine gibt die KI-Antwort im 'content' Feld zur√ºck
                if 'content' in analysis_result:
                    # Das ist die REINE, UNVER√ÑNDERTE KI-Antwort
                    raw_ki_response = analysis_result['content']
                    upload_logger.info(f"‚úÖ REINE KI-ANTWORT erhalten: {len(raw_ki_response)} Zeichen")
                    
                    # Versuche JSON-Parsing der KI-Antwort
                    try:
                        import json
                        # Entferne Markdown-Wrapper falls vorhanden
                        cleaned_response = raw_ki_response.strip()
                        if cleaned_response.startswith('```json'):
                            cleaned_response = cleaned_response[7:]
                        if cleaned_response.endswith('```'):
                            cleaned_response = cleaned_response[:-3]
                        
                        structured_data = json.loads(cleaned_response)
                        upload_logger.info(f"‚úÖ KI-Antwort erfolgreich als JSON geparst: {len(str(structured_data))} Zeichen")
                    except json.JSONDecodeError as e:
                        upload_logger.warning(f"‚ö†Ô∏è KI-Antwort ist kein g√ºltiges JSON: {e}")
                        # Fallback: Verwende die rohe KI-Antwort als String
                        structured_data = {
                            "raw_ki_response": raw_ki_response,
                            "parsing_error": str(e)
                        }
                else:
                    # Fallback: Verwende das gesamte Ergebnis
                    structured_data = analysis_result
                    upload_logger.info(f"‚úÖ Fallback: Verwende gesamtes Vision Engine Ergebnis: {len(str(structured_data))} Zeichen")
                
                # Wortliste extrahieren
                detected_words = structured_data.get('all_detected_words', [])
                
                # Validierung f√ºr PROMPT_TEST
                validation = {
                    "word_coverage": "PROMPT_TEST_validierung",
                    "coverage_percentage": 100.0,
                    "missing_words": [],
                    "validation_skipped": True,
                    "test_mode": True
                }
                
                # Workflow-Schritte f√ºr PROMPT_TEST
                workflow_steps = {
                    "step1_png_preview": {
                        "status": "completed",
                        "details": f"PNG erstellt: {len(images[0])} Bytes",
                        "timestamp": datetime.now().isoformat()
                    },
                    "step2_api_connection_test": {
                        "status": "completed",
                        "details": f"API-Verbindung getestet: {api_test_result.get('status', 'unknown')}",
                        "timestamp": datetime.now().isoformat()
                    },
                    "step3_unified_api_call": {
                        "prompt": prompt1,
                        "status": "completed",
                        "details": f"PROMPT_TEST API-Aufruf erfolgreich mit Provider '{analysis_result.get('provider', 'unknown')}': {len(str(structured_data))} Zeichen",
                        "timestamp": datetime.now().isoformat()
                    },
                    "step4_validation": {
                        "status": "completed",
                        "details": "PROMPT_TEST Validierung abgeschlossen",
                        "timestamp": datetime.now().isoformat()
                    }
                }
                
                # Audit-Trail f√ºr PROMPT_TEST
                audit_trail = {
                    "workflow_start": datetime.now().isoformat(),
                    "document_filename": file.filename,
                    "upload_method": "visio",
                    "document_type": "PROMPT_TEST",
                    "unified_prompt_used": True,
                    "api_calls_count": 1,
                    "validation_coverage": 100.0,
                    "workflow_completed": True,
                    "api_connection_tested": True,
                    "json_parsing_successful": True,
                    "test_mode": True
                }
                
                # ‚úÖ REINE KI-ANTWORT: Entpacke mehrfach serialisiertes JSON!
                # Das Ziel: Ein sauberes JSON-Objekt ohne String-Wrapper
                if isinstance(structured_data, dict):
                    # Entpacke das 'analysis' Feld falls es ein String ist
                    if 'analysis' in structured_data and isinstance(structured_data['analysis'], str):
                        try:
                            import json
                            # Erste Ebene: analysis String zu JSON
                            analysis_json = json.loads(structured_data['analysis'])
                            upload_logger.info(f"‚úÖ Analysis-Feld entpackt: {len(str(analysis_json))} Zeichen")
                            
                            # Entferne redundante Felder
                            cleaned_response = analysis_json.copy()
                            if 'content' in cleaned_response:
                                del cleaned_response['content']  # Redundant entfernen
                            if 'context' in cleaned_response:
                                del cleaned_response['context']  # Prompt entfernen
                            
                            upload_logger.info(f"‚úÖ SAUBERE KI-ANTWORT: {len(str(cleaned_response))} Zeichen")
                            return {
                                "success": True,
                                "raw_ki_response": cleaned_response,  # ECHTES JSON-OBJEKT
                                "message": "SAUBERE KI-ANTWORT ohne String-Wrapper"
                            }
                        except json.JSONDecodeError as e:
                            upload_logger.error(f"‚ùå Analysis-Feld JSON-Parsing fehlgeschlagen: {e}")
                            # Fallback: Verwende das urspr√ºngliche structured_data
                            pass
                    
                    # Falls kein 'analysis' Feld oder bereits geparst
                    # Entferne redundante Felder
                    cleaned_response = structured_data.copy()
                    if 'content' in cleaned_response:
                        del cleaned_response['content']  # Redundant entfernen
                    if 'context' in cleaned_response:
                        del cleaned_response['context']  # Prompt entfernen
                    if 'success' in cleaned_response:
                        del cleaned_response['success']  # Backend-Feld entfernen
                    
                    upload_logger.info(f"‚úÖ SAUBERE KI-ANTWORT: {len(str(cleaned_response))} Zeichen")
                    return {
                        "success": True,
                        "raw_ki_response": cleaned_response,  # ECHTES JSON-OBJEKT
                        "message": "SAUBERE KI-ANTWORT ohne String-Wrapper"
                    }
                else:
                    # Falls es ein String ist, versuche es zu parsen
                    try:
                        import json
                        parsed_json = json.loads(str(structured_data))
                        upload_logger.info(f"‚úÖ String zu JSON geparst: {len(str(parsed_json))} Zeichen")
                        return {
                            "success": True,
                            "raw_ki_response": parsed_json,  # ECHTES JSON-OBJEKT
                            "message": "SAUBERE KI-ANTWORT ohne String-Wrapper"
                        }
                    except json.JSONDecodeError as e:
                        upload_logger.error(f"‚ùå String-JSON-Parsing fehlgeschlagen: {e}")
                        return {
                            "success": False,
                            "error": f"KI-Antwort ist kein g√ºltiges JSON: {e}",
                            "raw_content": str(structured_data)[:500] + "..." if len(str(structured_data)) > 500 else str(structured_data)
                        }
            
            # üîß WICHTIG: Die Vision API gibt direkt das perfekte JSON zur√ºck!
            # analysis_result ist bereits das gew√ºnschte JSON-Objekt
            try:
                if isinstance(analysis_result, dict) and 'document_metadata' in analysis_result:
                    structured_data = analysis_result
                    upload_logger.info(f"‚úÖ Vision API JSON direkt verwendet: {len(str(structured_data))} Zeichen")
                elif isinstance(analysis_result, dict) and 'analysis' in analysis_result:
                    # Das ist die korrekte Vision API-Antwort
                    structured_data = analysis_result['analysis']
                    upload_logger.info(f"‚úÖ Vision API JSON aus analysis-Feld: {len(str(structured_data))} Zeichen")
                else:
                    upload_logger.error(f"‚ùå Unbekannte API-Antwort: {type(analysis_result)}")
                    upload_logger.error(f"‚ùå Inhalt: {str(analysis_result)[:200]}...")
                    raise HTTPException(
                        status_code=500, 
                        detail="Unbekannte API-Antwort - Vision API nicht verwendet"
                    )
                    
            except Exception as e:
                upload_logger.error(f"‚ùå Verarbeitung fehlgeschlagen: {e}")
                raise HTTPException(
                    status_code=500, 
                    detail=f"Verarbeitung fehlgeschlagen: {e}"
                )
            
            upload_logger.info(f"‚úÖ JSON erfolgreich geparst: {len(str(structured_data))} Zeichen")
            
            # ‚úÖ EINFACHER WORKFLOW: Keine Wortliste mehr
            upload_logger.info("‚úÖ Strukturierte Analyse erfolgreich abgeschlossen")
            
            # 10. Validierung √ºbersprungen (wie gew√ºnscht)
            validation = {
                "word_coverage": "validierung_√ºbersprungen",
                "coverage_percentage": 100.0,
                "missing_words": [],
                "validation_skipped": True
            }
            
            # 11. Workflow-Schritte dokumentieren
            workflow_steps = {
                "step1_png_preview": {
                    "status": "completed",
                    "details": f"PNG erstellt: {len(images[0])} Bytes",
                    "timestamp": datetime.now().isoformat()
                },
                "step2_api_connection_test": {
                    "status": "completed",
                    "details": f"API-Verbindung getestet: {api_test_result.get('status', 'unknown')}",
                    "timestamp": datetime.now().isoformat()
                },
                "step3_unified_api_call": {
                    "prompt": prompt1,
                    "status": "completed",
                    "details": f"API-Aufruf erfolgreich mit Provider '{analysis_result.get('provider', 'unknown')}': {len(str(structured_data))} Zeichen JSON",
                    "timestamp": datetime.now().isoformat()
                },
                "step4_validation": {
                    "status": "completed",
                    "details": f"Validierung √ºbersprungen: {validation.get('coverage_percentage', 100.0):.1f}%",
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            # 12. Audit-Trail
            audit_trail = {
                "workflow_start": datetime.now().isoformat(),
                "document_filename": file.filename,
                "upload_method": "visio",
                "document_type": document_type,
                "unified_prompt_used": True,
                "api_calls_count": 1,  # Nur ein API-Aufruf!
                "validation_coverage": validation.get("coverage_percentage", 100.0),
                "workflow_completed": True,
                "api_connection_tested": True,
                "json_parsing_successful": True
            }
            
            # 13. R√ºckgabe-Response
            return {
                "upload_method": "visio",
                "success": True,
                "preview_image": preview_image,
                "page_count": len(images),
                "structured_analysis": structured_data,
                "validation": validation,
                "workflow_steps": workflow_steps,
                "audit_trail": audit_trail,
                "api_connection_status": api_test_result,
                "debug_info": {
                    "api_calls": 1,
                    "png_size_bytes": len(images[0]) if images else 0,
                    "validation_coverage": validation.get("coverage_percentage", 100.0),
                    "timestamp": datetime.now().isoformat()
                },
                "message": "Optimierter Workflow erfolgreich abgeschlossen",
                "transparency_info": {
                    "unified_prompt_used": True,
                    "single_api_call": True,
                    "full_audit_trail": True,
                    "api_connection_tested": True,
                    "provider_used": analysis_result.get('provider', 'unknown'),
                    "available_providers": api_test_result.get('available_providers', [])
                },
                "version": "1.0"  # Korrekte Version f√ºr Schema-Validierung
            }
            
        finally:
            # Tempor√§re Datei l√∂schen
            try:
                if 'tmp_path' in locals():
                    tmp_path.unlink()
            except Exception as cleanup_error:
                upload_logger.warning(f"‚ö†Ô∏è Cleanup-Fehler: {cleanup_error}")
                
    except Exception as e:
        upload_logger.error(f"‚ùå Optimierter Workflow fehlgeschlagen: {e}")
        raise HTTPException(status_code=500, detail=f"Workflow-Fehler: {str(e)}")



async def _parse_json_response_robust(content: str) -> Optional[Dict[str, Any]]:
    """
    üîß Robusteres JSON-Parsing f√ºr DOPPELT VERSCHACHTELTE API-Antworten
    
    Args:
        content: Rohe API-Antwort (kann doppelt verschachtelt sein)
        
    Returns:
        Geparste JSON-Daten oder None
    """
    import re
    import json
    logger = logging.getLogger("json_parser")
    
    logger.info("üîç JSON-Parsing: Robuste Verarbeitung f√ºr doppelt verschachtelte Antworten")
    cleaned_content = content.strip()
    
    # Entferne Markdown-Formatierung
    if cleaned_content.startswith('```json'):
        cleaned_content = cleaned_content[7:]
    if cleaned_content.endswith('```'):
        cleaned_content = cleaned_content[:-3]
    
    # Entferne Kommentare und zus√§tzlichen Text
    cleaned_content = re.sub(r'//.*$', '', cleaned_content, flags=re.MULTILINE)
    cleaned_content = re.sub(r'#.*$', '', cleaned_content, flags=re.MULTILINE)
    
    # Entferne ung√ºltige Steuerzeichen (Control Characters)
    cleaned_content = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', cleaned_content)
    
    # üîß LEVEL 1: Versuche direktes JSON-Parsing (f√ºr einfache Antworten)
    try:
        result = json.loads(cleaned_content)
        logger.info(f"‚úÖ Level 1 erfolgreich - direktes JSON-Parsing: {len(cleaned_content)} Zeichen")
        return result
    except json.JSONDecodeError as e:
        logger.warning(f"‚ö†Ô∏è Level 1 fehlgeschlagen: {e}")
    
    # üîß LEVEL 2: Pr√ºfe auf doppelt verschachtelte Antwort
    try:
        # Versuche das √§u√üere JSON zu parsen
        outer_json = json.loads(cleaned_content)
        logger.info(f"‚úÖ Level 2 - √Ñu√üeres JSON geparst: {len(str(outer_json))} Zeichen")
        
        # Suche nach dem 'content' Feld
        if 'content' in outer_json and isinstance(outer_json['content'], str):
            inner_content = outer_json['content']
            logger.info(f"üîç Level 2 - Inneres content gefunden: {len(inner_content)} Zeichen")
            
            # Versuche das innere JSON zu parsen
            inner_result = json.loads(inner_content)
            logger.info(f"‚úÖ Level 2 erfolgreich - Inneres JSON geparst: {len(str(inner_result))} Zeichen")
            return inner_result
            
    except json.JSONDecodeError as e:
        logger.warning(f"‚ö†Ô∏è Level 2 fehlgeschlagen: {e}")
    
    # üîß LEVEL 3: Fallback - Suche nach dem gr√∂√üten g√ºltigen JSON-Objekt
    try:
        logger.info("üîç Level 3 - Suche nach gr√∂√ütem g√ºltigen JSON-Objekt")
        json_objects = []
        stack = []
        start = -1
        
        for i, char in enumerate(cleaned_content):
            if char == '{':
                if not stack:
                    start = i
                stack.append(char)
            elif char == '}':
                if stack:
                    stack.pop()
                    if not stack and start != -1:
                        json_str = cleaned_content[start:i+1]
                        try:
                            obj = json.loads(json_str)
                            json_objects.append((len(json_str), obj))
                        except:
                            pass
        
        if json_objects:
            # Verwende das gr√∂√üte g√ºltige JSON-Objekt
            largest_json = max(json_objects, key=lambda x: x[0])
            logger.info(f"‚úÖ Level 3 erfolgreich - Gr√∂√ütes JSON-Objekt: {largest_json[0]} Zeichen")
            return largest_json[1]
            
    except Exception as fallback_error:
        logger.error(f"‚ùå Level 3 fehlgeschlagen: {fallback_error}")
    
    # ‚ùå Alle Level fehlgeschlagen
    logger.error(f"‚ùå JSON-Parsing komplett fehlgeschlagen")
    logger.error(f"‚ùå Inhalt (erste 200 Zeichen): {cleaned_content[:200]}...")
    raise ValueError(f"JSON-Parsing fehlgeschlagen: Alle Parsing-Level fehlgeschlagen")

def _extract_fields_manually(content: str) -> Optional[Dict[str, Any]]:
    """
    üîß Manuelle Extraktion von Feldern aus der API-Antwort mit EINHEITLICHER Struktur
    """
    import re
    import logging
    logger = logging.getLogger("KI-QMS")
    
    try:
        result = {
            "document_metadata": {
                "title": "unknown",
                "document_type": "unknown",
                "version": "unknown",
                "chapter": "unknown",
                "valid_from": "unknown",
                "author": "unknown",
                "approved_by": "unknown"
            },
            "process_steps": [],
            "referenced_documents": [],
            "definitions": [],
            "compliance_requirements": [],
            "critical_rules": [],
            "all_detected_words": []
        }
        
        # Document Metadata extrahieren
        title_match = re.search(r'"title":\s*"([^"]+)"', content)
        if title_match:
            result["document_metadata"]["title"] = title_match.group(1)
        
        type_match = re.search(r'"document_type":\s*"([^"]+)"', content)
        if type_match:
            result["document_metadata"]["document_type"] = type_match.group(1)
        
        version_match = re.search(r'"version":\s*"([^"]+)"', content)
        if version_match:
            result["document_metadata"]["version"] = version_match.group(1)
        
        # W√∂rter extrahieren (Duplikate entfernen)
        words_match = re.search(r'"all_detected_words":\s*\[(.*?)\]', content, re.DOTALL)
        if words_match:
            words_str = words_match.group(1)
            words = re.findall(r'"([^"]+)"', words_str)
            # Duplikate entfernen und alphabetisch sortieren
            result["all_detected_words"] = sorted(list(set(words)))
        
        # Prozessschritte extrahieren (vereinfacht)
        steps_match = re.search(r'"process_steps":\s*\[(.*?)\]', content, re.DOTALL)
        if steps_match:
            # Hier k√∂nnte man komplexere Extraktion implementieren
            result["process_steps"] = []
        
        # Compliance-Anforderungen extrahieren
        compliance_match = re.search(r'"compliance_requirements":\s*\[(.*?)\]', content, re.DOTALL)
        if compliance_match:
            result["compliance_requirements"] = []
        
        # Qualit√§tskontrollen extrahieren
        quality_match = re.search(r'"quality_controls":\s*\[(.*?)\]', content, re.DOTALL)
        if quality_match:
            result["quality_controls"] = []
        
        if result:
            result["manual_extraction"] = True
            return result
            
    except Exception as e:
        logger.warning(f"Manuelle Extraktion fehlgeschlagen: {e}")
    
    return None

async def _validate_word_coverage(detected_words: List[str], structured_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    üìä Echte Wortabdeckungs-Validierung - Backend-Logik statt KI-Prompt
    """
    try:
        # 1. Alle W√∂rter aus der strukturierten JSON-Analyse extrahieren
        json_words = set()
        
        # Rekursiv durch die JSON-Struktur gehen
        def extract_words_from_json(obj):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    if isinstance(value, str):
                        # W√∂rter aus Strings extrahieren
                        words = value.lower().split()
                        json_words.update(words)
                    elif isinstance(value, (dict, list)):
                        extract_words_from_json(value)
            elif isinstance(obj, list):
                for item in obj:
                    extract_words_from_json(item)
        
        extract_words_from_json(structured_data)
        
        # 2. Detected words normalisieren
        detected_words_normalized = set()
        for word in detected_words:
            if isinstance(word, str):
                detected_words_normalized.add(word.lower().strip())
        
        # 3. Wortabdeckung berechnen
        if len(detected_words_normalized) == 0:
            coverage_percentage = 0.0
            missing_words = set()  # Leere Menge wenn keine W√∂rter extrahiert wurden
        else:
            # W√∂rter, die in der JSON-Analyse fehlen
            missing_words = detected_words_normalized - json_words
            coverage_percentage = ((len(detected_words_normalized) - len(missing_words)) / len(detected_words_normalized)) * 100
        
        # 4. Qualit√§tsbewertung (konfigurierbare Schwellen)
        high_threshold = get_quality_threshold("high_quality")
        medium_threshold = get_quality_threshold("medium_quality")
        
        if coverage_percentage >= high_threshold:
            verification_status = "verifiziert"
            quality_assessment = "hoch"
        elif coverage_percentage >= medium_threshold:
            verification_status = "verifiziert"
            quality_assessment = "mittel"
        else:
            verification_status = "nicht_verifiziert"
            quality_assessment = "niedrig"
        
        # 5. Empfehlungen
        recommendations = []
        if coverage_percentage < high_threshold:
            recommendations.append(f"Wortabdeckung nur {coverage_percentage:.1f}% - Manuelle √úberpr√ºfung empfohlen")
        if len(missing_words) > 0:
            recommendations.append(f"{len(missing_words)} W√∂rter fehlen in der Analyse")
        if coverage_percentage >= high_threshold:
            recommendations.append("Hohe Wortabdeckung - Analyse ist zuverl√§ssig")
        
        return {
            "status": "VALIDATED",
            "coverage_percentage": coverage_percentage,
            "missing_words": list(missing_words),
            "total_detected": len(detected_words_normalized),
            "total_in_json": len(json_words),
            "verification_status": verification_status,
            "quality_assessment": quality_assessment,
            "recommendations": recommendations,
            "validation_details": {
                "validation_timestamp": datetime.now().isoformat(),
                "method": "backend_logic"
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå Wortabdeckungs-Validierung fehlgeschlagen: {e}")
        return {
            "status": "ERROR",
            "coverage_percentage": 0.0,
            "missing_words": [],
            "verification_status": "fehler",
            "quality_assessment": "unbekannt",
            "recommendations": [f"Validierungsfehler: {str(e)}"],
            "validation_details": {
                "validation_timestamp": datetime.now().isoformat(),
                "error": str(e)
            }
        }

# Zentrale Prompt-Verwaltung wird jetzt in visio_prompts.py verwaltet

@app.post("/api/test/simple-vision", tags=["Test"])
async def test_simple_vision(
    file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """
    Einfacher Test f√ºr Vision API - fragt nur nach dem Firmennamen im Logo
    """
    try:
        upload_logger.info(f"üß™ Einfacher Vision-Test gestartet: {file.filename}")
        
        # 1. Datei tempor√§r speichern
        file_extension = file.filename.split('.')[-1] if '.' in file.filename else 'txt'
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_extension}") as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_path = Path(tmp_file.name)
        
        try:
            # 2. Pr√ºfen ob es eine Bild-Datei ist
            file_extension = file.filename.lower().split('.')[-1] if '.' in file.filename else 'txt'
            is_image = file_extension in ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff']
            is_pdf = file_extension == 'pdf'
            
            # 3. Datei-Inhalt nur f√ºr Text-Dateien lesen
            file_content = ""
            if not (is_image or is_pdf):
                with open(tmp_path, 'r', encoding='utf-8') as f:
                    file_content = f.read()
            
            # 4. API-Aufruf vorbereiten
            start_time = time.time()
            analysis_result = None
            
            if is_image or is_pdf:
                # Vision Engine f√ºr Bilder/PDFs
                vision_engine = VisionOCREngine()
                
                if is_image:
                    # Direkt mit der PNG-Datei arbeiten
                    with open(tmp_path, 'rb') as f:
                        image_bytes = f.read()
                    logger.info(f"üîç Starte einfachen Vision-Test mit {len(image_bytes)} Bytes")
                    
                    # Bild zu Base64 konvertieren
                    image_b64 = base64.b64encode(image_bytes).decode('utf-8')
                    
                    # ‚úÖ KORREKTER PROMPT f√ºr einfachen Vision-Test
                    simple_prompt = """
                    Du analysierst ein QM-Dokument f√ºr Medizinprodukte. Extrahiere ALLE Informationen strukturiert als JSON.

                    AUSGABE-FORMAT (JSON):
                    ```json
                    {
                        "document_title": "Dokumententitel",
                        "process_flow": [
                            {
                                "step": "Schritt-Name",
                                "responsibility": "Verantwortliche Abteilung", 
                                "decision_point": true/false,
                                "options": ["Ja", "Nein"] oder null,
                                "description": "Detaillierte Beschreibung"
                            }
                        ],
                        "process_references": [
                            "PA 8.5", "PA 8.2.1", etc.
                        ],
                        "compliance_requirements": [
                            "ISO 13485", "MDR", etc.
                        ],
                        "quality_controls": [
                            "Qualit√§tskontroll-Punkte"
                        ],
                        "erp_integration": [
                            "ERP-Bezogene Schritte"
                        ],
                        "extracted_text": "VOLLST√ÑNDIGER extrahierter Text",
                        "workflow_complexity": "hoch/mittel/niedrig",
                        "estimated_text_length": "Gesch√§tzte Zeichen-Anzahl"
                    }
                    ```

                    WICHTIG: 
                    - Lies JEDEN Text vollst√§ndig
                    - Erkenne auch klein gedruckten Text
                    - Verfolge ALLE Prozess-Pfeile
                    - Dokumentiere JEDE Prozess-Referenz
                    - Erfasse die kompletten Textboxen

                    Antworte NUR mit g√ºltigem JSON, kein Markdown, kein Freitext.
                    """
                    
                    # Direkter API-Aufruf mit korrektem Prompt
                    if not vision_engine.client:
                        raise HTTPException(status_code=500, detail="OpenAI Client nicht verf√ºgbar")
                    
                    response = vision_engine.client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": simple_prompt},
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/png;base64,{image_b64}",
                                            "detail": "high"
                                        }
                                    }
                                ]
                            }
                        ],
                        max_tokens=16384,
                        temperature=0.1
                    )
                    
                    response_text = response.choices[0].message.content or ""
                    
                    # JSON-Parsing
                    try:
                        cleaned_text = response_text.strip()
                        if cleaned_text.startswith('```json'):
                            cleaned_text = cleaned_text[7:]
                        if cleaned_text.endswith('```'):
                            cleaned_text = cleaned_text[:-3]
                        
                        analysis_result = json.loads(cleaned_text)
                        analysis_result['success'] = True
                        analysis_result['content'] = response_text
                        
                    except json.JSONDecodeError:
                        # Fallback bei JSON-Parsing-Fehler
                        analysis_result = {
                            "success": True,
                            "document_title": "Automatisch analysiert",
                            "process_flow": [],
                            "process_references": [],
                            "compliance_requirements": [],
                            "quality_controls": [],
                            "erp_integration": [],
                            "extracted_text": response_text,
                            "workflow_complexity": "unbekannt",
                            "estimated_text_length": str(len(response_text)),
                            "content": response_text
                        }
                else:
                    # PDF konvertieren (mit Caching)
                    images = await vision_engine._get_or_convert_images(tmp_path)
                    if not images:
                        raise HTTPException(status_code=500, detail="Keine Bilder erstellt")
                    
                    logger.info(f"üîç Starte einfachen Vision-Test mit {len(images[0])} Bytes")
                    
                    # Bild zu Base64 konvertieren
                    image_b64 = base64.b64encode(images[0]).decode('utf-8')
                    
                    analysis_result = await vision_engine._analyze_image_with_gpt4_vision(
                        image_b64, 
                        context="Einfacher Firmenname-Test",
                        custom_prompt="Analysiere dieses Bild und antworte nur mit dem Namen der Firma, die erw√§hnt wird. Falls kein Firmenname erw√§hnt wird, antworte mit 'Kein Firmenname erw√§hnt'."
                    )
            else:
                # Text-Analyse f√ºr Text-Dateien
                vision_engine = VisionOCREngine()
                logger.info(f"üîç Starte Text-Analyse mit {len(file_content)} Zeichen")
                
                # Einfache Text-Analyse mit OpenAI
                if not vision_engine.client:
                    raise HTTPException(status_code=500, detail="OpenAI Client nicht verf√ºgbar")
                
                response = vision_engine.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "user",
                            "content": f"""
                            Analysiere diesen Text und antworte nur mit dem Namen der Firma, die erw√§hnt wird.
                            Falls kein Firmenname erw√§hnt wird, antworte mit "Kein Firmenname erw√§hnt".
                            Antworte nur mit dem Firmennamen, nichts anderes.
                            
                            Text: {file_content}
                            """
                        }
                    ],
                    max_tokens=50,
                    temperature=0.1
                )
                
                response_text = response.choices[0].message.content or "Keine Antwort erhalten"
                analysis_result = {
                    "success": True,
                    "description": response_text,
                    "content": response_text
                }
            
            end_time = time.time()
            duration = end_time - start_time
            
            logger.info(f"‚úÖ Vision-Test abgeschlossen in {duration:.2f}s")
            
            # 6. Ergebnis verarbeiten
            if analysis_result and analysis_result.get('success'):
                # Vision API gibt strukturierte JSON zur√ºck - extrahiere relevante Informationen
                document_title = analysis_result.get('document_title', 'Unbekanntes Dokument')
                process_flow = analysis_result.get('process_flow', [])
                process_references = analysis_result.get('process_references', [])
                extracted_text = analysis_result.get('extracted_text', '')
                
                # ROBUSTE Zusammenfassung - funktioniert mit allen SOP-Strukturen
                summary_parts = []
                
                if document_title and document_title != 'Unbekanntes Dokument':
                    summary_parts.append(f"üìÑ {document_title}")
                
                if process_flow:
                    summary_parts.append(f"üîÑ {len(process_flow)} Prozessschritte")
                
                if process_references:
                    summary_parts.append(f"üìö {', '.join(process_references)}")
                
                # Fallback falls keine spezifischen Informationen vorhanden
                if not summary_parts:
                    response_text = "Dokument erfolgreich analysiert"
                else:
                    response_text = " | ".join(summary_parts)
                
                logger.info(f"üìù API-Antwort verarbeitet: {response_text}")
                
                # Bildgr√∂√üe ermitteln
                image_size = 0
                if is_image:
                    with open(tmp_path, 'rb') as f:
                        image_size = len(f.read())
                elif is_pdf and 'images' in locals():
                    image_size = len(images[0]) if images else 0
                
                # KOMPLETTE strukturierte Antwort zur√ºckgeben
                return {
                    "success": True,
                    "structured_analysis": analysis_result,  # VOLLST√ÑNDIGE JSON-Struktur
                    "summary": response_text,  # Benutzerfreundliche Zusammenfassung
                    "duration_seconds": round(duration, 2),
                    "image_size_bytes": image_size,
                    "file_type": file_extension,
                    "timestamp": datetime.now().isoformat(),
                    "provider_used": "vision_api"  # NEU: Provider-Info f√ºr Frontend
                }
            else:
                raise HTTPException(status_code=500, detail="Vision API gab keine g√ºltige Antwort zur√ºck")
                
        finally:
            # Tempor√§re Datei l√∂schen
            try:
                tmp_path.unlink()
            except:
                pass
                
    except Exception as e:
        upload_logger.error(f"‚ùå Einfacher Vision-Test fehlgeschlagen: {e}")
        raise HTTPException(status_code=500, detail=f"Test-Fehler: {str(e)}")

# === DATEI-UPLOAD ENDPUNKTE ===

@app.get("/api/upload-methods", tags=["Upload Methods"])
async def get_upload_methods():
    """
    Gibt alle verf√ºgbaren Upload-Methoden dynamisch zur√ºck.
    
    Returns:
        Dict mit allen verf√ºgbaren Upload-Methoden und deren Metadaten
    """
    return {
        "methods": [
            {
                "id": "ocr",
                "name": "OCR - F√ºr textbasierte Dokumente",
                "description": "Optical Character Recognition f√ºr Normen, Richtlinien und textbasierte Dokumente",
                "icon": "üìÑ",
                "suitable_for": ["PDF", "DOC", "DOCX", "TXT", "MD"],
                "features": ["Text-Extraktion", "Metadaten-Analyse", "Dokumenttyp-Erkennung"]
            },
            {
                "id": "visio", 
                "name": "Visio - F√ºr grafische Dokumente",
                "description": "KI-basierte Analyse von Flussdiagrammen, SOPs und grafischen Dokumenten",
                "icon": "üñºÔ∏è",
                "suitable_for": ["PNG", "JPG", "JPEG", "PDF"],
                "features": ["Bildanalyse", "Strukturierte JSON-Extraktion", "Dokumenttyp-Erkennung"]
            },
            {
                "id": "multi-visio",
                "name": "Multi-Visio - Erweiterte Validierung", 
                "description": "4-Stufen-Pipeline mit Wortabdeckungs-Validierung und Normkonformit√§ts-Check",
                "icon": "üîç",
                "suitable_for": ["PNG", "JPG", "JPEG", "PDF"],
                "features": ["Experten-Einweisung", "Strukturierte Analyse", "Wortabdeckungs-Validierung", "Normkonformit√§ts-Check"]
            }
        ]
    }

# === MULTI-VISIO PROMPT ENDPOINTS ===
@app.get("/api/multi-visio-prompts/{prompt_type}", tags=["Multi-Visio Prompts"])
async def get_multi_visio_prompt(prompt_type: str):
    """
    L√§dt Multi-Visio-Prompts DYNAMISCH - wie bei normaler Visio!
    
    Verwendet das neue multi_visio_prompts Management System f√ºr:
    - Automatische Updates bei Datei-√Ñnderungen ‚úÖ
    - Versionierung und Audit-Trail ‚úÖ
    - Konsistente API wie visio_prompts ‚úÖ
    """
    try:
        # ‚úÖ NEUES SYSTEM: Dynamisches Laden wie bei visio_prompts
        from .multi_visio_prompts import get_multi_visio_prompt as load_prompt
        
        # Mapping API-Parameter zu internen Stage-Namen
        stage_mapping = {
            "expert-induction": "expert_induction",
            "structured-analysis": "structured_analysis", 
            "word-coverage": "word_coverage",
            "verification": "verification",
            "norm-compliance": "norm_compliance"
        }
        
        if prompt_type not in stage_mapping:
            raise HTTPException(status_code=404, detail=f"Prompt-Typ '{prompt_type}' nicht gefunden")
        
        # Lade Prompt dynamisch mit vollem Audit-Trail
        stage_name = stage_mapping[prompt_type]
        prompt_data = load_prompt(stage_name)
        
        # API-kompatible Response
        response = {
            "prompt": prompt_data["prompt"],
            "type": prompt_type,
            "version": prompt_data["version"],
            "description": prompt_data["metadata"]["description"],
            "metadata": {
                "stage": stage_name,
                "filename": prompt_data["metadata"].get("filename", "unknown"),
                "prompt_length": prompt_data["metadata"]["prompt_length"],
                "prompt_hash": prompt_data["hash"],
                "loaded_at": prompt_data["metadata"]["loaded_at"],
                "system_version": prompt_data["metadata"]["system_version"]
            },
            "audit_info": prompt_data["audit_info"]
        }
        
        # ‚úÖ AUDIT-LOG f√ºr Transparenz
        logger.info(f"üîç MULTI-VISIO PROMPT API: {prompt_type} ‚Üí {stage_name}")
        logger.info(f"   üìù Version: {prompt_data['version']}")
        logger.info(f"   üìè L√§nge: {prompt_data['metadata']['prompt_length']} Zeichen")
        logger.info(f"   üîê Hash: {prompt_data['hash']}")
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Fehler beim dynamischen Laden des Multi-Visio-Prompts '{prompt_type}': {str(e)}")
        
        # ‚ö° FALLBACK: Altes System
        logger.warning(f"‚ö° Fallback f√ºr {prompt_type}: Direktes Datei-Laden")
        try:
            prompt_file_map = {
                "expert-induction": "01_expert_induction.txt",
                "structured-analysis": "02_structured_analysis.txt", 
                "word-coverage": "03_word_coverage.txt",
                "norm-compliance": "05_norm_compliance.txt"
            }
            
            prompt_file = prompt_file_map.get(prompt_type, f"{prompt_type}.txt")
            prompt_path = get_prompts_dir() / prompt_file
            
            if not os.path.exists(prompt_path):
                raise HTTPException(status_code=404, detail=f"Prompt-Datei '{prompt_file}' nicht gefunden")
            
            with open(prompt_path, 'r', encoding='utf-8') as f:
                prompt_content = f.read()
            
            return {
                "prompt": prompt_content,
                "type": prompt_type,
                "version": "1.0",
                "description": f"Multi-Visio Prompt f√ºr {prompt_type} (Fallback)"
            }
            
        except Exception as fallback_error:
            logger.error(f"‚ùå Auch Fallback fehlgeschlagen: {fallback_error}")
            raise HTTPException(status_code=500, detail=f"Fehler beim Laden des Prompts: {str(e)}")

# === AI PROVIDER STATUS ===
@app.get("/api/ai/free-providers-status", tags=["AI Providers"])
async def get_ai_provider_status():
    """Gibt den Status aller verf√ºgbaren AI-Provider zur√ºck"""
    try:
        from .ai_engine import AdvancedAIEngine
        
        # AI Engine initialisieren
        ai_engine = AdvancedAIEngine()
        
        # Provider-Status abrufen
        provider_status = {}
        
        # OpenAI 4o-mini
        try:
            openai_available = bool(os.getenv("OPENAI_API_KEY"))
            provider_status["openai"] = {
                "available": openai_available,
                "name": "OpenAI GPT-4o",
                "description": "OpenAI GPT-4o Mini f√ºr Text- und Bildanalyse",
                "status": "available" if openai_available else "unavailable",
                "type": "cloud",
                "cost": "pay-per-use",
                "performance": "high"
            }
        except:
            provider_status["openai"] = {
                "available": False,
                "name": "OpenAI GPT-4o",
                "description": "OpenAI GPT-4o Mini f√ºr Text- und Bildanalyse",
                "status": "unavailable",
                "type": "cloud",
                "cost": "pay-per-use",
                "performance": "high"
            }
        
        # Ollama
        try:
            ollama_available = True  # Ollama l√§uft lokal
            provider_status["ollama"] = {
                "available": ollama_available,
                "name": "Ollama (Lokal)",
                "description": "Lokaler Ollama-Server f√ºr Textanalyse",
                "status": "available" if ollama_available else "unavailable",
                "type": "local",
                "cost": "free",
                "performance": "medium"
            }
        except:
            provider_status["ollama"] = {
                "available": False,
                "name": "Ollama (Lokal)",
                "description": "Lokaler Ollama-Server f√ºr Textanalyse",
                "status": "unavailable",
                "type": "local",
                "cost": "free",
                "performance": "medium"
            }
        
        # Google Gemini
        try:
            gemini_available = bool(os.getenv("GOOGLE_AI_API_KEY"))
            provider_status["gemini"] = {
                "available": gemini_available,
                "name": "Google Gemini",
                "description": "Google Gemini f√ºr Text- und Bildanalyse",
                "status": "available" if gemini_available else "unavailable",
                "type": "cloud",
                "cost": "pay-per-use",
                "performance": "high"
            }
        except:
            provider_status["gemini"] = {
                "available": False,
                "name": "Google Gemini",
                "description": "Google Gemini f√ºr Text- und Bildanalyse",
                "status": "unavailable",
                "type": "cloud",
                "cost": "pay-per-use",
                "performance": "high"
            }
        
        return {
            "provider_status": provider_status,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Fehler beim Abrufen des AI-Provider-Status: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Fehler beim Abrufen des Provider-Status: {str(e)}")

# === AI TEST ENDPOINTS ===
@app.post("/api/ai/test-provider", tags=["AI Test"])
async def test_ai_provider(
    provider: str = Form(...),
    test_text: str = Form(...)
):
    """Testet einen spezifischen AI-Provider"""
    try:
        from .ai_providers import OpenAI4oMiniProvider, OllamaProvider, GoogleGeminiProvider
        
        # Provider ausw√§hlen
        if provider == "openai":
            ai_provider = OpenAI4oMiniProvider()
        elif provider == "ollama":
            ai_provider = OllamaProvider()
        elif provider == "gemini":
            ai_provider = GoogleGeminiProvider()
        else:
            raise HTTPException(status_code=400, detail=f"Unbekannter Provider: {provider}")
        
        # Test durchf√ºhren
        result = await ai_provider.analyze_document(test_text, "text")
        
        return {
            "success": True,
            "provider": provider,
            "test_text": test_text,
            "response": result.get("ai_summary", str(result)),
            "full_response": result
        }
        
    except Exception as e:
        logger.error(f"AI Provider Test Fehler: {e}")
        return {
            "success": False,
            "provider": provider,
            "error": str(e),
            "test_text": test_text
        }

@app.post("/api/ai/simple-prompt", tags=["AI Test"])
async def simple_ai_prompt_test(
    prompt: str = Form(...),
    provider: str = Form("auto")
):
    """Einfacher AI Prompt Test"""
    import time
    start_time = time.time()
    
    try:
        from .ai_providers import OpenAI4oMiniProvider, OllamaProvider, GoogleGeminiProvider
        
        # Provider ausw√§hlen
        if provider == "auto":
            # Auto-Auswahl: OpenAI > Ollama > Gemini
            try:
                ai_provider = OpenAI4oMiniProvider()
                provider = "openai"
            except:
                try:
                    ai_provider = OllamaProvider()
                    provider = "ollama"
                except:
                    ai_provider = GoogleGeminiProvider()
                    provider = "gemini"
        elif provider == "openai":
            ai_provider = OpenAI4oMiniProvider()
        elif provider == "ollama":
            ai_provider = OllamaProvider()
        elif provider == "gemini":
            ai_provider = GoogleGeminiProvider()
        else:
            raise HTTPException(status_code=400, detail=f"Unbekannter Provider: {provider}")
        
        # Prompt ausf√ºhren - direkt mit dem Provider kommunizieren
        if hasattr(ai_provider, 'simple_prompt'):
            # Verwende die simple_prompt Methode falls verf√ºgbar
            result = await ai_provider.simple_prompt(prompt)
        else:
            # Fallback: Direkte Kommunikation mit dem Provider
            if provider == "gemini":
                # Direkter Gemini API Call
                import requests
                import os
                
                api_key = os.getenv("GOOGLE_AI_API_KEY")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
                
                payload = {
                    "contents": [{
                        "parts": [{"text": prompt}]
                    }],
                    "generationConfig": {
                        "temperature": 0.7,
                        "maxOutputTokens": 1000
                    }
                }
                
                response = requests.post(url, json=payload, timeout=30)
                if response.status_code == 200:
                    result_data = response.json()
                    if "candidates" in result_data and result_data["candidates"]:
                        ai_response = result_data["candidates"][0]["content"]["parts"][0]["text"]
                        result = {
                            "ai_summary": ai_response,
                            "response": ai_response,
                            "provider": "gemini"
                        }
                    else:
                        result = {"ai_summary": "Keine Antwort von Gemini erhalten", "response": "Keine Antwort"}
                else:
                    result = {"ai_summary": f"Gemini API Fehler: {response.status_code}", "response": f"Fehler: {response.status_code}"}
            else:
                # Fallback f√ºr andere Provider
                result = await ai_provider.analyze_document(prompt, "text")
        
        # Zeitmessung
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "provider": provider,
            "prompt": prompt,
            "response": result.get("ai_summary", result.get("response", str(result))),
            "full_response": result,
            "processing_time_seconds": processing_time
        }
        
    except Exception as e:
        logger.error(f"AI Prompt Test Fehler: {e}")
        return {
            "success": False,
            "provider": provider,
            "error": str(e),
            "prompt": prompt
        }

# === MULTI-VISIO STAGE EXECUTION ===

# üìã IN-MEMORY CACHE f√ºr Pipeline-Ergebnisse (verhindert redundante AI-Calls)
_multi_visio_cache = {}

def _get_file_hash(file_path: str) -> str:
    """Erstellt einen Hash f√ºr die Datei zur Cache-Identifikation"""
    import hashlib
    with open(file_path, 'rb') as f:
        content = f.read()
    return hashlib.md5(content).hexdigest()

@app.post("/api/multi-visio/stage/{stage_number}", tags=["Multi-Visio Pipeline"])
async def execute_multi_visio_stage(
    stage_number: int,
    file: UploadFile = File(...),
    provider: str = Form("auto")
):
    """
    F√ºhrt eine einzelne Stufe der Multi-Visio-Pipeline aus.
    
    WICHTIG: F√ºr Stages 3+4 wird die komplette Pipeline bis zur gew√ºnschten Stage ausgef√ºhrt,
    um redundante AI-Calls zu vermeiden und Pipeline-Abh√§ngigkeiten zu ber√ºcksichtigen.
    """
    try:
        if stage_number not in [1, 2, 3, 4, 5]:
            raise HTTPException(status_code=400, detail=f"Ung√ºltige Stufe: {stage_number}. Nur Stufen 1-5 sind erlaubt.")
        
        # Multi-Visio Engine importieren
        from .multi_visio_engine import MultiVisioEngine
        
        # Datei speichern und PNG erstellen
        file_response = await save_uploaded_file(file, "OTHER", "multi-visio")
        file_path = file_response.file_path
        
        # Multi-Visio Engine initialisieren
        multi_visio_engine = MultiVisioEngine()
        
        # üöÄ EINMALIGE Bildkonvertierung mit Cache (verhindert LibreOffice Pop-ups)
        images = await multi_visio_engine._get_or_convert_images(file_path)
        
        if not images:
            raise HTTPException(status_code=500, detail="Dokument konnte nicht zu Bildern konvertiert werden")
        
        logger.info(f"üîÑ Multi-Visio Stage {stage_number} - Bilder gecacht, starte optimierte Pipeline...")
        
        # üìã OPTIMIERTE PIPELINE: Ausf√ºhrung bis zur gew√ºnschten Stage
        if stage_number == 1:
            # Stage 1: Kontext-Setup (Bild an AI)
            result = await multi_visio_engine._stage1_context_setup(images, "OTHER", provider)
            
        elif stage_number == 2:
            # Stage 2: Strukturierte Analyse (Bild an AI) mit Cache
            file_hash = _get_file_hash(file_path)
            cache_key = f"{file_hash}_stage2_{provider}"
            
            if cache_key in _multi_visio_cache:
                logger.info("‚úÖ Cache HIT: Stage 2 bereits berechnet")
                result = _multi_visio_cache[cache_key]
            else:
                logger.info("üîÑ Cache MISS: Stage 2 Strukturierte Analyse (Bild an AI)")
                result = await multi_visio_engine._stage2_structured_analysis(images, "OTHER", provider)
                if result.get("success"):
                    _multi_visio_cache[cache_key] = result
            
        elif stage_number == 3:
            # Stage 3: BACKEND-ONLY Processing (KEIN Bild an AI)
            logger.info("üîÑ Stage 3 - Backend-Processing: Stage 2 ‚Üí Text-Extraktion (KEIN AI-Call)")
            
            # üìã CACHE-OPTIMIERUNG: Stage 2 nur einmal pro Datei
            file_hash = _get_file_hash(file_path)
            cache_key = f"{file_hash}_stage2_{provider}"
            
            if cache_key in _multi_visio_cache:
                logger.info("‚úÖ Cache HIT: Stage 2 Ergebnis aus Cache geladen")
                stage2_result = _multi_visio_cache[cache_key]
            else:
                logger.info("üîÑ Cache MISS: Stage 2 wird ausgef√ºhrt und gecacht")
                stage2_result = await multi_visio_engine._stage2_structured_analysis(images, "OTHER", provider)
                if stage2_result.get("success"):
                    _multi_visio_cache[cache_key] = stage2_result
            
            if not stage2_result.get("success"):
                raise HTTPException(status_code=500, detail="Stage 2 fehlgeschlagen - erforderlich f√ºr Stage 3")
            
            # Backend-Processing ohne AI-Calls
            result = await multi_visio_engine._stage3_text_extraction_from_stage2(stage2_result)
            
        elif stage_number == 4:
            # Stage 4: BACKEND-ONLY Verifikation (KEIN Bild an AI)
            logger.info("üîç Stage 4 - Backend-Verifikation: Stage 2 ‚Üí Stage 3 ‚Üí Hybrid-Validation (KEIN AI-Call)")
            
            # üìã CACHE-OPTIMIERUNG: Stage 2 + 3 aus Cache oder berechnen
            file_hash = _get_file_hash(file_path)
            stage2_cache_key = f"{file_hash}_stage2_{provider}"
            stage3_cache_key = f"{file_hash}_stage3_{provider}"
            
            # Stage 2 aus Cache oder neu berechnen
            if stage2_cache_key in _multi_visio_cache:
                logger.info("‚úÖ Cache HIT: Stage 2 aus Cache")
                stage2_result = _multi_visio_cache[stage2_cache_key]
            else:
                logger.info("üîÑ Cache MISS: Stage 2 wird berechnet")
                stage2_result = await multi_visio_engine._stage2_structured_analysis(images, "OTHER", provider)
                if stage2_result.get("success"):
                    _multi_visio_cache[stage2_cache_key] = stage2_result
            
            if not stage2_result.get("success"):
                raise HTTPException(status_code=500, detail="Stage 2 fehlgeschlagen - erforderlich f√ºr Stage 4")
            
            # Stage 3 aus Cache oder neu berechnen (Backend-only)
            if stage3_cache_key in _multi_visio_cache:
                logger.info("‚úÖ Cache HIT: Stage 3 aus Cache")
                stage3_result = _multi_visio_cache[stage3_cache_key]
            else:
                logger.info("üîÑ Cache MISS: Stage 3 Backend-Processing")
                stage3_result = await multi_visio_engine._stage3_text_extraction_from_stage2(stage2_result)
                if stage3_result.get("success"):
                    _multi_visio_cache[stage3_cache_key] = stage3_result
            
            if not stage3_result.get("success"):
                raise HTTPException(status_code=500, detail="Stage 3 Backend-Processing fehlgeschlagen")
            
            # Backend-Verifikation ohne AI-Calls
            result = await multi_visio_engine._stage4_verification_hybrid(stage3_result, stage2_result)
        elif stage_number == 5:
            # Stage 5: Norm-Compliance (mit Stage 2 Cache)
            logger.info("üîÑ Stage 5 - Norm-Compliance: Stage 2 ‚Üí Text-Analyse")
            
            file_hash = _get_file_hash(file_path)
            stage2_cache_key = f"{file_hash}_stage2_{provider}"
            
            # Stage 2 aus Cache oder neu berechnen
            if stage2_cache_key in _multi_visio_cache:
                logger.info("‚úÖ Cache HIT: Stage 2 f√ºr Stage 5 aus Cache")
                stage2_result = _multi_visio_cache[stage2_cache_key]
            else:
                logger.info("üîÑ Cache MISS: Stage 2 f√ºr Stage 5 wird berechnet")
                stage2_result = await multi_visio_engine._stage2_structured_analysis(images, "OTHER", provider)
                if stage2_result.get("success"):
                    _multi_visio_cache[stage2_cache_key] = stage2_result
            
            if not stage2_result.get("success"):
                raise HTTPException(status_code=500, detail="Stage 2 fehlgeschlagen - erforderlich f√ºr Stage 5")
            structured_json = stage2_result.get("json_data", {})
            result = await multi_visio_engine._stage5_norm_compliance(images, structured_json, "OTHER", provider)
        
        return result
        
    except Exception as e:
        logger.error(f"Fehler in Multi-Visio Stufe {stage_number}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Fehler in Stufe {stage_number}: {str(e)}")

@app.post("/api/multi-visio/clear-cache", tags=["Multi-Visio Pipeline"])
async def clear_multi_visio_cache():
    """Leert den Multi-Visio Pipeline Cache (f√ºr neue Dokumente oder Debugging)"""
    global _multi_visio_cache
    cache_size = len(_multi_visio_cache)
    _multi_visio_cache.clear()
    logger.info(f"üóëÔ∏è Multi-Visio Cache geleert: {cache_size} Eintr√§ge entfernt")
    return {
        "success": True,
        "message": f"Cache geleert: {cache_size} Eintr√§ge entfernt",
        "cache_entries_removed": cache_size
    }

@app.post("/api/multi-visio/full-pipeline", tags=["Multi-Visio Pipeline"])
async def execute_full_multi_visio_pipeline(
    file: UploadFile = File(...),
    document_type: str = Form("PROCESS"),
    provider: str = Form("auto")
):
    """F√ºhrt 5-Stufen Prompt-Chain durch"""
    try:
        # Multi-Visio Engine importieren
        from .multi_visio_engine import MultiVisioEngine
        
        # Datei speichern
        file_response = await save_uploaded_file(file, document_type, "multi-visio")
        file_path = file_response.file_path
        
        # Multi-Visio Engine initialisieren und Pipeline ausf√ºhren
        multi_visio_engine = MultiVisioEngine()
        result = await multi_visio_engine.run_full_pipeline(file_path, document_type, provider)
        
        return result
        
    except Exception as e:
        logger.error(f"Fehler in Multi-Visio Pipeline: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Fehler in Multi-Visio Pipeline: {str(e)}")

@app.post("/api/files/upload", response_model=FileUploadResponse, tags=["File Upload"])
async def upload_file(
    file: UploadFile = File(...),
    document_type: str = Form(...),
    upload_method: str = Form("ocr"),  # NEU: Upload-Methode als Formularfeld
    db: Session = Depends(get_db)
):
    """
    L√§dt eine Datei hoch und speichert sie strukturiert.
    
    Args:
        file: Hochzuladende Datei (PDF, DOC, DOCX, TXT, MD, XLS, XLSX)
        document_type: Dokumenttyp f√ºr Ordnerorganisation
        upload_method: Ausgew√§hlte Upload-Methode (ocr, visio, multi-visio)
        
    Returns:
        FileUploadResponse: Metadaten der gespeicherten Datei
    """
    try:
        upload_response = await save_uploaded_file(file, document_type, upload_method)
        return upload_response
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Upload-Fehler: {str(e)}"
        )

@app.post("/api/documents/with-file", response_model=Document, tags=["Documents"])
async def create_document_with_file(
    title: Optional[str] = Form(None),
    document_type: Optional[str] = Form("OTHER"),
    creator_id: int = Form(...),
    version: str = Form("1.0"),
    content: Optional[str] = Form(None),
    remarks: Optional[str] = Form(None),
    chapter_numbers: Optional[str] = Form(None),
    ai_model: Optional[str] = Form("auto"),
    enable_debug: Optional[str] = Form("false"),
    upload_method: str = Form("ocr"),  # NEU: Upload-Methode als Formularfeld
    file: Optional[UploadFile] = File(None),
    db: Session = Depends(get_db)
):
    """
    Erstellt ein Dokument mit optionalem Datei-Upload und intelligenter Analyse.
    
    **Neue Features:**
    - ü§ñ **Intelligente Dokumenttyp-Erkennung** basierend auf Inhalt (erste 3000 Zeichen)
    - üìä **Umfassende Metadaten-Extraktion** (Keywords, Compliance-Indikatoren, etc.)
    - üéØ **Automatische Titel/Beschreibung** falls nicht angegeben
    - üîç **Content-Analyse** f√ºr bessere Kategorisierung
    - üîÄ **Zwei Upload-Methoden**: OCR (textbasiert) oder Visio (bildbasiert)
    
    Args:
        title: Dokumenttitel (optional - wird automatisch extrahiert)
        document_type: Dokumenttyp (wird intelligent erkannt wenn "OTHER")
        creator_id: ID des erstellenden Benutzers
        version: Dokumentversion (Standard: "1.0")
        content: Beschreibung (optional - wird automatisch extrahiert)
        remarks: Bemerkungen
        chapter_numbers: Relevante Normkapitel (z.B. "4.2.3, 7.5.1")
        upload_method: Verarbeitungsmethode - "ocr" oder "visio" (Standard: "ocr")
        file: Upload-Datei (PDF, DOCX, XLSX, TXT)
        db: Datenbankverbindung
        
    Returns:
        Document: Erstelltes Dokument mit Metadaten und ggf. erkanntem Typ
        
    Example Request:
        ```bash
        curl -X POST "http://localhost:8000/api/documents/with-file" \
             -F "file=@sop-dokumentenkontrolle.pdf" \
             -F "creator_id=2" \
             -F "document_type=OTHER"  # Wird automatisch als "SOP" erkannt
        ```
        
    Example Response:
        ```json
        {
            "id": 15,
            "title": "SOP-001: Dokumentenlenkung und -kontrolle",
            "document_type": "SOP",  # Automatisch erkannt!
            "detected_metadata": {
                "confidence": 0.85,
                "keywords": ["Dokumentenkontrolle", "ISO 13485", "Freigabe"],
                "complexity_score": 7
            }
        }
        ```
    """
    try:
        upload_logger.info(f"üîÑ Document Upload gestartet: creator_id={creator_id}, type={document_type}, method={upload_method}, file={file.filename if file else 'None'}")
        start_time = time.time()
        
        # Validiere Upload-Methode
        if upload_method not in ['ocr', 'visio', 'multi-visio']:
            raise HTTPException(status_code=400, detail=f"Ung√ºltige Upload-Methode: {upload_method}. Erlaubt: ocr, visio, multi-visio")
        
        # 1. Datei-Upload verarbeiten (falls vorhanden)
        file_data = None
        extracted_text = ""
        metadata = {}
        validation_status = None
        structured_analysis = None
        prompt_used = None
        ocr_text_preview = None
        
        # PNG-Metadaten initialisieren
        png_preview_path = None
        png_preview_hash = None
        png_preview_size = None
        png_generation_timestamp = None
        png_generation_method = None
        
        if file:
            # üéØ NEU: Original-Dokument-Metadaten speichern
            original_document_path = f"uploads/{document_type or 'OTHER'}/{file.filename}"
            original_document_size = file.size
            original_document_mime_type = file.content_type
            
            # Datei speichern
            upload_result = await save_uploaded_file(file, document_type or "OTHER", upload_method)
            # FileUploadResponse hat kein success Attribut - es wird nur bei Erfolg zur√ºckgegeben
            file_data = upload_result
            
            # üéØ NEU: Original-Dokument-Hash berechnen
            import hashlib
            file_content = await file.read()
            original_document_hash = hashlib.sha256(file_content).hexdigest()
            await file.seek(0)  # Reset file pointer
            
            # Je nach Upload-Methode verarbeiten
            if upload_method == "ocr":
                # === OCR-METHODE: Textbasierte Verarbeitung ===
                upload_logger.info("üìÑ OCR-Methode gew√§hlt - Textextraktion")
                
                # Text extrahieren
                extracted_text = extract_text_from_file(
                    Path(upload_result.file_path), 
                    upload_result.mime_type
                )
                
                # KEIN FALLBACK: OCR-Text wird so verwendet wie er ist
                
                # OCR-Text-Vorschau speichern (erste 2000 Zeichen)
                ocr_text_preview = extracted_text[:2000] + "..." if len(extracted_text) > 2000 else extracted_text
                
            elif upload_method == "visio":
                # === ZENTRALE VISIO-METHODE: KEIN FALLBACK! ===
                upload_logger.info("üñºÔ∏è ZENTRALE Visio-Methode gew√§hlt - KEIN FALLBACK!")
                
                try:
                    from .vision_ocr_engine import VisionOCREngine
                    
                    vision_engine = VisionOCREngine()
                    
                    # 1. Dokument zu Bildern konvertieren (mit Caching)
                    images = await vision_engine._get_or_convert_images(Path(upload_result.file_path))
                    if not images:
                        raise HTTPException(status_code=500, detail="Dokument konnte nicht zu Bildern konvertiert werden")
                    
                    upload_logger.info(f"üì∏ {len(images)} Bilder erstellt")
                    
                    # üéØ NEU: PNG-Metadaten speichern (erstes Bild)
                    if images and len(images) > 0:
                        # ‚úÖ KORRIGIERT: PNG-Datei physisch speichern
                        import os
                        
                        # Erstelle PNG-Dateiname basierend auf Original-Dokument
                        original_filename = Path(upload_result.file_path).stem
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        png_filename = f"{timestamp}_{original_filename}_preview.png"
                        
                        # Speichere PNG im uploads Ordner mit Dokumenttyp-Unterordner
                        uploads_dir = get_uploads_dir() / document_type
                        png_path_local = uploads_dir / png_filename
                        
                        # Stelle sicher, dass der uploads Ordner existiert
                        uploads_dir.mkdir(exist_ok=True, parents=True)
                        
                        # Speichere PNG-Bytes als Datei
                        with open(png_path_local, 'wb') as png_file:
                            png_file.write(images[0])
                        
                        # Setze PNG-Metadaten f√ºr Datenbank
                        png_preview_path = str(png_path_local)
                        png_preview_size = png_path_local.stat().st_size
                        png_generation_timestamp = datetime.now()
                        png_generation_method = "vision_engine_convert"
                        
                        # PNG-Hash berechnen
                        png_preview_hash = hashlib.sha256(images[0]).hexdigest()
                        
                        upload_logger.info(f"‚úÖ PNG-Vorschau gespeichert: {png_preview_path} ({png_preview_size} Bytes)")
                
                # Wichtig: Variablen wurden gesetzt f√ºr Datenbank-Speicherung
                    
                    # 2. ZENTRALE VISION-ANALYSE: Verwende NUR die API-Prompt-Funktion - KEIN FALLBACK!
                    # Provider-Mapping f√ºr Vision Engine
                    vision_provider = get_default_provider()  # Konfigurierbar
                    if ai_model == "gemini":
                        vision_provider = "gemini"
                    elif ai_model == "openai" or ai_model == "openai_4o_mini":
                        vision_provider = get_default_provider()
                    elif ai_model == "ollama":
                        vision_provider = "ollama"
                    elif ai_model == "auto":
                        vision_provider = get_default_provider()  # Auto = OpenAI als Standard
                    
                    analysis_result = await vision_engine.analyze_document_with_api_prompt(
                        images=images,
                        document_type=document_type or "OTHER",
                        preferred_provider=vision_provider
                    )
                    
                    if not analysis_result.get('success'):
                        error_msg = analysis_result.get('error', 'Unbekannter Fehler')
                        upload_logger.error(f"‚ùå ZENTRALE VISION-ANALYSE fehlgeschlagen: {error_msg}")
                        raise HTTPException(status_code=500, detail=f"Zentrale Vision-Analyse fehlgeschlagen: {error_msg}")
                    
                    # 3. Erfolgreiche Analyse verarbeiten
                    upload_logger.info("‚úÖ ZENTRALE VISION-ANALYSE erfolgreich")
                    
                    # PNG-Vorschau f√ºr Frontend erstellen
                    preview_image = None
                    if images:
                        import base64
                        preview_image = base64.b64encode(images[0]).decode('utf-8')
                        upload_logger.info(f"üñºÔ∏è PNG-Vorschau erstellt: {len(preview_image)} Zeichen")
                        
                        # üéØ NEU: PNG auch hier physisch speichern
                        import os
                        
                        # Erstelle PNG-Dateiname basierend auf Original-Dokument
                        original_filename = Path(upload_result.file_path).stem
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        png_filename = f"{timestamp}_{original_filename}_preview.png"
                        
                        # Speichere PNG im backend/uploads Ordner mit Dokumenttyp-Unterordner
                        uploads_dir = get_uploads_dir() / document_type
                        png_path_local = uploads_dir / png_filename
                        
                        # Stelle sicher, dass der uploads Ordner existiert
                        uploads_dir.mkdir(exist_ok=True, parents=True)
                        
                        # Speichere PNG-Bytes als Datei
                        with open(png_path_local, 'wb') as png_file:
                            png_file.write(images[0])
                        
                        # Setze PNG-Metadaten f√ºr Datenbank (verwende die √§u√üeren Variablen!)
                        png_preview_path = str(png_path_local)
                        png_preview_size = png_path_local.stat().st_size
                        png_generation_timestamp = datetime.now()
                        png_generation_method = "vision_engine_convert"
                        
                        # PNG-Hash berechnen
                        png_preview_hash = hashlib.sha256(images[0]).hexdigest()
                        
                        upload_logger.info(f"‚úÖ PNG-Vorschau gespeichert: {png_preview_path} ({png_preview_size} Bytes)")
                
                # Wichtig: Variablen wurden gesetzt f√ºr Datenbank-Speicherung
                    
                    # Strukturierte Analyse extrahieren
                    structured_analysis = analysis_result.get('analysis', '')
                    if isinstance(structured_analysis, dict):
                        structured_analysis = json.dumps(structured_analysis, ensure_ascii=False, indent=2)
                    
                    # Prompt-Info extrahieren
                    prompt_info = analysis_result.get('prompt_used', {})
                    prompt_used = f"Prompt: {document_type} (Version: {prompt_info.get('version', 'unbekannt')})"
                    
                    # Wortliste aus strukturierter Analyse extrahieren (falls vorhanden)
                    word_list = []
                    if isinstance(analysis_result.get('analysis'), dict):
                        # Versuche W√∂rter aus verschiedenen Feldern zu extrahieren
                        analysis_data = analysis_result['analysis']
                        if 'process_steps' in analysis_data:
                            for step in analysis_data['process_steps']:
                                if isinstance(step, dict) and 'label' in step:
                                    word_list.append(step['label'])
                                elif isinstance(step, str):
                                    word_list.append(step)
                        elif 'extracted_text' in analysis_data:
                            # Fallback: W√∂rter aus extrahiertem Text
                            text = analysis_data['extracted_text']
                            word_list = [word.strip() for word in text.split() if len(word.strip()) > 2][:50]
                    
                    upload_logger.info(f"üìù {len(word_list)} W√∂rter aus strukturierter Analyse extrahiert")
                    
                    # JSON parsen - KRITISCH: Die Vision API gibt das Ergebnis in 'analysis' zur√ºck!
                    try:
                        # Versuche zuerst 'analysis' (das ist das echte Ergebnis)
                        if 'analysis' in analysis_result and analysis_result['analysis']:
                            if isinstance(analysis_result['analysis'], dict):
                                structured_analysis = json.dumps(analysis_result['analysis'], ensure_ascii=False, indent=2)
                                upload_logger.info(f"‚úÖ Strukturierte Analyse aus 'analysis' extrahiert: {len(str(analysis_result['analysis']))} Zeichen")
                            else:
                                structured_analysis = str(analysis_result['analysis'])
                                upload_logger.info(f"‚úÖ Strukturierte Analyse als String aus 'analysis': {len(structured_analysis)} Zeichen")
                        # Fallback: Versuche 'content'
                        elif 'content' in analysis_result and analysis_result['content']:
                            if isinstance(analysis_result['content'], dict):
                                structured_analysis = json.dumps(analysis_result['content'], ensure_ascii=False, indent=2)
                                upload_logger.info(f"‚úÖ Strukturierte Analyse aus 'content' extrahiert: {len(str(analysis_result['content']))} Zeichen")
                            else:
                                structured_data = json.loads(analysis_result['content'])
                                structured_analysis = json.dumps(structured_data, ensure_ascii=False, indent=2)
                                upload_logger.info(f"‚úÖ Strukturierte Analyse aus 'content' geparst: {len(str(structured_data))} Zeichen")
                        else:
                            upload_logger.warning("‚ö†Ô∏è Keine strukturierte Analyse in 'analysis' oder 'content' gefunden")
                            structured_analysis = "{}"
                    except json.JSONDecodeError as e:
                        upload_logger.warning(f"‚ö†Ô∏è JSON-Parsing fehlgeschlagen: {e}")
                        structured_analysis = analysis_result.get('content', '{}')
                    except Exception as e:
                        upload_logger.error(f"‚ùå Fehler beim Extrahieren der strukturierten Analyse: {e}")
                        structured_analysis = "{}"
                    
                    # üîß WICHTIG: Vergleich √ºbersprungen - wir brauchen nur einen API-Aufruf!
                    upload_logger.info("‚úÖ Vergleich √ºbersprungen - nur ein API-Aufruf")
                    
                    # Keine Validierung mehr
                    validation_status = "SKIPPED"
                    
                    # Extrahierten Text aus Wortliste generieren (f√ºr RAG)
                    extracted_text = ' '.join(word_list)
                    
                except Exception as visio_error:
                    upload_logger.error(f"‚ùå Visio-Verarbeitung fehlgeschlagen: {visio_error}")
                    raise HTTPException(status_code=500, detail=f"Visio-Verarbeitung fehlgeschlagen: {str(visio_error)}")
            
            elif upload_method == "multi-visio":
                # === MULTI-VISIO-METHODE: 5-STUFEN-PIPELINE ===
                upload_logger.info("üîç Multi-Visio-Methode gew√§hlt - 5-Stufen-Pipeline")
                
                try:
                    from .multi_visio_engine import MultiVisioEngine
                    
                    multi_visio_engine = MultiVisioEngine()
                    
                    # ‚úÖ NEUE PIPELINE: F√ºhre die komplette 5-Stufen-Pipeline aus
                    pipeline_result = await multi_visio_engine.run_full_pipeline(
                        file_path=upload_result.file_path,
                        document_type=document_type or "PROCESS",
                        provider=ai_model or "auto"
                    )
                    
                    # üéØ NEU: Multi-Visio PNG-Metadaten aus Pipeline-Result extrahieren
                    if pipeline_result.get('pipeline_success'):
                        # PNG-Pfad aus Stage 1 extrahieren (falls verf√ºgbar)
                        stage1_result = pipeline_result.get('stages', {}).get('context_setup', {})
                        if 'png_path' in stage1_result:
                            png_preview_path = stage1_result['png_path']
                            png_generation_timestamp = datetime.now()
                            png_generation_method = "multi_visio_pipeline"
                            
                            # PNG-Metadaten berechnen
                            if Path(png_preview_path).exists():
                                png_preview_size = Path(png_preview_path).stat().st_size
                                with open(png_preview_path, 'rb') as png_file:
                                    png_content = png_file.read()
                                    png_preview_hash = hashlib.sha256(png_content).hexdigest()
                    
                    if not pipeline_result.get('pipeline_success'):
                        error_msg = pipeline_result.get('error', 'Unbekannter Fehler')
                        upload_logger.error(f"‚ùå Multi-Visio-Pipeline fehlgeschlagen: {error_msg}")
                        raise HTTPException(status_code=500, detail=f"Multi-Visio-Pipeline fehlgeschlagen: {error_msg}")
                    
                    # Erfolgreiche Pipeline verarbeiten
                    upload_logger.info("‚úÖ Multi-Visio-Pipeline erfolgreich")
                    
                    # PNG-Vorschau f√ºr Frontend erstellen (√ºbersprungen f√ºr Multi-Visio)
                    preview_image = None
                    upload_logger.info("üñºÔ∏è PNG-Vorschau √ºbersprungen f√ºr Multi-Visio")
                    
                    # ‚úÖ KRITISCH: Extrahiere JSON aus Stufe 2 (Strukturierte Analyse)
                    stage2_result = pipeline_result.get('stages', {}).get('structured_analysis', {})
                    structured_json = stage2_result.get('json_data', {})
                    
                    # Strukturierte Analyse als JSON-String
                    if isinstance(structured_json, dict):
                        structured_analysis = json.dumps(structured_json, ensure_ascii=False, indent=2)
                    else:
                        structured_analysis = json.dumps({}, ensure_ascii=False, indent=2)
                    
                    # Prompt-Info extrahieren
                    prompt_used = f"Multi-Visio Pipeline: {document_type} (5-Stufen)"
                    
                    # Wortliste aus strukturierter Analyse extrahieren
                    word_list = []
                    if isinstance(structured_json, dict):
                        # Versuche W√∂rter aus verschiedenen Feldern zu extrahieren
                        if 'process_steps' in structured_json:
                            for step in structured_json['process_steps']:
                                if isinstance(step, dict) and 'label' in step:
                                    word_list.append(step['label'])
                                elif isinstance(step, str):
                                    word_list.append(step)
                        elif 'extracted_text' in structured_json:
                            # Fallback: W√∂rter aus extrahiertem Text
                            text = structured_json['extracted_text']
                            word_list = [word.strip() for word in text.split() if len(word.strip()) > 2][:50]
                    
                    upload_logger.info(f"üìù {len(word_list)} W√∂rter aus strukturierter Analyse extrahiert")
                    
                    # Keine Validierung mehr
                    validation_status = "SKIPPED"
                    
                    # ‚úÖ KRITISCH: Speichere die ECHTE JSON von der Multi-Visio-Pipeline!
                    extracted_text = json.dumps(structured_json) if structured_json else '{}'
                    
                    # üéØ NEU: Multi-Visio Stufen-Ergebnisse in Datenbank speichern
                    multi_visio_stage1_result = json.dumps(pipeline_result.get('stages', {}).get('context_setup', {}), ensure_ascii=False, indent=2)
                    multi_visio_stage2_result = json.dumps(pipeline_result.get('stages', {}).get('structured_analysis', {}), ensure_ascii=False, indent=2)
                    multi_visio_stage3_result = json.dumps(pipeline_result.get('stages', {}).get('text_extraction', {}), ensure_ascii=False, indent=2)
                    multi_visio_stage4_result = json.dumps(pipeline_result.get('stages', {}).get('verification', {}), ensure_ascii=False, indent=2)
                    multi_visio_stage5_result = json.dumps(pipeline_result.get('stages', {}).get('norm_compliance', {}), ensure_ascii=False, indent=2)
                    
                    # Pipeline-Zusammenfassung
                    multi_visio_pipeline_summary = json.dumps({
                        "pipeline_success": pipeline_result.get('pipeline_success', False),
                        "pipeline_duration_seconds": pipeline_result.get('pipeline_duration_seconds', 0),
                        "methodology": pipeline_result.get('methodology', '5_stage_prompt_chain'),
                        "document_type": pipeline_result.get('document_type', document_type),
                        "provider": pipeline_result.get('provider', ai_model),
                        "stages_completed": len([stage for stage in pipeline_result.get('stages', {}).keys()]),
                        "timestamp": pipeline_result.get('pipeline_start', datetime.now().isoformat())
                    }, ensure_ascii=False, indent=2)
                    
                    # Provider und Metriken
                    multi_visio_provider_used = ai_model or "auto"
                    multi_visio_total_duration = pipeline_result.get('pipeline_duration_seconds', 0)
                    
                    # Erfolgsrate berechnen
                    successful_stages = sum(
                        1 for stage in pipeline_result.get('stages', {}).values() 
                        if isinstance(stage, dict) and stage.get('success', False)
                    )
                    total_stages = len(pipeline_result.get('stages', {}))
                    multi_visio_success_rate = successful_stages / total_stages if total_stages > 0 else 0.0
                    
                    upload_logger.info(f"üéØ Multi-Visio Stufen-Ergebnisse extrahiert: {successful_stages}/{total_stages} erfolgreich")
                    
                except Exception as multi_visio_error:
                    upload_logger.error(f"‚ùå Multi-Visio-Verarbeitung fehlgeschlagen: {multi_visio_error}")
                    raise HTTPException(status_code=500, detail=f"Multi-Visio-Verarbeitung fehlgeschlagen: {str(multi_visio_error)}")
            
            # üöÄ ENHANCED SCHEMA METADATEN-EXTRAKTION (f√ºr beide Methoden)
            ai_result = None  # Initialisiere ai_result
            
            # üéØ Multi-Visio Variablen initialisieren (falls nicht Multi-Visio)
            multi_visio_stage1_result = None
            multi_visio_stage2_result = None
            multi_visio_stage3_result = None
            multi_visio_stage4_result = None
            multi_visio_stage5_result = None
            multi_visio_pipeline_summary = None
            multi_visio_provider_used = None
            multi_visio_total_duration = None
            multi_visio_success_rate = None
            
            # üéØ NEU: Original-Dokument und PNG-Metadaten
            original_document_path = None
            original_document_hash = None
            original_document_size = None
            original_document_mime_type = None
            png_preview_path = None
            png_preview_hash = None
            png_preview_size = None
            png_generation_timestamp = None
            png_generation_method = None
            conversion_success = True
            conversion_duration_seconds = None
            conversion_log = None
            
            # Pr√ºfe ob AI-Provider verf√ºgbar sind
            from .ai_engine import ai_engine
            ai_providers_available = ai_engine.check_providers_available()
            
            if ENHANCED_AI_AVAILABLE and extracted_text and ai_providers_available:
                upload_logger.info(f"üéØ Enhanced Schema Metadaten-Extraktion mit {ai_model}")
                
                try:
                    # Enhanced Metadata Extractor initialisieren
                    extractor = get_enhanced_extractor(ai_model if ai_model != "auto" else "openai")
                    
                    # Enhanced Metadata Extraction durchf√ºhren
                    enhanced_response = await extractor.extract_enhanced_metadata(
                        content=extracted_text,
                        document_title=title or file.filename,
                        document_type_hint=document_type,
                        include_chunking=True
                    )
                    
                    if enhanced_response.success:
                        enhanced_metadata = enhanced_response.metadata
                        
                        # Legacy-Format f√ºr R√ºckw√§rtskompatibilit√§t erstellen
                        ai_result = {
                            'document_type': enhanced_metadata.document_type.value,
                            'confidence': enhanced_metadata.ai_confidence,
                            'language': 'de',  # Enhanced Schema hat Language-Detection
                            'language_confidence': 0.9,
                            'quality_score': int(enhanced_metadata.quality_scores.overall * 10),
                            'keywords': [kw.term for kw in enhanced_metadata.primary_keywords[:5]],
                            'main_topics': [kw.term for kw in enhanced_metadata.qm_keywords[:3]],
                            'norm_references': enhanced_metadata.iso_standards_referenced,
                            'risk_level': enhanced_metadata.compliance_level.value,
                            'ai_summary': enhanced_metadata.description[:200] + "..." if len(enhanced_metadata.description) > 200 else enhanced_metadata.description,
                            'provider': ai_model if ai_model != "auto" else "openai"  # Provider hinzuf√ºgen
                        }
                        
                        upload_logger.info(f"‚úÖ Enhanced Schema erfolgreich: {enhanced_metadata.document_type.value} ({enhanced_metadata.ai_confidence:.1%} Konfidenz)")
                        
                    else:
                        upload_logger.warning(f"‚ö†Ô∏è Enhanced Schema fehlgeschlagen: {enhanced_response.errors}")
                        # Fallback zu alter AI-Engine
                        raise Exception("Enhanced Schema fehlgeschlagen")
                        
                except Exception as e:
                    upload_logger.warning(f"‚ùå Enhanced Schema Fehler: {e} - Fallback zu Legacy AI")
                    # Fallback zur alten AI-Engine
                    from .ai_engine import ai_engine
                    ai_result = await ai_engine.ai_enhanced_analysis_with_provider(
                        text=extracted_text,
                        document_type=document_type or "unknown",
                        preferred_provider=ai_model or "auto",
                        enable_debug=enable_debug.lower() == "true" if enable_debug else False
                    )
            
            # Keine Fallbacks - ehrliche Fehlermeldung wenn AI-Analyse fehlschl√§gt
            if ai_result is None:
                # F√ºr Testzwecke: Verwende Standardwerte ohne AI-Analyse
                upload_logger.info("üìù Keine AI-Analyse verf√ºgbar - Verwende Standardwerte f√ºr Test")
                ai_result = {
                    'document_type': document_type or 'OTHER',
                    'confidence': 0.5,
                    'language': 'de',
                    'language_confidence': 0.5,
                    'quality_score': 5,
                    'keywords': [],
                    'main_topics': [],
                    'norm_references': [],
                    'risk_level': 'mittel',
                    'ai_summary': 'Standardwerte - AI-Analyse nicht verf√ºgbar',
                    'provider': ai_model if ai_model != "auto" else "openai"  # Provider hinzuf√ºgen
                }
            
            # Legacy-Format f√ºr R√ºckw√§rtskompatibilit√§t erstellen
            legacy_result = type('AIResult', (), {
                'document_type': ai_result.get('document_type', 'OTHER'),
                'type_confidence': 0.8,  # Standardwert
                'detected_language': type('Lang', (), {'value': ai_result.get('language', 'de')})(),
                'language_confidence': 0.8,
                'content_quality_score': ai_result.get('quality_score', 5) / 10.0,
                'complexity_score': ai_result.get('quality_score', 5),
                'risk_level': ai_result.get('risk_level', 'mittel'),
                'extracted_keywords': ai_result.get('keywords', []),
                'compliance_keywords': ai_result.get('main_topics', []),
                'norm_references': ai_result.get('norm_references', []),
                'potential_duplicates': []
            })()
            
            # Dokumenttyp intelligent erkennen (falls nicht spezifiziert oder "OTHER")
            if not document_type or document_type == "OTHER":
                document_type = ai_result.get('document_type', 'OTHER')
                confidence = ai_result.get('confidence', 0.8)
                print(f"ü§ñ Intelligent erkannt: {file.filename} ‚Üí {document_type} ({confidence:.1%} Konfidenz)")
            
            # Spracherkennung
            detected_lang = ai_result.get('language', 'de')
            lang_confidence = ai_result.get('language_confidence', 0.8)
            print(f"üåç Sprache erkannt: {detected_lang} ({lang_confidence:.1%})")
            
            # Norm-Referenzen anzeigen
            norm_refs = ai_result.get('norm_references', [])
            if norm_refs:
                ref_names = [ref.get('norm_name', str(ref)) if isinstance(ref, dict) else str(ref) for ref in norm_refs]
                print(f"üìã Norm-Referenzen gefunden: {', '.join(ref_names)}")
            
            # Titel und Beschreibung automatisch extrahieren (falls nicht angegeben)
            if not title or not content:
                auto_title, auto_content = extract_smart_title_and_description(
                    extracted_text, file.filename
                )
                title = title or auto_title
                content = content or auto_content or f"Automatisch generiert - {ai_result.get('document_type', 'OTHER')}"
                
        # 2. Validierung der Eingaben
        if not title:
            raise HTTPException(status_code=400, detail="Titel ist erforderlich")
        
        # 3. Pr√ºfung auf Duplikate (pr√§ziser mit Metadaten)
        existing_doc = db.query(DocumentModel).filter(
            DocumentModel.title == title
        ).first()
        
        if existing_doc:
            # Intelligentere Duplikatspr√ºfung basierend auf Inhalt
            similarity_score = _calculate_content_similarity(
                existing_doc.extracted_text or "", 
                extracted_text
            )
            
            if similarity_score > 0.8:  # 80% √Ñhnlichkeit
                raise HTTPException(
                    status_code=409, 
                    detail=f"DUPLIKAT: Sehr √§hnliches Dokument bereits vorhanden: '{existing_doc.title}' (ID: {existing_doc.id}, √Ñhnlichkeit: {similarity_score:.1%})"
                )
        
        # 4. Dokument-Typ validieren und konvertieren
        try:
            # String zu DocumentType Enum konvertieren
            if isinstance(document_type, str):
                doc_type_enum = DocumentType(document_type)
            else:
                doc_type_enum = document_type
        except ValueError:
            raise HTTPException(
                status_code=400, 
                detail=f"Ung√ºltiger Dokumenttyp: {document_type}. Erlaubte Werte: {[e.value for e in DocumentType]}"
            )
        
        # 4. Dokument erstellen mit intelligenten Metadaten
        db_document = DocumentModel(
            title=title,
            document_number=generate_document_number(document_type),
            document_type=doc_type_enum,
            version=version,
            content=content,
            creator_id=creator_id,
            chapter_numbers=chapter_numbers,
            parent_document_id=None,  # Explizit auf None setzen
            
            # Datei-Informationen
            file_path=file_data.file_path if file_data else None,
            file_name=file_data.file_name if file_data else None,  # file_name nicht original_filename
            file_size=file_data.file_size if file_data else None,
            file_hash=file_data.file_hash if file_data else None,
            mime_type=file_data.mime_type if file_data else None,
            
            # Intelligente Text-Extraktion
            # ‚úÖ KRITISCH: Speichere die ECHTE JSON von der Vision API, nicht den escaped String!
            extracted_text=json.dumps(structured_analysis) if structured_analysis else extracted_text,
            keywords=", ".join(legacy_result.extracted_keywords),
            
            # NEU: Upload-Methoden-Felder
            upload_method=upload_method,
            validation_status=validation_status,
            structured_analysis=structured_analysis,
            prompt_used=prompt_used,
            ocr_text_preview=ocr_text_preview,
            
            # üéØ NEU: Original-Dokument und PNG-Metadaten
            original_document_path=original_document_path,
            original_document_hash=original_document_hash,
            original_document_size=original_document_size,
            original_document_mime_type=original_document_mime_type,
            png_preview_path=png_preview_path,
            png_preview_hash=png_preview_hash,
            png_preview_size=png_preview_size,
            png_generation_timestamp=png_generation_timestamp,
            png_generation_method=png_generation_method,
            conversion_success=conversion_success,
            conversion_duration_seconds=conversion_duration_seconds,
            conversion_log=conversion_log,
            
            # üéØ NEU: Multi-Visio Pipeline Stufen-Ergebnisse
            multi_visio_stage1_result=multi_visio_stage1_result if upload_method == "multi-visio" else None,
            multi_visio_stage2_result=multi_visio_stage2_result if upload_method == "multi-visio" else None,
            multi_visio_stage3_result=multi_visio_stage3_result if upload_method == "multi-visio" else None,
            multi_visio_stage4_result=multi_visio_stage4_result if upload_method == "multi-visio" else None,
            multi_visio_stage5_result=multi_visio_stage5_result if upload_method == "multi-visio" else None,
            multi_visio_pipeline_summary=multi_visio_pipeline_summary if upload_method == "multi-visio" else None,
            multi_visio_provider_used=multi_visio_provider_used if upload_method == "multi-visio" else None,
            multi_visio_total_duration=multi_visio_total_duration if upload_method == "multi-visio" else None,
            multi_visio_success_rate=multi_visio_success_rate if upload_method == "multi-visio" else None,
            
            # KI-Enhanced Metadaten-Felder
            compliance_status="ZU_BEWERTEN",
            priority=legacy_result.risk_level,
            
            # Zus√§tzliche KI-Metadaten (als JSON-String in bestehenden Feldern)
            remarks=f"{remarks or ''}\n\nü§ñ KI-Analyse ({ai_result.get('provider', 'unknown')}):\n- Sprache: {detected_lang} ({lang_confidence:.1%})\n- Qualit√§t: {legacy_result.content_quality_score:.1%}\n- Komplexit√§t: {legacy_result.complexity_score}/10\n- Compliance-Keywords: {', '.join(legacy_result.compliance_keywords[:5])}"
        )
        db.add(db_document)
        db.commit()
        db.refresh(db_document)
        
        upload_logger.info(f"‚úÖ Document erfolgreich erstellt: ID={db_document.id}, Title='{db_document.title}', Type={db_document.document_type}")
        upload_logger.info(f"‚è±Ô∏è Upload-Zeit: {time.time() - start_time:.2f}s")
        
        # Frontend-kompatible Antwort mit success-Feld
        response_data = {
            "success": True,
            "document": db_document,
            "structured_analysis": {
                "document_metadata": {
                    "title": db_document.title,
                    "document_type": db_document.document_type.value,
                    "version": db_document.version,
                    "status": db_document.status.value if db_document.status else "draft"
                },
                "extracted_text": db_document.extracted_text,
                "keywords": db_document.keywords.split(", ") if db_document.keywords else [],
                "ai_analysis": {
                    "provider": ai_result.get('provider', 'unknown'),
                    "quality_score": ai_result.get('quality_score', 5),
                    "language": ai_result.get('language', 'de'),
                    "compliance_status": db_document.compliance_status
                }
            },
            "summary": f"Dokument '{db_document.title}' erfolgreich erstellt und analysiert",
            "provider_used": ai_result.get('provider', 'unknown'),
            "duration_seconds": time.time() - start_time,
            "image_size_bytes": file_data.file_size if file_data else 0
        }
        
        # 5. üöÄ **ERWEITERTE RAG-INDEXIERUNG** mit Advanced AI
        if extracted_text and len(extracted_text.strip()) > 100:  # Nur sinnvolle Texte indexieren
            try:
                # UPGRADE: Advanced RAG Engine verwenden
                import asyncio
                
                # Advanced Indexierung mit Hierarchical Chunking und Enhanced Metadata
                async def async_advanced_index():
                    try:
                        # Advanced RAG mit Enhanced Schema Integration
                        enhanced_rag_metadata = {}
                        
                        # Enhanced Metadata f√ºr RAG integrieren (falls verf√ºgbar)
                        if ENHANCED_AI_AVAILABLE and 'enhanced_response' in locals() and enhanced_response.success:
                            enhanced_meta = enhanced_response.metadata
                            enhanced_rag_metadata = {
                                'enhanced_metadata': enhanced_meta,
                                'chunk_metadata': enhanced_response.chunks_metadata
                            }
                            upload_logger.info(f"‚úÖ Enhanced Metadata f√ºr RAG √ºbertragen: {len(enhanced_response.chunks_metadata)} Chunks")
                        
                        index_result = await advanced_rag_engine.index_document_advanced(
                            document_id=db_document.id,
                            title=db_document.title,
                            content=extracted_text,
                            document_type=db_document.document_type.value,
                            metadata={
                                'creator_id': db_document.creator_id,
                                'version': db_document.version,
                                'file_name': db_document.file_name,
                                'file_path': db_document.file_path,
                                'keywords': db_document.keywords or "",
                                'uploaded_at': datetime.utcnow().isoformat(),
                                **enhanced_rag_metadata  # Enhanced Schema Metadaten hinzuf√ºgen
                            }
                        )
                        upload_logger.info(f"üöÄ Advanced RAG Indexierung erfolgreich: {index_result}")
                        return index_result
                    except Exception as advanced_error:
                        upload_logger.warning(f"‚ö†Ô∏è Advanced RAG fehlgeschlagen, versuche Fallback: {advanced_error}")
                        # Fallback zu Basic Qdrant Engine
                        try:
                            from .qdrant_rag_engine import qdrant_rag_engine as basic_engine
                            fallback_result = await basic_engine.index_document(
                                document_id=db_document.id,
                                title=db_document.title,
                                content=extracted_text,
                                document_type=db_document.document_type.value,
                                metadata={'creator_id': db_document.creator_id}
                            )
                            upload_logger.info(f"‚úÖ Fallback Indexierung erfolgreich: {fallback_result}")
                            return fallback_result
                        except Exception as fallback_error:
                            upload_logger.error(f"‚ùå Auch Fallback-Indexierung fehlgeschlagen: {fallback_error}")
                            return None
                
                # Async Funktion ausf√ºhren (FastAPI kompatibel)
                try:
                    # KORRIGIERT: Task abwarten f√ºr sofortige Indexierung
                    upload_logger.info(f"üîÑ Advanced RAG Indexierung gestartet f√ºr Dokument {db_document.id}")
                    print(f"üöÄ Advanced RAG-Indexierung gestartet f√ºr '{db_document.title}' (ID: {db_document.id})")
                    
                    # WICHTIG: Indexierung sofort ausf√ºhren und abwarten
                    index_result = await async_advanced_index()
                    
                    if index_result:
                        upload_logger.info(f"‚úÖ Advanced RAG Indexierung ERFOLGREICH f√ºr Dokument {db_document.id}")
                        print(f"‚úÖ Dokument '{db_document.title}' erfolgreich in Qdrant indexiert!")
                    else:
                        upload_logger.warning(f"‚ö†Ô∏è Advanced RAG Indexierung fehlgeschlagen f√ºr Dokument {db_document.id}")
                        print(f"‚ö†Ô∏è Indexierung fehlgeschlagen f√ºr '{db_document.title}'")
                        
                except Exception as task_error:
                    upload_logger.error(f"‚ùå Advanced RAG Indexierung fehlgeschlagen: {task_error}")
                    print(f"‚ùå RAG-Indexierung Fehler: {task_error}")
                
            except Exception as rag_error:
                upload_logger.error(f"‚ùå Advanced RAG Setup fehlgeschlagen f√ºr Dokument {db_document.id}: {rag_error}")
                print(f"‚ö†Ô∏è Advanced RAG nicht verf√ºgbar: {rag_error}")
        else:
            print("‚è≠Ô∏è RAG-Indexierung √ºbersprungen (zu wenig Text)")
        
        # 6. üöÄ Workflow Engine aktivieren (falls verf√ºgbar)
        try:
            from .workflow_engine import WorkflowEngine
            
            workflow = WorkflowEngine()
            workflow_tasks = workflow.create_workflow_tasks(db_document, db)
            
            print(f"üìã Workflow gestartet: {len(workflow_tasks)} Aufgaben f√ºr {len(set(task.assigned_group for task in workflow_tasks))} Interessengruppen")
            
        except Exception as workflow_error:
            print(f"‚ö†Ô∏è Workflow-Fehler (nicht kritisch): {workflow_error}")
        
        # 6. Erfolgreiche Antwort - GIB ECHTES DOCUMENT OBJEKT ZUR√úCK!
        return db_document
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Dokument-Erstellung fehlgeschlagen: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Dokument-Erstellung fehlgeschlagen: {str(e)}")

def _calculate_content_similarity(text1: str, text2: str) -> float:
    """
    Berechnet Content-√Ñhnlichkeit zwischen zwei Texten.
    
    Args:
        text1: Erster Text
        text2: Zweiter Text
        
    Returns:
        float: √Ñhnlichkeitsscore (0.0 - 1.0)
    """
    if not text1 or not text2:
        return 0.0
    
    # Einfache Wort-basierte √Ñhnlichkeitsberechnung
    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())
    
    if not words1 or not words2:
        return 0.0
    
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    
    return len(intersection) / len(union) if union else 0.0

@app.get("/api/documents/{document_id}/download", tags=["Documents"])
async def download_document_file(document_id: int, db: Session = Depends(get_db)):
    """
    L√§dt eine Dokumentdatei herunter oder √∂ffnet sie im Browser.
    
    Args:
        document_id (int): ID des Dokuments
        
    Returns:
        FileResponse: Die Dokumentdatei zum Download/Anzeige
        
    Raises:
        HTTPException: 404 wenn Dokument oder Datei nicht gefunden
    """
    from fastapi.responses import FileResponse
    import os
    
    # Dokument aus DB laden
    document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
    if not document:
        raise HTTPException(
            status_code=404,
            detail=f"Dokument mit ID {document_id} nicht gefunden"
        )
    
    # Pr√ºfen ob Datei existiert
    if not document.file_path:
        raise HTTPException(
            status_code=404,
            detail="Keine Datei f√ºr dieses Dokument hinterlegt"
        )
    
    file_path = os.path.join("backend", document.file_path)
    if not os.path.exists(file_path):
        raise HTTPException(
            status_code=404,
            detail=f"Datei nicht gefunden: {document.file_path}"
        )
    
    # MIME-Type basierend auf Dateierweiterung
    import mimetypes
    mime_type, _ = mimetypes.guess_type(file_path)
    if not mime_type:
        mime_type = "application/octet-stream"
    
    # Dateiname f√ºr Download
    filename = os.path.basename(file_path)
    
    return FileResponse(
        path=file_path,
        media_type=mime_type,
        filename=filename,
        headers={
            "Content-Disposition": f"inline; filename={filename}"  # inline √∂ffnet im Browser
        }
    )

@app.post("/api/documents", response_model=Document, tags=["Documents"])
async def create_document(document: DocumentCreate, db: Session = Depends(get_db)):
    """
    Neues Dokument erstellen.
    
    Erstellt ein neues QMS-Dokument im System. Unterst√ºtzt alle
    14 QMS-spezifischen Dokumenttypen.
    
    Args:
        document (DocumentCreate): Daten des neuen Dokuments
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Document: Das erstellte Dokument
        
    Example Request:
        ```json
        {
            "title": "VA-003: Softwarevalidierung",
            "document_type": "VALIDATION_PROTOCOL",
            "description": "Validierungsprotokoll f√ºr die Embedded Software des Ger√§ts",
            "version": "1.0",
            "status": "DRAFT",
            "file_path": "/documents/validation-protocol-software-v1.0.pdf",
            "created_by": 8
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 15,
            "title": "VA-003: Softwarevalidierung",
            "document_type": "VALIDATION_PROTOCOL",
            "description": "Validierungsprotokoll f√ºr die Embedded Software des Ger√§ts",
            "version": "1.0", 
            "status": "DRAFT",
            "file_path": "/documents/validation-protocol-software-v1.0.pdf",
            "created_by": 8,
            "approved_by": null,
            "created_at": "2024-01-15T10:30:00Z",
            "approved_at": null
        }
        ```
        
    Raises:
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 404 wenn created_by User nicht existiert
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Titel sollte eindeutig sein (wird empfohlen)
        - created_at wird automatisch gesetzt
        - approved_by und approved_at bleiben null bis zur Freigabe
        - file_path sollte relativen Pfad enthalten
        
    Business Logic:
        - Status beginnt meist mit "DRAFT"
        - Version folgt Semantic Versioning (1.0, 1.1, 2.0)
        - Dokumenttyp bestimmt Workflow und Berechtigungen
    """
    # Pr√ºfen ob creator_id User existiert
    user_exists = db.query(UserModel).filter(UserModel.id == document.creator_id).first()
    if not user_exists:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Benutzer mit ID {document.creator_id} existiert nicht"
        )
    
    # ‚úÖ WICHTIG: document_number automatisch generieren!
    document_data = document.dict()
    document_data["document_number"] = generate_document_number(document.document_type)
    
    db_document = DocumentModel(**document_data)
    db.add(db_document)
    db.commit()
    db.refresh(db_document)
    return db_document

@app.put("/api/documents/{document_id}", response_model=Document, tags=["Documents"])
async def update_document(
    document_id: int,
    document_update: DocumentUpdate,
    db: Session = Depends(get_db)
):
    """
    Dokument aktualisieren.
    
    Aktualisiert ein bestehendes Dokument. F√ºr Versionierung,
    Status-√Ñnderungen und Freigabe-Workflows.
    
    Args:
        document_id (int): ID des zu aktualisierenden Dokuments
        document_update (DocumentUpdate): Zu aktualisierende Felder
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Document: Das aktualisierte Dokument
        
    Example Request (Status auf APPROVED setzen):
        ```json
        {
            "status": "APPROVED",
            "approved_by": 2,
            "approved_at": "2024-01-15T14:30:00Z"
        }
        ```
        
    Example Request (neue Version):
        ```json
        {
            "version": "1.1",
            "description": "√úberarbeitete Version nach internem Review",
            "status": "REVIEW"
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 7,
            "title": "SOP-005: Kalibrierungsverfahren",
            "document_type": "CALIBRATION_PROCEDURE",
            "description": "√úberarbeitete Version nach internem Review",
            "version": "1.1",
            "status": "REVIEW",
            "file_path": "/documents/sop-005-calibration-v1.1.pdf",
            "created_by": 5,
            "approved_by": null,
            "created_at": "2024-01-10T09:30:00Z",
            "approved_at": null
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Dokument nicht gefunden
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Nur √ºbermittelte Felder werden aktualisiert
        - approved_by und approved_at f√ºr Freigabe-Workflow
        - Versionierung f√ºr √Ñnderungsverfolgung
        
    Business Logic:
        - Status-Workflow: DRAFT ‚Üí REVIEW ‚Üí APPROVED ‚Üí OBSOLETE
        - Automatische Benachrichtigungen bei Status-√Ñnderungen
        - Audit-Trail f√ºr alle √Ñnderungen
    """
    db_document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
    if not db_document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Dokument mit ID {document_id} nicht gefunden"
        )
    
    update_data = document_update.dict(exclude_unset=True)
    for field, value in update_data.items():
        setattr(db_document, field, value)
    
    db.commit()
    db.refresh(db_document)
    return db_document

@app.delete("/api/documents/{document_id}", response_model=GenericResponse, tags=["Documents"])
async def delete_document(document_id: int, db: Session = Depends(get_db)):
    """
    Dokument l√∂schen.
    
    Entfernt ein Dokument aus dem System. F√ºr Dokumenten-Lifecycle-Management
    und Bereinigung veralteter Dokumente.
    
    Args:
        document_id (int): ID des zu l√∂schenden Dokuments
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        GenericResponse: Best√§tigung der L√∂schung
        
    Example Response:
        ```json
        {
            "message": "Dokument 'Veraltete Arbeitsanweisung v0.9' wurde gel√∂scht",
            "success": true
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Dokument nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Hard Delete: Dokument wird permanent entfernt
        - Datei auf Festplatte bleibt bestehen (separater Prozess)
        - F√ºr Compliance-relevante Dokumente vorsichtig verwenden
        
    Warning:
        - Genehmigte Dokumente sollten nicht gel√∂scht werden
        - Alternative: Status auf OBSOLETE setzen
        - Pr√ºfe Referenzen in anderen Dokumenten
    """
    try:
        db_document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
        if not db_document:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Dokument mit ID {document_id} nicht gefunden"
            )
        
        document_title = db_document.title
        
        # 1. Abh√§ngige Status-History-Eintr√§ge l√∂schen (CASCADE)
        from app.models import DocumentStatusHistory as StatusHistoryModel
        history_entries = db.query(StatusHistoryModel).filter(
            StatusHistoryModel.document_id == document_id
        ).delete()
        
        print(f"üóëÔ∏è {history_entries} Status-History-Eintr√§ge gel√∂scht f√ºr Dokument {document_id}")
        
        # 2. Advanced RAG-System bereinigen (falls verf√ºgbar)
        rag_cleanup_result = None
        if ADVANCED_AI_AVAILABLE:
            try:
                # Qdrant Collection bereinigen f√ºr dieses Dokument
                # Advanced RAG Engine hat keine direkte delete_document Funktion
                # Vector Cleanup wird vom System automatisch verwaltet
                print(f"üß† Advanced RAG: Vektoren f√ºr Dokument {document_id} werden automatisch bereinigt")
                rag_cleanup_result = {"success": True, "deleted_chunks": "auto-managed"}
            except Exception as e:
                print(f"‚ö†Ô∏è RAG-Cleanup fehlgeschlagen (nicht kritisch): {e}")
        
        # 3. Hauptdokument l√∂schen
        db.delete(db_document)
        db.commit()
        
        cleanup_info = ""
        if rag_cleanup_result and rag_cleanup_result.get('success'):
            cleanup_info = f" (+ {rag_cleanup_result.get('deleted_chunks', 0)} RAG-Chunks)"
        
        print(f"‚úÖ Dokument '{document_title}' erfolgreich gel√∂scht{cleanup_info}")
        return GenericResponse(
            message=f"Dokument '{document_title}' wurde gel√∂scht{cleanup_info}",
            success=True
        )
        
    except HTTPException:
        # Re-raise HTTP Exceptions
        raise
    except Exception as e:
        db.rollback()
        print(f"‚ùå Fehler beim L√∂schen von Dokument {document_id}: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Fehler beim L√∂schen des Dokuments: {str(e)}"
        )
async def get_documents_by_type(document_type: DocumentType, db: Session = Depends(get_db)):
    """
    Dokumente nach Typ filtern.
    
    L√§dt alle Dokumente eines spezifischen Typs. F√ºr typ-spezifische
    √úbersichten und Workflows.
    
    Args:
        document_type (DocumentType): Enum-Wert des Dokumenttyps
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[Document]: Liste aller Dokumente des Typs
        
    Example Request:
        ```
        GET /api/documents/by-type/SOP
        ```
        
    Example Response:
        ```json
        [
            {
                "id": 3,
                "title": "SOP-001: Lieferantenbewertung",
                "document_type": "SOP",
                "description": "Standardverfahren zur Bewertung von Lieferanten",
                "version": "1.3",
                "status": "APPROVED",
                "file_path": "/documents/sop-001-v1.3.pdf",
                "created_by": 3,
                "approved_by": 2,
                "created_at": "2024-01-10T09:20:00Z",
                "approved_at": "2024-01-18T16:30:00Z"
            }
        ]
        ```
        
    Raises:
        HTTPException: 400 bei ung√ºltigem Dokumenttyp
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Sortierung nach Titel (alphabetisch)
        - Alle Status werden angezeigt (DRAFT, REVIEW, APPROVED, OBSOLETE)
        - F√ºr typ-spezifische Dashboards geeignet
        
    Available Document Types:
        - QM_MANUAL, SOP, WORK_INSTRUCTION, FORM
        - USER_MANUAL, SERVICE_MANUAL, RISK_ASSESSMENT
        - VALIDATION_PROTOCOL, CALIBRATION_PROCEDURE
        - AUDIT_REPORT, CAPA_DOCUMENT, TRAINING_MATERIAL
        - SPECIFICATION, OTHER
    """
    documents = db.query(DocumentModel).filter(DocumentModel.document_type == document_type).all()
    return documents

# === DOCUMENT STATUS WORKFLOW API ===

@app.put("/api/documents/{document_id}/status", response_model=Document, tags=["Document Workflow"])
async def change_document_status(
    document_id: int,
    status_change: DocumentStatusChange,
    current_user: UserModel = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Dokumentstatus √§ndern mit QM-Workflow-Validierung.
    
    Implementiert den 4-stufigen QM-Workflow:
    - DRAFT ‚Üí REVIEWED: Alle k√∂nnen weiterleiten
    - REVIEWED ‚Üí APPROVED: Nur QM-Gruppe 
    - APPROVED ‚Üí OBSOLETE: Nur QM-Gruppe
    - OBSOLETE ‚Üí DRAFT: Nur QM-Gruppe (f√ºr Testing)
    """
    # Dokument laden
    document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
    if not document:
        raise HTTPException(status_code=404, detail="Dokument nicht gefunden")
    
    # QM-Berechtigung pr√ºfen (QMS Admin, Level 4 User oder quality_management Gruppe)
    from .auth import is_qms_admin
    user_groups = auth_get_user_groups(db, current_user)
    is_qm_user = (
        is_qms_admin(current_user) or 
        current_user.approval_level >= 4 or  # Level 4+ Users haben automatisch QM-Rechte
        "quality_management" in user_groups
    )
    
    # Aktueller und neuer Status
    old_status = document.status
    new_status = status_change.status
    
    # Status-√Ñnderungs-Validierung
    if old_status == new_status:
        raise HTTPException(status_code=400, detail="Neuer Status ist identisch mit aktuellem Status")
    
    # QM-Berechtigungen pr√ºfen
    qm_only_transitions = [
        (DocumentStatus.REVIEWED, DocumentStatus.APPROVED),  # Nur QM darf freigeben
        (DocumentStatus.APPROVED, DocumentStatus.OBSOLETE),  # Nur QM darf obsolet setzen
        (DocumentStatus.OBSOLETE, DocumentStatus.DRAFT),     # Nur QM darf reaktivieren (Testing)
    ]
    
    if (old_status, new_status) in qm_only_transitions and not is_qm_user:
        raise HTTPException(
            status_code=403, 
            detail=f"Status-Wechsel {old_status.value} ‚Üí {new_status.value} erfordert QM-Berechtigung"
        )
    
    # Status-History erstellen (vor der √Ñnderung)
    from .models import DocumentStatusHistory as StatusHistoryModel
    history_entry = StatusHistoryModel(
        document_id=document_id,
        old_status=old_status,
        new_status=new_status,
        changed_by_id=current_user.id,
        comment=status_change.comment
    )
    db.add(history_entry)
    
    # Dokument-Status aktualisieren
    document.status = new_status
    document.status_changed_by_id = current_user.id
    document.status_changed_at = datetime.utcnow()
    document.status_comment = status_change.comment
    
    # Workflow-spezifische Felder setzen
    if new_status == DocumentStatus.REVIEWED:
        document.reviewed_by_id = current_user.id
        document.reviewed_at = datetime.utcnow()
    elif new_status == DocumentStatus.APPROVED:
        document.approved_by_id = current_user.id
        document.approved_at = datetime.utcnow()
    
    # Benachrichtigung generieren (Console Log f√ºr MVP)
    notification = generate_status_notification(document, old_status, new_status, current_user, is_qm_user)
    print(f"üìß NOTIFICATION: {notification.message}")
    print(f"   Recipients: {', '.join(notification.recipients)}")
    
    try:
        db.commit()
        db.refresh(document)
        return document
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Fehler beim Status-Update: {str(e)}")

@app.get("/api/documents/{document_id}/status-history", response_model=List[DocumentStatusHistory], tags=["Document Workflow"])
async def get_document_status_history(
    document_id: int,
    db: Session = Depends(get_db)
):
    """Status-√Ñnderungshistorie eines Dokuments abrufen (Audit-Trail)."""
    # Dokument existiert pr√ºfen
    document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
    if not document:
        raise HTTPException(status_code=404, detail="Dokument nicht gefunden")
    
    # Status-History laden mit User-Beziehung
    from .models import DocumentStatusHistory as StatusHistoryModel
    from sqlalchemy.orm import joinedload
    history = db.query(StatusHistoryModel).options(
        joinedload(StatusHistoryModel.changed_by)
    ).filter(
        StatusHistoryModel.document_id == document_id
    ).order_by(StatusHistoryModel.changed_at.desc()).all()
    
    return history

@app.get("/api/documents/status/{status}", response_model=List[Document], tags=["Document Workflow"])
async def get_documents_by_status(
    status: DocumentStatus,
    skip: int = 0,
    limit: int = 20,
    db: Session = Depends(get_db)
):
    """Alle Dokumente mit einem bestimmten Status abrufen (f√ºr Workflow-Dashboards)."""
    documents = db.query(DocumentModel).filter(
        DocumentModel.status == status
    ).order_by(DocumentModel.updated_at.desc()).offset(skip).limit(limit).all()
    
    return documents

def generate_status_notification(
    document: DocumentModel, 
    old_status: DocumentStatus, 
    new_status: DocumentStatus, 
    changed_by: UserModel,
    is_qm_user: bool
) -> NotificationInfo:
    """Generiert Console-Log Benachrichtigungen f√ºr Status-√Ñnderungen (MVP)."""
    # Standard QM-Gruppe f√ºr alle QM-relevanten Benachrichtigungen
    qm_emails = ["qm@company.com"]  # Placeholder
    
    # Status-spezifische Nachrichten und Empf√§nger
    if new_status == DocumentStatus.REVIEWED:
        message = f"üìã Dokument '{document.title}' wurde zur QM-Freigabe eingereicht"
        recipients = qm_emails
    elif new_status == DocumentStatus.APPROVED:
        message = f"‚úÖ Dokument '{document.title}' wurde von QM freigegeben"
        recipients = [document.creator.email] if document.creator else []
    elif new_status == DocumentStatus.OBSOLETE:
        message = f"üóëÔ∏è Dokument '{document.title}' wurde als obsolet markiert"
        recipients = [document.creator.email] if document.creator else []
    else:
        message = f"üìù Dokument '{document.title}' Status ge√§ndert: {old_status.value} ‚Üí {new_status.value}"
        recipients = []
    
    return NotificationInfo(
        message=message,
        recipients=recipients,
        document_title=document.title,
        new_status=new_status,
        changed_by=changed_by.full_name
    )

# === NORMS API ===

@app.get("/api/norms", response_model=List[Norm], tags=["Norms"])
async def get_norms(skip: int = 0, limit: int = 20, db: Session = Depends(get_db)):
    """
    Alle Normen abrufen.
    
    L√§dt eine paginierte Liste aller im System erfassten Normen und
    Compliance-Standards (ISO 13485, MDR, ISO 14971, etc.).
    
    Args:
        skip (int): Anzahl zu √ºberspringender Datens√§tze. Default: 0
        limit (int): Maximale Anzahl zur√ºckzugebender Datens√§tze. Default: 20, Max: 100
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[Norm]: Liste aller Normen im System
        
    Example Response:
        ```json
        [
            {
                "id": 1,
                "name": "ISO 13485:2016",
                "title": "Medical devices ‚Äî Quality management systems ‚Äî Requirements for regulatory purposes",
                "description": "Internationale Norm f√ºr Qualit√§tsmanagementsysteme in der Medizinprodukteindustrie",
                "category": "QMS",
                "version": "2016",
                "effective_date": "2016-03-01",
                "authority": "ISO",
                "is_mandatory": true,
                "created_at": "2024-01-15T10:30:00Z"
            },
            {
                "id": 2,
                "name": "MDR 2017/745",
                "title": "Medical Device Regulation",
                "description": "EU-Verordnung √ºber Medizinprodukte, g√ºltig seit Mai 2021",
                "category": "REGULATION",
                "version": "2017",
                "effective_date": "2021-05-26",
                "authority": "EU Commission",
                "is_mandatory": true,
                "created_at": "2024-01-15T10:30:00Z"
            }
        ]
        ```
        
    Raises:
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Normen sind nach effective_date sortiert (neueste zuerst)
        - is_mandatory zeigt regulatorische Verpflichtung an
        - category gruppiert Normen thematisch
        
    Common Categories:
        - QMS: Qualit√§tsmanagementsystem
        - REGULATION: EU/FDA Verordnungen
        - RISK_MANAGEMENT: Risikomanagement
        - SOFTWARE: Software-Lifecycle
        - CLINICAL: Klinische Bewertung
    """
    norms = db.query(NormModel).offset(skip).limit(limit).all()
    return norms

@app.get("/api/norms/{norm_id}", response_model=Norm, tags=["Norms"])
async def get_norm(norm_id: int, db: Session = Depends(get_db)):
    """
    Eine spezifische Norm abrufen.
    
    L√§dt eine einzelne Norm mit allen Details f√ºr die Norm-Analyse
    und Compliance-Pr√ºfung.
    
    Args:
        norm_id (int): Eindeutige ID der Norm
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Norm: Detaillierte Norminformationen
        
    Example Response:
        ```json
        {
            "id": 3,
            "name": "ISO 14971:2019",
            "title": "Medical devices ‚Äî Application of risk management to medical devices",
            "description": "Standard f√ºr Risikomanagement bei Medizinprodukten √ºber den gesamten Produktlebenszyklus",
            "category": "RISK_MANAGEMENT",
            "version": "2019",
            "effective_date": "2019-12-01",
            "authority": "ISO",
            "is_mandatory": true,
            "created_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Norm nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - F√ºr AI-basierte Norm-Analyse verwendbar
        - effective_date wichtig f√ºr Compliance-Zeitr√§ume
        - authority zeigt herausgebende Organisation
    """
    norm = db.query(NormModel).filter(NormModel.id == norm_id).first()
    if not norm:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Norm mit ID {norm_id} nicht gefunden"
        )
    return norm

@app.post("/api/norms", response_model=Norm, tags=["Norms"])
async def create_norm(norm: NormCreate, db: Session = Depends(get_db)):
    """
    Neue Norm erstellen.
    
    Erstellt eine neue Norm oder einen Compliance-Standard im System.
    F√ºr Erweiterung der Norm-Bibliothek.
    
    Args:
        norm (NormCreate): Daten der neuen Norm
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Norm: Die erstellte Norm
        
    Example Request:
        ```json
        {
            "name": "IEC 62304:2006+A1:2015",
            "title": "Medical device software ‚Äî Software life cycle processes",
            "description": "Internationale Norm f√ºr Software-Lifecycle-Prozesse bei Medizinprodukten",
            "category": "SOFTWARE",
            "version": "2015",
            "effective_date": "2015-06-01",
            "authority": "IEC",
            "is_mandatory": true
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 8,
            "name": "IEC 62304:2006+A1:2015",
            "title": "Medical device software ‚Äî Software life cycle processes",
            "description": "Internationale Norm f√ºr Software-Lifecycle-Prozesse bei Medizinprodukten",
            "category": "SOFTWARE",
            "version": "2015",
            "effective_date": "2015-06-01",
            "authority": "IEC",
            "is_mandatory": true,
            "created_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 409 wenn Norm bereits existiert
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - name sollte eindeutig sein (Norm-Bezeichnung)
        - effective_date f√ºr Compliance-√úberwachung wichtig
        - is_mandatory unterscheidet zwischen Pflicht und freiwillig
        
    Business Logic:
        - Neue Normen automatisch in Gap-Analyse einbeziehen
        - Benachrichtigung an QM-Team bei neuen Pflichtnormen
        - Version-Tracking f√ºr Norm-Updates
    """
    # Pr√ºfen ob Norm bereits existiert
    existing_norm = db.query(NormModel).filter(NormModel.name == norm.name).first()
    if existing_norm:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Norm '{norm.name}' existiert bereits"
        )
    
    db_norm = NormModel(**norm.dict())
    db.add(db_norm)
    db.commit()
    db.refresh(db_norm)
    return db_norm

@app.put("/api/norms/{norm_id}", response_model=Norm, tags=["Norms"])
async def update_norm(
    norm_id: int,
    norm_update: NormUpdate,
    db: Session = Depends(get_db)
):
    """
    Norm aktualisieren.
    
    Aktualisiert eine bestehende Norm (z.B. neue Version, ge√§nderte Details).
    F√ºr Norm-Maintenance und Version-Updates.
    
    Args:
        norm_id (int): ID der zu aktualisierenden Norm
        norm_update (NormUpdate): Zu aktualisierende Felder
        db (Session): Datenbankverbindung
        
    Returns:
        Norm: Die aktualisierte Norm
    """
    db_norm = db.query(NormModel).filter(NormModel.id == norm_id).first()
    if not db_norm:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Norm mit ID {norm_id} nicht gefunden"
        )
    
    update_data = norm_update.dict(exclude_unset=True)
    
    # Pr√ºfen auf Name-Konflikte bei √Ñnderung
    if "name" in update_data:
        existing_norm = db.query(NormModel).filter(
            NormModel.name == update_data["name"],
            NormModel.id != norm_id
        ).first()
        if existing_norm:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"Norm mit Name '{update_data['name']}' existiert bereits"
            )
    
    for field, value in update_data.items():
        setattr(db_norm, field, value)
    
    db.commit()
    db.refresh(db_norm)
    return db_norm

@app.delete("/api/norms/{norm_id}", response_model=GenericResponse, tags=["Norms"])
async def delete_norm(norm_id: int, db: Session = Depends(get_db)):
    """
    Norm l√∂schen.
    
    L√∂scht eine Norm aus dem System. **Vorsicht:** Pr√ºft Abh√§ngigkeiten zu Dokumenten.
    
    Args:
        norm_id (int): ID der zu l√∂schenden Norm
        db (Session): Datenbankverbindung
        
    Returns:
        GenericResponse: Best√§tigung der L√∂schung
    """
    db_norm = db.query(NormModel).filter(NormModel.id == norm_id).first()
    if not db_norm:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Norm mit ID {norm_id} nicht gefunden"
        )
    
    # Pr√ºfen auf Abh√§ngigkeiten (falls zuk√ºnftig Norm-Dokument-Verkn√ºpfungen existieren)
    # TODO: Erweitern wenn Norm-Referenzen in anderen Tabellen existieren
    
    norm_name = db_norm.name
    db.delete(db_norm)
    db.commit()
    
    return GenericResponse(
        message=f"Norm '{norm_name}' wurde erfolgreich gel√∂scht",
        success=True
    )
# === EQUIPMENT API ===

@app.get("/api/equipment", response_model=List[Equipment], tags=["Equipment"])
async def get_equipment(skip: int = 0, limit: int = 20, db: Session = Depends(get_db)):
    """
    Alle Equipment-Eintr√§ge abrufen.
    
    L√§dt eine paginierte Liste aller im System erfassten Ger√§te und
    Ausr√ºstungen mit ihren Kalibrierungsstatusangaben.
    
    Args:
        skip (int): Anzahl zu √ºberspringender Datens√§tze. Default: 0
        limit (int): Maximale Anzahl zur√ºckzugebender Datens√§tze. Default: 20, Max: 100
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[Equipment]: Liste aller Equipment-Eintr√§ge
        
    Example Response:
        ```json
        [
            {
                "id": 1,
                "name": "Digitaler Messschieber Mitutoyo",
                "equipment_type": "measuring_device",
                "serial_number": "MIT-2024-001",
                "manufacturer": "Mitutoyo Corporation",
                "model": "CD-15DCX",
                "location": "Qualit√§tslabor - Messplatz 1",
                "calibration_interval_months": 12,
                "last_calibration": "2023-06-15",
                "next_calibration": "2024-06-15",
                "status": "active",
                "notes": "Pr√§zisionsmessger√§t f√ºr Dimensionskontrolle",
                "created_at": "2024-01-15T10:30:00Z"
            },
            {
                "id": 3,
                "name": "Analytische Waage Sartorius",
                "equipment_type": "laboratory_scale",
                "serial_number": "SAR-2023-003",
                "manufacturer": "Sartorius AG",
                "model": "MSE225P-100-DA",
                "location": "Chemielabor - Abzug 2",
                "calibration_interval_months": 6,
                "last_calibration": "2023-12-01",
                "next_calibration": "2024-06-01",
                "status": "active",
                "notes": "Mikrowaage f√ºr Substanzanalysen, t√§gliche Funktionskontrolle",
                "created_at": "2024-01-15T10:30:00Z"
            }
        ]
        ```
        
    Raises:
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - next_calibration f√ºr Fristen√ºberwachung wichtig
        - status zeigt Betriebszustand ("active", "maintenance", "retired")
        - Sortierung nach next_calibration (f√§llige zuerst)
        
    Equipment Types:
        - measuring_device: Messger√§te
        - laboratory_scale: Laborwaagen
        - temperature_monitor: Temperatur√ºberwachung
        - pressure_gauge: Druckmessger√§te
        - test_equipment: Pr√ºfger√§te
        - production_tool: Produktionswerkzeuge
    """
    equipment = db.query(EquipmentModel).offset(skip).limit(limit).all()
    return equipment

@app.get("/api/equipment/overdue", response_model=List[Equipment], tags=["Equipment"])
async def get_overdue_equipment(db: Session = Depends(get_db)):
    """
    √úberf√§llige Equipment-Kalibrierungen abrufen.
    
    Zeigt alle Ger√§te an, deren Kalibrierung bereits √ºberf√§llig ist.
    Kritisch f√ºr Compliance und Produktqualit√§t.
    
    Returns:
        List[Equipment]: Liste aller √ºberf√§lligen Ger√§te
    """
    from datetime import date
    today = date.today()
    
    overdue_equipment = db.query(EquipmentModel).filter(
        EquipmentModel.next_calibration < today
    ).all()
    
    return overdue_equipment

@app.get("/api/equipment/{equipment_id}", response_model=Equipment, tags=["Equipment"])
async def get_equipment_item(equipment_id: int, db: Session = Depends(get_db)):
    """
    Ein spezifisches Equipment abrufen.
    
    L√§dt ein einzelnes Ger√§t mit allen Details f√ºr die Equipment-Verwaltung
    und Kalibrierungsplanung.
    
    Args:
        equipment_id (int): Eindeutige ID des Equipments
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Equipment: Detaillierte Equipment-Informationen
        
    Example Response:
        ```json
        {
            "id": 4,
            "name": "Umwelttestkammer Heraeus",
            "equipment_type": "environmental_chamber",
            "serial_number": "HER-2022-004",
            "manufacturer": "Heraeus Medical GmbH",
            "model": "UT6760",
            "location": "Testlabor - Pr√ºfstand B",
            "calibration_interval_months": 12,
            "last_calibration": "2023-08-20",
            "next_calibration": "2024-08-20",
            "status": "active",
            "notes": "Klimapr√ºfschrank f√ºr Alterungstests, Temperaturbereich -40¬∞C bis +180¬∞C",
            "created_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Equipment nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Vollst√§ndige Ger√§te-Historie verf√ºgbar
        - Verkn√ºpfung zu Kalibrierungsprotokollen √ºber ID
        - Standort-Tracking f√ºr Asset-Management
    """
    equipment = db.query(EquipmentModel).filter(EquipmentModel.id == equipment_id).first()
    if not equipment:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Equipment mit ID {equipment_id} nicht gefunden"
        )
    return equipment

@app.post("/api/equipment", response_model=Equipment, tags=["Equipment"])
async def create_equipment(equipment: EquipmentCreate, db: Session = Depends(get_db)):
    """
    Neues Equipment erstellen.
    
    Registriert ein neues Ger√§t oder eine neue Ausr√ºstung im System
    mit automatischer Kalibrierungsplanung.
    
    Args:
        equipment (EquipmentCreate): Daten des neuen Equipments
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Equipment: Das erstellte Equipment
        
    Example Request:
        ```json
        {
            "name": "pH-Meter Mettler Toledo",
            "equipment_type": "measuring_device",
            "serial_number": "MET-2024-007",
            "manufacturer": "Mettler Toledo International Inc.",
            "model": "FiveEasy F20",
            "location": "Qualit√§tskontrolle - Analytik",
            "calibration_interval_months": 6,
            "last_calibration": "2024-01-15",
            "status": "active",
            "notes": "pH-Messger√§t f√ºr Pufferl√∂sungen und Produktkontrollen"
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 12,
            "name": "pH-Meter Mettler Toledo",
            "equipment_type": "measuring_device",
            "serial_number": "MET-2024-007",
            "manufacturer": "Mettler Toledo International Inc.",
            "model": "FiveEasy F20",
            "location": "Qualit√§tskontrolle - Analytik",
            "calibration_interval_months": 6,
            "last_calibration": "2024-01-15",
            "next_calibration": "2024-07-15",
            "status": "active",
            "notes": "pH-Messger√§t f√ºr Pufferl√∂sungen und Produktkontrollen",
            "created_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 409 wenn Seriennummer bereits existiert
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - serial_number muss eindeutig sein
        - next_calibration wird automatisch berechnet
        - status ist standardm√§√üig "active"
        - Automatische Erinnerungen vor Kalibrierungsterminen
        
    Business Logic:
        - Kalibrierungsintervall basiert auf Ger√§tetyp und Kritikalit√§t
        - Asset-Tracking f√ºr Wartungsplanung
        - Integration mit Kalibrierungs-Workflow
    """
    # Pr√ºfen ob Seriennummer bereits existiert
    existing_equipment = db.query(EquipmentModel).filter(
        EquipmentModel.serial_number == equipment.serial_number
    ).first()
    if existing_equipment:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Equipment mit Seriennummer '{equipment.serial_number}' existiert bereits"
        )
    
    db_equipment = EquipmentModel(**equipment.dict())
    db.add(db_equipment)
    db.commit()
    db.refresh(db_equipment)
    return db_equipment

@app.put("/api/equipment/{equipment_id}", response_model=Equipment, tags=["Equipment"])
async def update_equipment(
    equipment_id: int,
    equipment_update: EquipmentUpdate,
    db: Session = Depends(get_db)
):
    """
    Equipment aktualisieren.
    
    Aktualisiert ein bestehendes Equipment. F√ºr Versionierung,
    Status-√Ñnderungen und Freigabe-Workflows.
    
    Args:
        equipment_id (int): ID des zu aktualisierenden Equipments
        equipment_update (EquipmentUpdate): Zu aktualisierende Felder
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Equipment: Das aktualisierte Equipment
        
    Example Request (Status auf APPROVED setzen):
        ```json
        {
            "status": "APPROVED",
            "approved_by": 2,
            "approved_at": "2024-01-15T14:30:00Z"
        }
        ```
        
    Example Request (neue Version):
        ```json
        {
            "version": "1.1",
            "description": "√úberarbeitete Version nach internem Review",
            "status": "REVIEW"
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 12,
            "name": "pH-Meter Mettler Toledo",
            "equipment_type": "measuring_device",
            "serial_number": "MET-2024-007",
            "manufacturer": "Mettler Toledo International Inc.",
            "model": "FiveEasy F20",
            "location": "Qualit√§tskontrolle - Analytik",
            "calibration_interval_months": 6,
            "last_calibration": "2024-01-15",
            "next_calibration": "2024-07-15",
            "status": "active",
            "notes": "pH-Messger√§t f√ºr Pufferl√∂sungen und Produktkontrollen",
            "created_at": "2024-01-15T10:30:00Z"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Equipment nicht gefunden
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Nur √ºbermittelte Felder werden aktualisiert
        - approved_by und approved_at f√ºr Freigabe-Workflow
        - Versionierung f√ºr √Ñnderungsverfolgung
        
    Business Logic:
        - Status-Workflow: DRAFT ‚Üí REVIEW ‚Üí APPROVED ‚Üí OBSOLETE
        - Automatische Benachrichtigungen bei Status-√Ñnderungen
        - Audit-Trail f√ºr alle √Ñnderungen
    """
    db_equipment = db.query(EquipmentModel).filter(EquipmentModel.id == equipment_id).first()
    if not db_equipment:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Equipment mit ID {equipment_id} nicht gefunden"
        )
    
    update_data = equipment_update.dict(exclude_unset=True)
    for field, value in update_data.items():
        setattr(db_equipment, field, value)
    
    db.commit()
    db.refresh(db_equipment)
    return db_equipment

@app.delete("/api/equipment/{equipment_id}", response_model=GenericResponse, tags=["Equipment"])
async def delete_equipment(equipment_id: int, db: Session = Depends(get_db)):
    """
    Equipment l√∂schen.
    
    Entfernt ein Equipment aus dem System. F√ºr Equipment-Lifecycle-Management
    und Bereinigung veralteter Equipment.
    
    Args:
        equipment_id (int): ID des zu l√∂schenden Equipments
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        GenericResponse: Best√§tigung der L√∂schung
        
    Example Response:
        ```json
        {
            "message": "Equipment 'Umwelttestkammer Heraeus' wurde gel√∂scht",
            "success": true
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Equipment nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Hard Delete: Equipment wird permanent entfernt
        - Datei auf Festplatte bleibt bestehen (separater Prozess)
        - F√ºr Compliance-relevante Equipment vorsichtig verwenden
        
    Warning:
        - Genehmigte Equipment sollten nicht gel√∂scht werden
        - Alternative: Status auf OBSOLETE setzen
        - Pr√ºfe Referenzen in anderen Dokumenten
    """
    db_equipment = db.query(EquipmentModel).filter(EquipmentModel.id == equipment_id).first()
    if not db_equipment:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Equipment mit ID {equipment_id} nicht gefunden"
        )
    
    # Pr√ºfen auf aktive Abh√§ngigkeiten (z.B. laufende Kalibrierungen)
    from app.models import Calibration as CalibrationModel
    active_calibrations = db.query(CalibrationModel).filter(
        CalibrationModel.equipment_id == equipment_id,
        CalibrationModel.status == "valid"
    ).count()
    
    if active_calibrations > 0:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Equipment kann nicht gel√∂scht werden: {active_calibrations} aktive Kalibrierungen zugeordnet"
        )
    
    equipment_name = db_equipment.name
    db.delete(db_equipment)
    db.commit()
    return GenericResponse(
        message=f"Equipment '{equipment_name}' wurde gel√∂scht",
        success=True
    )



# === CALIBRATIONS API ===

@app.get("/api/calibrations", response_model=List[Calibration], tags=["Calibrations"])
async def get_calibrations(skip: int = 0, limit: int = 20, db: Session = Depends(get_db)):
    """
    Alle Kalibrierungen abrufen.
    
    L√§dt eine paginierte Liste aller durchgef√ºhrten Kalibrierungen
    mit Ergebnissen und Metadaten.
    
    Args:
        skip (int): Anzahl zu √ºberspringender Datens√§tze. Default: 0
        limit (int): Maximale Anzahl zur√ºckzugebender Datens√§tze. Default: 20, Max: 100
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[Calibration]: Liste aller Kalibrierungsprotokoll
        
    Example Response:
        ```json
        [
            {
                "id": 1,
                "equipment_id": 1,
                "calibration_date": "2024-01-10",
                "calibrated_by": "Max Mustermann, DAkkS Lab",
                "certificate_number": "DAkkS-K-12345-2024",
                "result": "passed",
                "deviation": "¬±0.002 mm",
                "notes": "Alle Messungen innerhalb der Toleranzen",
                "next_calibration_date": "2025-01-10",
                "file_path": "/calibrations/dakkS-k-12345-2024.pdf",
                "created_at": "2024-01-10T14:30:00Z"
            },
            {
                "id": 3,
                "equipment_id": 3,
                "calibration_date": "2023-12-01",
                "calibrated_by": "Sartorius Service Team",
                "certificate_number": "SAR-CAL-2023-045",
                "result": "passed",
                "deviation": "¬±0.0001 g",
                "notes": "Waage innerhalb der Spezifikationen, Eckenlast gepr√ºft",
                "next_calibration_date": "2024-06-01",
                "file_path": "/calibrations/sartorius-cal-2023-045.pdf",
                "created_at": "2023-12-01T09:15:00Z"
            }
        ]
        ```
        
    Raises:
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Sortierung nach calibration_date (neueste zuerst)
        - file_path verweist auf Kalibrierungs-Zertifikate
        - result: "passed", "failed", "conditional"
        - certificate_number f√ºr R√ºckverfolgbarkeit wichtig
        
    Calibration Results:
        - passed: Erfolgreich, alle Toleranzen eingehalten
        - failed: Fehlgeschlagen, au√üerhalb der Toleranzen
        - conditional: Bedingt bestanden, mit Einschr√§nkungen
    """
    calibrations = db.query(CalibrationModel).offset(skip).limit(limit).all()
    return calibrations

@app.get("/api/calibrations/{calibration_id}", response_model=Calibration, tags=["Calibrations"])
async def get_calibration(calibration_id: int, db: Session = Depends(get_db)):
    """
    Eine spezifische Kalibrierung abrufen.
    
    L√§dt ein einzelnes Kalibrierungsprotokoll mit allen Details
    f√ºr die Dokumentation und Audit-Zwecke.
    
    Args:
        calibration_id (int): Eindeutige ID der Kalibrierung
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Calibration: Detaillierte Kalibrierungsinformationen
        
    Example Response:
        ```json
        {
            "id": 4,
            "equipment_id": 4,
            "calibration_date": "2023-08-20",
            "calibrated_by": "Heraeus Service Center M√ºnchen",
            "certificate_number": "HER-ENV-2023-890",
            "result": "passed",
            "deviation": "Temperatur: ¬±0.3¬∞C, Feuchte: ¬±2.5% rH",
            "notes": "Umweltkammer vollst√§ndig kalibriert, alle Sensoren innerhalb der Spezifikation. 18-Punkt-Kalibrierung durchgef√ºhrt.",
            "next_calibration_date": "2024-08-20",
            "file_path": "/calibrations/heraeus-env-2023-890.pdf",
            "created_at": "2023-08-20T16:45:00Z"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Kalibrierung nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Vollst√§ndige Dokumentation f√ºr Audit-Trail
        - deviation zeigt gemessene Abweichungen
        - file_path f√ºr Zertifikat-Download
        - Verkn√ºpfung zu Equipment √ºber equipment_id
    """
    calibration = db.query(CalibrationModel).filter(CalibrationModel.id == calibration_id).first()
    if not calibration:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Kalibrierung mit ID {calibration_id} nicht gefunden"
        )
    return calibration
@app.post("/api/calibrations", response_model=Calibration, tags=["Calibrations"])
async def create_calibration(calibration: CalibrationCreate, db: Session = Depends(get_db)):
    """
    Neue Kalibrierung erstellen.
    
    Dokumentiert eine durchgef√ºhrte Kalibrierung und aktualisiert
    automatisch den Kalibrierungsstatus des zugeh√∂rigen Equipments.
    
    Args:
        calibration (CalibrationCreate): Daten der neuen Kalibrierung
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Calibration: Die erstellte Kalibrierung
        
    Example Request:
        ```json
        {
            "equipment_id": 5,
            "calibration_date": "2024-01-15",
            "calibrated_by": "T√úV S√úD Industrie Service",
            "certificate_number": "TUV-IS-2024-1234",
            "result": "passed",
            "deviation": "¬±0.1¬∞C bei 37¬∞C Referenztemperatur",
            "notes": "Inkubator kalibriert nach DIN EN 60601-2-19, alle Temperatursensoren gepr√ºft",
            "next_calibration_date": "2025-01-15",
            "file_path": "/calibrations/tuv-is-2024-1234.pdf"
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 8,
            "equipment_id": 5,
            "calibration_date": "2024-01-15",
            "calibrated_by": "T√úV S√úD Industrie Service",
            "certificate_number": "TUV-IS-2024-1234",
            "result": "passed",
            "deviation": "¬±0.1¬∞C bei 37¬∞C Referenztemperatur",
            "notes": "Inkubator kalibriert nach DIN EN 60601-2-19, alle Temperatursensoren gepr√ºft",
            "next_calibration_date": "2025-01-15",
            "file_path": "/calibrations/tuv-is-2024-1234.pdf",
            "created_at": "2024-01-15T11:20:00Z"
        }
        ```
        
    Raises:
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 404 wenn Equipment nicht existiert
        HTTPException: 409 wenn Zertifikatsnummer bereits existiert
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - equipment_id muss existieren
        - certificate_number sollte eindeutig sein
        - Automatische Aktualisierung der Equipment-Kalibrierungsdaten
        - file_path f√ºr PDF-Zertifikat wichtig
        
    Business Logic:
        - Equipment last_calibration und next_calibration werden aktualisiert
        - Status-Benachrichtigungen an verantwortliche Teams
        - Automatische Planung der n√§chsten Kalibrierung
        - Compliance-Dokumentation f√ºr Audits
    """
    # Pr√ºfen ob Equipment existiert
    equipment = db.query(EquipmentModel).filter(EquipmentModel.id == calibration.equipment_id).first()
    if not equipment:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Equipment mit ID {calibration.equipment_id} nicht gefunden"
        )
    
    # Pr√ºfen ob Zertifikatsnummer bereits existiert
    existing_cal = db.query(CalibrationModel).filter(
        CalibrationModel.certificate_number == calibration.certificate_number
    ).first()
    if existing_cal:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Kalibrierung mit Zertifikatsnummer '{calibration.certificate_number}' existiert bereits"
        )
    
    # Kalibrierung erstellen
    db_calibration = CalibrationModel(**calibration.dict())
    db.add(db_calibration)
    
    # Equipment-Kalibrierungsdaten aktualisieren
    equipment.last_calibration = calibration.calibration_date
    equipment.next_calibration = calibration.next_calibration_date
    
    db.commit()
    db.refresh(db_calibration)
    return db_calibration

@app.put("/api/calibrations/{calibration_id}", response_model=Calibration, tags=["Calibrations"])
async def update_calibration(
    calibration_id: int,
    calibration_update: CalibrationUpdate,
    db: Session = Depends(get_db)
):
    """
    Kalibrierung aktualisieren.
    
    Aktualisiert eine bestehende Kalibrierung. F√ºr Versionierung,
    Status-√Ñnderungen und Freigabe-Workflows.
    
    Args:
        calibration_id (int): ID der zu aktualisierenden Kalibrierung
        calibration_update (CalibrationUpdate): Zu aktualisierende Felder
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        Calibration: Die aktualisierte Kalibrierung
        
    Example Request (Status auf APPROVED setzen):
        ```json
        {
            "status": "APPROVED",
            "approved_by": 2,
            "approved_at": "2024-01-15T14:30:00Z"
        }
        ```
        
    Example Request (neue Version):
        ```json
        {
            "version": "1.1",
            "description": "√úberarbeitete Version nach internem Review",
            "status": "REVIEW"
        }
        ```
        
    Example Response:
        ```json
        {
            "id": 8,
            "equipment_id": 5,
            "calibration_date": "2024-01-15",
            "calibrated_by": "T√úV S√úD Industrie Service",
            "certificate_number": "TUV-IS-2024-1234",
            "result": "passed",
            "deviation": "¬±0.1¬∞C bei 37¬∞C Referenztemperatur",
            "notes": "Inkubator kalibriert nach DIN EN 60601-2-19, alle Temperatursensoren gepr√ºft",
            "next_calibration_date": "2025-01-15",
            "file_path": "/calibrations/tuv-is-2024-1234.pdf",
            "created_at": "2024-01-15T11:20:00Z"
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Kalibrierung nicht gefunden
        HTTPException: 400 bei ung√ºltigen Eingabedaten
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Nur √ºbermittelte Felder werden aktualisiert
        - approved_by und approved_at f√ºr Freigabe-Workflow
        - Versionierung f√ºr √Ñnderungsverfolgung
        
    Business Logic:
        - Status-Workflow: DRAFT ‚Üí REVIEW ‚Üí APPROVED ‚Üí OBSOLETE
        - Automatische Benachrichtigungen bei Status-√Ñnderungen
        - Audit-Trail f√ºr alle √Ñnderungen
    """
    db_calibration = db.query(CalibrationModel).filter(CalibrationModel.id == calibration_id).first()
    if not db_calibration:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Kalibrierung mit ID {calibration_id} nicht gefunden"
        )
    
    update_data = calibration_update.dict(exclude_unset=True)
    for field, value in update_data.items():
        setattr(db_calibration, field, value)
    
    db.commit()
    db.refresh(db_calibration)
    return db_calibration

@app.delete("/api/calibrations/{calibration_id}", response_model=GenericResponse, tags=["Calibrations"])
async def delete_calibration(calibration_id: int, db: Session = Depends(get_db)):
    """
    Kalibrierung l√∂schen.
    
    Entfernt eine Kalibrierung aus dem System. F√ºr Kalibrierungs-Lifecycle-Management
    und Bereinigung veralteter Kalibrierungen.
    
    Args:
        calibration_id (int): ID der zu l√∂schenden Kalibrierung
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        GenericResponse: Best√§tigung der L√∂schung
        
    Example Response:
        ```json
        {
            "message": "Kalibrierung 'Temperatur√ºberwachung' wurde gel√∂scht",
            "success": true
        }
        ```
        
    Raises:
        HTTPException: 404 wenn Kalibrierung nicht gefunden
        HTTPException: 500 bei Datenbankfehlern
        
    Note:
        - Hard Delete: Kalibrierung wird permanent entfernt
        - Datei auf Festplatte bleibt bestehen (separater Prozess)
        - F√ºr Compliance-relevante Kalibrierungen vorsichtig verwenden
        
    Warning:
        - Genehmigte Kalibrierungen sollten nicht gel√∂scht werden
        - Alternative: Status auf OBSOLETE setzen
        - Pr√ºfe Referenzen in anderen Dokumenten
    """
    db_calibration = db.query(CalibrationModel).filter(CalibrationModel.id == calibration_id).first()
    if not db_calibration:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Kalibrierung mit ID {calibration_id} nicht gefunden"
        )
    
    # Kalibrierungen haben kein name-Feld, verwende ID
    db.delete(db_calibration)
    db.commit()
    return GenericResponse(
        message=f"Kalibrierung mit ID {calibration_id} wurde gel√∂scht",
        success=True
    )



# === SEARCH & ANALYTICS APIs ===
# Erweiterte Such- und Analysefunktionen

@app.get("/api/documents/{document_id}/workflow", tags=["Document Workflow"])
async def get_document_workflow(document_id: int, db: Session = Depends(get_db)):
    """
    Workflow-Status f√ºr ein Dokument abrufen.
    
    Zeigt die automatisch generierte Workflow-Information f√ºr ein Dokument,
    einschlie√ülich zust√§ndiger Interessengruppen, Freigabe-Kette und Tasks.
    
    Args:
        document_id: ID des Dokuments
        
    Returns:
        Dict mit vollst√§ndiger Workflow-Information
    """
    # Dokument finden
    document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Dokument mit ID {document_id} nicht gefunden"
        )
    
    # Workflow-Engine verwenden
    workflow_engine = get_workflow_engine()
    workflow_summary = workflow_engine.get_workflow_summary(document)
    
    return workflow_summary

@app.get("/api/documents/{document_id}/preview", tags=["Documents"])
async def get_document_preview(document_id: int, db: Session = Depends(get_db)):
    """
    üì∏ PNG-Vorschau eines Dokuments abrufen
    
    L√§dt die gespeicherte PNG-Vorschau aus der Datenbank und gibt sie als Base64-kodiertes Bild zur√ºck.
    """
    try:
        # Dokument aus Datenbank laden
        document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
        if not document:
            raise HTTPException(status_code=404, detail="Dokument nicht gefunden")
        
        # Pr√ºfe ob PNG-Vorschau existiert
        if not document.png_preview_path:
            raise HTTPException(status_code=404, detail="Keine PNG-Vorschau verf√ºgbar")
        
        # Pr√ºfe ob PNG-Datei physisch existiert
        png_path = Path(document.png_preview_path)
        if not png_path.exists():
            raise HTTPException(status_code=404, detail="PNG-Vorschau-Datei nicht gefunden")
        
        # PNG-Datei lesen und als Base64 kodieren
        with open(png_path, 'rb') as png_file:
            png_content = png_file.read()
            png_base64 = base64.b64encode(png_content).decode('utf-8')
        
        # Metadaten f√ºr Frontend
        preview_data = {
            "success": True,
            "document_id": document_id,
            "document_title": document.title,
            "png_preview_path": document.png_preview_path,
            "png_preview_size": document.png_preview_size,
            "png_generation_timestamp": document.png_generation_timestamp.isoformat() if document.png_generation_timestamp else None,
            "png_generation_method": document.png_generation_method,
            "png_preview_hash": document.png_preview_hash,
            "image_data": f"data:image/png;base64,{png_base64}",
            "message": f"PNG-Vorschau f√ºr '{document.title}' erfolgreich geladen"
        }
        
        return preview_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Fehler beim Laden der PNG-Vorschau: {e}")
        raise HTTPException(status_code=500, detail=f"Fehler beim Laden der PNG-Vorschau: {str(e)}")


@app.get("/api/documents/search/{query}", response_model=List[Document], tags=["Search"])
async def search_documents(query: str, db: Session = Depends(get_db)):
    """
    Volltextsuche in Dokumenten.
    
    F√ºhrt eine erweiterte Volltextsuche in Dokumententiteln und
    -beschreibungen durch. F√ºr schnelle Dokumentensuche.
    
    Args:
        query (str): Suchbegriff oder -phrase
        db (Session): Datenbankverbindung (automatisch injiziert)
        
    Returns:
        List[Document]: Liste der gefundenen Dokumente
    """
    if not query or len(query.strip()) < 2:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Suchbegriff muss mindestens 2 Zeichen lang sein"
        )
    
    search_filter = f"%{query}%"
    documents = db.query(DocumentModel).filter(
        (DocumentModel.title.ilike(search_filter)) |
        (DocumentModel.description.ilike(search_filter))
    ).limit(50).all()
    
    return documents


@app.post("/api/users/{user_id}/temp-password", response_model=PasswordResetResponse, tags=["User Management (Admin Only)"])
async def generate_temp_password(
    user_id: int,
    current_user: UserModel = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    **[SYSTEM ADMIN ONLY]** Generiert tempor√§res Passwort f√ºr Benutzer.
    
    Schnelle Hilfe-Funktion f√ºr Administratoren ohne vollst√§ndigen Reset.
    Generiert sicheres tempor√§res Passwort und setzt Force-Change-Flag.
    
    Args:
        user_id: ID des Benutzers
        current_user: System Administrator
        db: Datenbankverbindung
        
    Returns:
        PasswordResetResponse: Tempor√§res Passwort
        
    Use Cases:
        - Neuer Mitarbeiter ben√∂tigt ersten Login
        - Schnelle Passwort-Hilfe ohne vollst√§ndigen Reset
        - Tempor√§rer Zugang f√ºr Externe
    """
    if not _is_system_admin(current_user):
        raise HTTPException(status_code=403, detail="üö® Nur System Administratoren d√ºrfen tempor√§re Passw√∂rter generieren")
    
    try:
        target_user = db.query(UserModel).filter(UserModel.id == user_id).first()
        if not target_user:
            raise HTTPException(status_code=404, detail=f"Benutzer mit ID {user_id} nicht gefunden")
        
        # Sicheres tempor√§res Passwort generieren
        import secrets
        import string
        alphabet = string.ascii_letters + string.digits + "!@#$%&*"
        temp_password = ''.join(secrets.choice(alphabet) for _ in range(10))
        
        # Passwort setzen
        new_hashed_password = get_password_hash(temp_password)
        target_user.hashed_password = new_hashed_password
        
        db.commit()
        
        print(f"üîë TEMP PASSWORD: {target_user.full_name} ({target_user.email}) von {current_user.full_name}")
        
        return PasswordResetResponse(
            message=f"Tempor√§res Passwort f√ºr {target_user.full_name} generiert",
            temporary_password=temp_password,
            force_change_required=True,
            reset_by_admin=True,
            reset_at=datetime.now()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Fehler beim Generieren des tempor√§ren Passworts: {str(e)}")

def _is_system_admin(user: UserModel) -> bool:
    """
    Pr√ºft ob User System Administrator ist.
    
    Args:
        user: User Model Object
        
    Returns:
        bool: True wenn System Admin
    """
    # ‚úÖ SPEZIAL: QMS Admin hat IMMER System Admin Rechte
    if (user.email == "qms.admin@company.com" and 
        user.approval_level == 4 and
        user.employee_id == "QMS001"):
        return True
    
    try:
        # System Admin Permissions pr√ºfen
        perms = user.individual_permissions or ""
        if isinstance(perms, str):
            import json
            try:
                perms_list = json.loads(perms)
                return "system_administration" in perms_list
            except json.JSONDecodeError:
                return False
        elif isinstance(perms, list):
            return "system_administration" in perms
        
        return False
    except Exception:
        return False

# === KI-ANALYSE ENDPOINTS ===
# Erweiterte KI-Funktionalit√§ten f√ºr intelligente Dokumentenanalyse

@app.post("/api/documents/{document_id}/ai-analysis", tags=["AI Analysis"])
async def analyze_document_with_ai(
    document_id: int,
    analyze_duplicates: bool = True,
    db: Session = Depends(get_db)
):
    """
    ü§ñ F√ºhrt eine umfassende KI-Analyse f√ºr ein existierendes Dokument durch
    
    **Features:**
    - üåç Automatische Spracherkennung (DE/EN/FR)
    - üìä Verbesserte Dokumenttyp-Klassifikation (95%+ Genauigkeit)
    - üìã Intelligente Norm-Referenz-Extraktion
    - ‚öñÔ∏è Compliance-Keywords-Analyse
    - üîç Duplikatserkennung (optional)
    - üìà Qualit√§ts- und Vollst√§ndigkeitsbewertung
    
    Args:
        document_id: ID des zu analysierenden Dokuments
        analyze_duplicates: Ob Duplikatspr√ºfung durchgef√ºhrt werden soll
        
    Returns:
        Umfassende KI-Analyseergebnisse
    """
    from .ai_engine import ai_engine
    
    # Dokument laden
    document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
    if not document:
        raise HTTPException(status_code=404, detail="Dokument nicht gefunden")
    
    if not document.extracted_text:
        raise HTTPException(status_code=400, detail="Dokument hat keinen extrahierten Text f√ºr KI-Analyse")
    
    # Existierende Dokumente f√ºr Duplikatspr√ºfung laden (falls gew√ºnscht)
    existing_docs_data = []
    if analyze_duplicates:
        existing_docs = db.query(DocumentModel).filter(
            DocumentModel.id != document_id,
            DocumentModel.extracted_text.isnot(None)
        ).all()
        existing_docs_data = [
            {
                'id': doc.id,
                'title': doc.title,
                'extracted_text': doc.extracted_text or ""
            } for doc in existing_docs
        ]
    
    # KI-Analyse durchf√ºhren
    try:
        ai_result = ai_engine.comprehensive_analysis(
            text=document.extracted_text,
            filename=document.file_name or document.title,
            existing_documents=existing_docs_data if analyze_duplicates else None
        )
        
        # Ergebnis formatieren f√ºr API-Response
        response_data = {
            "document_id": document_id,
            "analysis_timestamp": datetime.utcnow().isoformat(),
            
            # Spracherkennung
            "language_analysis": {
                "detected_language": ai_result.detected_language.value,
                "confidence": ai_result.language_confidence,
                "language_scores": ai_result.language_details
            },
            
            # Dokumenttyp-Klassifikation
            "document_classification": {
                "predicted_type": ai_result.document_type,
                "confidence": ai_result.type_confidence,
                "alternatives": [
                    {"type": alt[0], "confidence": alt[1]} 
                    for alt in ai_result.type_alternatives
                ],
                "current_type": document.document_type.value if document.document_type else None
            },
            
            # Norm-Referenzen
            "norm_references": ai_result.norm_references,
            
            # Compliance-Analyse
            "compliance_analysis": {
                "keywords": ai_result.compliance_keywords,
                "risk_level": ai_result.risk_level,
                "complexity_score": ai_result.complexity_score
            },
            
            # Qualit√§tsbewertung
            "quality_assessment": {
                "content_quality": ai_result.content_quality_score,
                "completeness": ai_result.completeness_score,
                "extracted_keywords": ai_result.extracted_keywords
            },
            
            # Duplikatsanalyse
            "duplicate_analysis": {
                "enabled": analyze_duplicates,
                "potential_duplicates": ai_result.potential_duplicates if analyze_duplicates else []
            },
            
            # Empfehlungen
            "recommendations": _generate_ai_recommendations(ai_result, document)
        }
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå KI-Analyse fehlgeschlagen f√ºr Dokument {document_id}: {e}")
        raise HTTPException(status_code=500, detail=f"KI-Analyse fehlgeschlagen: {str(e)}")

@app.post("/api/ai/analyze-text", tags=["AI Analysis"])
async def analyze_text_with_ai(
    text: str,
    filename: Optional[str] = None,
    analyze_duplicates: bool = False,
    db: Session = Depends(get_db)
):
    """
    üß† Analysiert beliebigen Text mit der KI-Engine (ohne Dokumenterstellung)
    
    F√ºr Test-Zwecke und Vorschau-Analysen.
    
    Args:
        text: Zu analysierender Text
        filename: Optionaler Dateiname f√ºr bessere Klassifikation
        analyze_duplicates: Ob Duplikatspr√ºfung durchgef√ºhrt werden soll
        
    Returns:
        KI-Analyseergebnisse
    """
    from .ai_engine import ai_engine
    
    if not text or len(text.strip()) < 50:
        raise HTTPException(status_code=400, detail="Text zu kurz f√ºr KI-Analyse (min. 50 Zeichen)")
    
    # Existierende Dokumente f√ºr Duplikatspr√ºfung laden (falls gew√ºnscht)
    existing_docs_data = []
    if analyze_duplicates:
        existing_docs = db.query(DocumentModel).filter(
            DocumentModel.extracted_text.isnot(None)
        ).all()
        existing_docs_data = [
            {
                'id': doc.id,
                'title': doc.title,
                'extracted_text': doc.extracted_text or ""
            } for doc in existing_docs
        ]
    
    try:
        ai_result = ai_engine.comprehensive_analysis(
            text=text,
            filename=filename or "text_analysis.txt",
            existing_documents=existing_docs_data if analyze_duplicates else None
        )
        
        return {
            "analysis_timestamp": datetime.utcnow().isoformat(),
            "text_length": len(text),
            "language": {
                "detected": ai_result.detected_language.value,
                "confidence": ai_result.language_confidence,
                "details": ai_result.language_details
            },
            "classification": {
                "predicted_type": ai_result.document_type,
                "confidence": ai_result.type_confidence,
                "alternatives": ai_result.type_alternatives
            },
            "norm_references": ai_result.norm_references,
            "compliance": {
                "keywords": ai_result.compliance_keywords,
                "risk_level": ai_result.risk_level,
                "complexity": ai_result.complexity_score
            },
            "quality": {
                "content_score": ai_result.content_quality_score,
                "completeness": ai_result.completeness_score,
                "keywords": ai_result.extracted_keywords
            },
            "duplicates": ai_result.potential_duplicates if analyze_duplicates else []
        }
        
    except Exception as e:
        logger.error(f"‚ùå Text-KI-Analyse fehlgeschlagen: {e}")
        raise HTTPException(status_code=500, detail=f"Text-Analyse fehlgeschlagen: {str(e)}")

@app.get("/api/ai/language-detection/{document_id}", tags=["AI Analysis"])
async def detect_document_language(document_id: int, db: Session = Depends(get_db)):
    """
    üåç Erkennt die Sprache eines Dokuments
    
    Schnelle Spracherkennung f√ºr ein existierendes Dokument.
    """
    from .ai_engine import ai_engine
    
    document = db.query(DocumentModel).filter(DocumentModel.id == document_id).first()
    if not document:
        raise HTTPException(status_code=404, detail="Dokument nicht gefunden")
    
    if not document.extracted_text:
        raise HTTPException(status_code=400, detail="Kein Text f√ºr Spracherkennung verf√ºgbar")
    
    language, confidence, details = ai_engine.detect_language(document.extracted_text)
    
    return {
        "document_id": document_id,
        "detected_language": language.value,
        "confidence": confidence,
        "language_scores": details,
        "text_sample": document.extracted_text[:200] + "..." if len(document.extracted_text) > 200 else document.extracted_text
    }

@app.get("/api/ai/similarity/{document_id_1}/{document_id_2}", tags=["AI Analysis"])
async def compare_documents_similarity(
    document_id_1: int,
    document_id_2: int,
    db: Session = Depends(get_db)
):
    """
    üîç Berechnet die √Ñhnlichkeit zwischen zwei Dokumenten
    
    F√ºr Duplikatsanalyse und Inhaltsbewertung.
    """
    from .ai_engine import ai_engine
    
    # Beide Dokumente laden
    doc1 = db.query(DocumentModel).filter(DocumentModel.id == document_id_1).first()
    doc2 = db.query(DocumentModel).filter(DocumentModel.id == document_id_2).first()
    
    if not doc1:
        raise HTTPException(status_code=404, detail=f"Dokument {document_id_1} nicht gefunden")
    if not doc2:
        raise HTTPException(status_code=404, detail=f"Dokument {document_id_2} nicht gefunden")
    
    if not doc1.extracted_text or not doc2.extracted_text:
        raise HTTPException(status_code=400, detail="Beide Dokumente ben√∂tigen extrahierten Text")
    
    similarity = ai_engine.calculate_content_similarity(doc1.extracted_text, doc2.extracted_text)
    
    # √Ñhnlichkeits-Level bestimmen
    if similarity >= 0.8:
        similarity_level = "SEHR_HOCH"
        warning = "‚ö†Ô∏è Potentielles Duplikat!"
    elif similarity >= 0.6:
        similarity_level = "HOCH"
        warning = "üìã Hohe √Ñhnlichkeit erkannt"
    elif similarity >= 0.4:
        similarity_level = "MITTEL"
        warning = "üìù Moderate √Ñhnlichkeit"
    else:
        similarity_level = "NIEDRIG"
        warning = "‚úÖ Dokumente sind unterschiedlich"
    
    return {
        "document_1": {
            "id": doc1.id,
            "title": doc1.title,
            "type": doc1.document_type.value if doc1.document_type else None
        },
        "document_2": {
            "id": doc2.id,
            "title": doc2.title,
            "type": doc2.document_type.value if doc2.document_type else None
        },
        "similarity_analysis": {
            "score": similarity,
            "percentage": f"{similarity:.1%}",
            "level": similarity_level,
            "warning": warning
        },
        "comparison_timestamp": datetime.utcnow().isoformat()
    }