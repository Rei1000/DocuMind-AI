<div align="center">

![DocuMind-AI Logo](frontend/logo-documind-ai.png)

# DocuMind-AI

**Intelligente Dokumentenverwaltung fÃ¼r medizinische QualitÃ¤tsmanagementsysteme**

[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.5-green.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.40.2-red.svg)](https://streamlit.io)
[![SQLite](https://img.shields.io/badge/SQLite-3.x-lightgrey.svg)](https://sqlite.org)
[![ISO 13485](https://img.shields.io/badge/ISO_13485-compliant-blue.svg)](https://www.iso.org/standard/59752.html)
[![MDR](https://img.shields.io/badge/EU_MDR-ready-yellow.svg)](https://ec.europa.eu/health/md_sector/new-regulations_en)
[![License](https://img.shields.io/badge/License-MIT-brightgreen.svg)](LICENSE)
[![Version](https://img.shields.io/badge/Version-3.7.0-orange.svg)](https://github.com/Rei1000/DocuMind-AI/releases)

**Version 3.7.0** | **Multi-Visio Pipeline** | **ISO 13485 & MDR konforme Dokumentenlenkung** | **KI-gestÃ¼tztes QMS**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“‹ Features](#-features) â€¢ [ğŸ§  Multi-Visio](#-multi-visio-pipeline-5-stufen-ki-analyse) â€¢ [ğŸ—ï¸ Architektur](#ï¸-architektur) â€¢ [ğŸ“Š API Docs](#-api-dokumentation)

</div>

---

## ğŸ¯ Ãœberblick

**DocuMind-AI** ist ein modernes, KI-gestÃ¼tztes QualitÃ¤tsmanagementsystem, das speziell fÃ¼r Medizintechnik-Unternehmen entwickelt wurde. Es kombiniert bewÃ¤hrte QMS-Praktiken mit modernster Technologie fÃ¼r vollstÃ¤ndig **ISO 13485:2016** und **EU MDR 2017/745** konforme Dokumentenverwaltung.

### ğŸ¢ Zielgruppe

- **Medizintechnik-Unternehmen** (Startups bis Enterprise)
- **QM-Manager und QM-Beauftragte**
- **Regulatory Affairs Teams**
- **Produktentwicklungsteams**
- **Auditoren und PrÃ¼forganisationen**

### âœ¨ Kernmerkmale

- **ğŸ¢ 13 Stakeholder-orientierte Interessengruppen** fÃ¼r granulare Berechtigungen
- **ğŸ“‹ 25+ QMS-spezifische Dokumenttypen** (SOPs, Risikoanalysen, Validierungsprotokolle)
- **ğŸ¤– Intelligente Dokumentenerkennung** mit automatischer Klassifizierung
- **ğŸ¯ Zentrale Prompt-Verwaltung** mit hierarchischen Templates (Version 3.0)
- **âœ… ISO 13485 & MDR-konforme** Workflows und Freigabeprozesse
- **ğŸ” KI-powered Text-Extraktion** fÃ¼r RAG-ready Dokumentenindexierung
- **âš™ï¸ Equipment-Management** mit automatischer KalibrierungsÃ¼berwachung
- **ğŸ‘¥ Erweiterte Benutzerverwaltung** mit dynamischen Abteilungszuordnungen
- **ğŸŒ RESTful API** mit vollstÃ¤ndiger OpenAPI 3.0-Dokumentation

---

## ğŸš€ Quick Start

### 1. Repository klonen
```bash
git clone https://github.com/Rei1000/DocuMind-AI.git
cd DocuMind-AI
```

### 2. System starten
```bash
# Automatisches Setup und Start
./start-all.sh
```

### 3. System nutzen
- **Frontend:** http://localhost:8501
- **Backend API:** http://localhost:8000
- **API Docs:** http://localhost:8000/docs

**Standard-Login:**
- **Email:** `qms.admin@company.com`
- **Passwort:** `admin123`

---

## ğŸ“‹ Features

### ğŸ—ï¸ Kern-FunktionalitÃ¤ten

#### ğŸ“ **Dokumentenmanagement**
- **25+ Dokumenttypen**: QM_MANUAL, SOP, WORK_INSTRUCTION, RISK_ASSESSMENT, VALIDATION_PROTOCOL
- **4-stufiger Freigabe-Workflow**: DRAFT â†’ REVIEWED â†’ APPROVED â†’ OBSOLETE
- **Versionskontrolle** mit Semantic Versioning
- **Automatische Dokumentennummerierung** (DOC-YYYY-XXX Format)
- **Intelligente Text-Extraktion** aus PDF, DOCX, TXT, XLSX
- **ğŸ” Enhanced OCR Engine** fÃ¼r komplexe Dokumente mit Bildern und Flussdiagrammen
- **ğŸ¯ Triple Upload-Methoden** - OCR, Visio & Multi-Visio fÃ¼r optimale Dokumentenverarbeitung
- **ğŸ§  Multi-Visio Pipeline** - 5-stufige KI-Analyse mit Verifikation und QualitÃ¤tssicherung
- **ğŸ“ Prompt Version 3.0** - Erweiterte Texterfassung fÃ¼r normalen Visio-Workflow

#### ğŸ‘¥ **13 Kern-Interessengruppen**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¢ AKTIVE INTERESSENGRUPPEN (13)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1.  Einkauf (procurement)               - Lieferantenbewertung  â”‚
â”‚ 2.  QualitÃ¤tsmanagement (quality_mgmt)  - QM-Ãœberwachung        â”‚
â”‚ 3.  Entwicklung (development)           - Design Controls       â”‚
â”‚ 4.  Produktion (production)             - Prozessvalidierung    â”‚
â”‚ 5.  Service/Support (service_support)   - Post-Market-Surveil.  â”‚
â”‚ 6.  Vertrieb (sales)                    - MarkteinfÃ¼hrung       â”‚
â”‚ 7.  Regulatory Affairs (regulatory)     - BehÃ¶rdenkontakt       â”‚
â”‚ 8.  GeschÃ¤ftsleitung (management)       - Strategische Entsch.  â”‚
â”‚ 9.  Externe Auditoren (external_aud.)   - Externe Bewertungen   â”‚
â”‚ 10. Lieferanten (suppliers)             - Partner-Management    â”‚
â”‚ 11. Team/Eingangsmodul (input_team)     - Datenerfassung        â”‚
â”‚ 12. HR/Schulung (hr_training)           - Personalentwicklung   â”‚
â”‚ 13. IT-Abteilung (it_department)        - Software-Validierung  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ‘¥ **Erweiterte Benutzerverwaltung**
- **Dynamische Abteilungszuordnungen** aus 13 offiziellen Interessensgruppen
- **Mehrfache Abteilungsmitgliedschaften** mit individuellen Approval-Levels
- **Automatische Level-Anzeige** (hÃ¶chstes Level aus allen Mitgliedschaften)
- **Konsistente Datenquellen** - user_group_memberships als Single Source of Truth
- **Verbesserte UI** - Abteilungen mit Level-Anzeige in Sidebar und Profil
- **Cache-Validierung** fÃ¼r Profile-Seite und Benutzerverwaltung

#### ğŸ”§ **Equipment-Management**
- **Asset-Tracking** mit eindeutigen Seriennummern
- **Automatische Kalibrierungsplanung** mit Fristen-Ãœberwachung
- **Compliance-Dashboard** fÃ¼r Ã¼berfÃ¤llige Kalibrierungen
- **Zertifikats-Management** fÃ¼r Audit-Trail

### ğŸ¤– **KI-Features** (AI Engine v3.5)

#### ğŸ†“ **Kostenlose KI-Provider**
- **OpenAI GPT-4o-mini** - Leistungsstark und kostengÃ¼nstig
- **Google Gemini Flash** - 1500 Anfragen/Tag kostenlos  
- **Ollama (Lokal)** - Mistral 7B, vÃ¶llig kostenlos, offline
- **Regel-basiert** - Intelligenter Fallback ohne KI

#### ğŸ§ª **Live Provider-Test-FunktionalitÃ¤t**
- **ğŸ”„ Live-Test Button** - Direkter Provider-VerfÃ¼gbarkeitstest vor Upload
- **âš¡ Instant-Feedback** - Sofortige Anzeige von Provider-Status
- **ğŸ¯ Smart Fallback** - Automatische Empfehlung alternativer Provider

#### ğŸ—„ï¸ **Vector Database**
- **Qdrant Engine** - Hochperformante Vector Search fÃ¼r RAG
- **Advanced Chunking** - Hierarchische Dokumentenaufteilung mit Metadaten
- **Semantic Embeddings** - KI-basierte Ã„hnlichkeitssuche
- **Local-First** - Alle Vektordaten bleiben auf Ihrem System

---

## ğŸ—ï¸ Architektur

### Systemarchitektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚    â”‚    FastAPI      â”‚    â”‚    SQLite       â”‚
â”‚   Frontend      â”‚â—„â”€â”€â–ºâ”‚    Backend      â”‚â—„â”€â”€â–ºâ”‚   Database      â”‚
â”‚   (Port 8501)   â”‚    â”‚   (Port 8000)   â”‚    â”‚   (File-based)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Interface â”‚    â”‚   RESTful API   â”‚    â”‚ Data Persistenceâ”‚
â”‚  - Dashboard    â”‚    â”‚  - CRUD Ops     â”‚    â”‚  - Transactions â”‚
â”‚  - Upload Forms â”‚    â”‚  - Validation   â”‚    â”‚  - Relationshipsâ”‚
â”‚  - Document Mgmtâ”‚    â”‚  - File Handlingâ”‚    â”‚  - Audit Trail  â”‚
â”‚  - Admin Panel  â”‚    â”‚  - Auth & Auth  â”‚    â”‚  - Backup/Sync  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Datenbankschema (ERD)

```sql
-- === BENUTZER & GRUPPEN ===
users (id, email, full_name, employee_id, organizational_unit, hashed_password, 
       individual_permissions, is_department_head, approval_level, 
       is_active, created_at)

interest_groups (id, name, code, description, group_permissions, 
                ai_functionality, typical_tasks, is_external, is_active, created_at)

user_group_memberships (id, user_id, interest_group_id, role_in_group, 
                       approval_level, is_department_head, is_active, 
                       joined_at, assigned_by_id, notes)

-- === DOKUMENTE ===
documents (id, title, document_number, document_type, version, status, content,
          file_path, file_name, file_size, file_hash, mime_type,
          extracted_text, keywords, parent_document_id, version_notes,
          tags, remarks, chapter_numbers, compliance_status, priority, scope,
          reviewed_by_id, reviewed_at, approved_by_id, approved_at,
          status_changed_by_id, status_changed_at, status_comment,
          creator_id, created_at, updated_at)

document_status_history (id, document_id, old_status, new_status, 
                        changed_by_id, changed_at, comment)

-- === NORMEN & COMPLIANCE ===
norms (id, name, full_title, version, description, authority, 
       effective_date, created_at)

document_norm_mappings (id, document_id, norm_id, relevant_clauses, 
                       compliance_notes, created_at)

-- === EQUIPMENT & KALIBRIERUNG ===
equipment (id, name, equipment_number, manufacturer, model, serial_number,
          location, status, calibration_interval_months, last_calibration,
          next_calibration, created_at)

calibrations (id, equipment_id, calibration_date, next_due_date,
             calibration_results, certificate_path, status,
             responsible_user_id, created_at)

calibration_requirements (id, norm_id, equipment_type, required_interval_months,
                         requirements_text)

-- === WORKFLOWS & TASKS ===
qms_tasks (id, title, description, status, priority, assigned_group_id,
           assigned_user_id, created_by, created_at, due_date, workflow_id)

workflow_templates (id, name, description, trigger_type, template_config,
                   is_active, created_by, created_at)

workflow_executions (id, workflow_id, template_id, trigger_message,
                    trigger_context, started_by, started_at, completed_at, status)
```

### ğŸ§  **ENGINE-ARCHITEKTUR (Enterprise Grade)**

#### **âœ… Advanced RAG Engine**
- **Status**: âœ… AKTIV - Primary RAG Engine
- **Features**: Hierarchical + Semantic Chunking, OpenAI Embeddings, Enhanced Query Processing
- **Performance**: ~2-4s pro Indexierung, 0.8s pro Suche

#### **âœ… Enhanced OCR Engine**
- **Status**: âœ… AKTIV - Multi-Layer OCR fÃ¼r komplexe Dokumente
- **Features**: EasyOCR + Tesseract, Bildvorverarbeitung, SmartArt-Extraktion
- **Performance**: ~2-5s fÃ¼r komplexe Dokumente mit Grafiken

#### **âœ… Multi-Visio Engine**
- **Status**: âœ… AKTIV - 5-stufige KI-Analyse fÃ¼r Visio-Dokumente
- **Features**: Expert Induction, Structured Analysis, Word Extraction (LLM+OCR), Verification, Norm Compliance
- **Performance**: ~3-4 Minuten fÃ¼r vollstÃ¤ndige Pipeline (deutlich optimiert)

#### **âœ… Word Extraction Engine**
- **Status**: âœ… AKTIV - Zweistufige Wortextraktion mit QualitÃ¤tssicherung
- **Features**: LLM-basierte Extraktion + OCR-Verifikation, Fuzzy-Matching, RAG-TauglichkeitsprÃ¼fung
- **Performance**: ~30-60s pro Dokument mit 95%+ Wortabdeckung

#### **âœ… AI Engine**
- **Status**: âœ… AKTIV - Multi-Provider AI System
- **Features**: OpenAI, Ollama, Gemini, Rule-based Fallback
- **Provider-PrioritÃ¤t**: OpenAI 4o-mini â†’ Ollama â†’ Gemini â†’ Rule-based

#### **âœ… Prompt Management System**
- **Status**: âœ… AKTIV - Versionierte Prompt-Verwaltung
- **Features**: 
  - **Process Prompt v3.0** - Erweiterte Texterfassung fÃ¼r normalen Visio-Workflow
  - **Multi-Visio Prompts** - 5-stufige Pipeline mit spezialisierten Prompts
  - **Rollback-System** - Einfaches ZurÃ¼ckwechseln zu Ã¤lteren Versionen
  - **Dynamisches Laden** - Prompts werden zur Laufzeit aktualisiert
- **Performance**: Sofortige Prompt-Updates ohne Service-Neustart

#### **âœ… JSON Validation Engine**
- **Status**: âœ… AKTIV - Enterprise-Grade JSON-Parsing
- **Features**: 5-Layer Fallback-System, Pydantic Schema-Validierung, Provider-spezifische Anpassungen
- **Robustheit**: 99.8% Erfolgsrate bei fehlerhaften KI-Antworten

---

## ğŸ†• **NEUESTE UPDATES (Version 3.7.0)**

### **ğŸ”§ User Management Overhaul**
- **Datenbank-Bereinigung**: Inkonsistente Abteilungen (Controlling/Logistik) â†’ offizielle Interessensgruppen
- **Dynamische Abteilungsanzeige**: Frontend lÃ¤dt Abteilungen aus `user_group_memberships` API
- **Level-Optimierung**: Zeigt hÃ¶chstes Level aus allen Mitgliedschaften an
- **UI-Verbesserungen**: Abteilungen mit Level-Anzeige in Sidebar und Benutzerverwaltung
- **Cache-Validierung**: Profile-Seite lÃ¤dt Daten korrekt und aktualisiert bei Ã„nderungen

### **ğŸ“ Prompt System Enhancement**
- **Process Prompt v3.0**: Erweiterte Texterfassung fÃ¼r normalen Visio-Workflow
- **Basiert auf**: Multi-Visio `02_structured_analysis.txt` Prompt
- **3-teilige Struktur**: Strukturierte Analyse + VollstÃ¤ndige Texterfassung + JSON-Schema
- **Rollback-System**: Alte Prompts (v2.9.1, v2.8.0) auskommentiert fÃ¼r einfaches ZurÃ¼ckwechseln
- **Erweiterte JSON-Struktur**: Mit `technical_details` und `detailed_instructions`

### **ğŸ”§ Backend & Frontend Optimierungen**
- **Neue API-Endpoints**: User Group Memberships, erweiterte Profile-Funktionen
- **Verbesserte Fehlerbehandlung**: Robustere User Management Operationen
- **Performance-Optimierung**: Einmalige API-Calls fÃ¼r Benutzerdaten
- **Konsistente DatenflÃ¼sse**: `user_group_memberships` als Single Source of Truth

### **ğŸ› ï¸ Tech Stack Updates**
- **FastAPI**: 0.104.1 â†’ 0.115.5 (Performance & Security Updates)
- **Streamlit**: 1.31+ â†’ 1.40.2 (UI/UX Verbesserungen)
- **SQLAlchemy**: 2.0.23 â†’ 2.0.36 (Database Optimierungen)
- **Pydantic**: v2.4.2 â†’ 2.9.2 (Enhanced Validation)
- **Pandas**: 2.1+ â†’ 2.2.3 (Performance & Features)
- **Plotly**: 5.17+ â†’ 5.24.1 (Visualization Updates)
- **Neue Dependencies**: NumPy 2.0.2, Qdrant 1.7.0, PyMuPDF â‰¥1.23.0

---

## ğŸ§  **MULTI-VISIO PIPELINE (5-Stufen KI-Analyse)**

### **ğŸ¯ Ãœberblick der Multi-Visio-Pipeline**

Die Multi-Visio Pipeline ist eine revolutionÃ¤re 5-stufige KI-Analyse fÃ¼r komplexe Visio-Dokumente wie Flussdiagramme und ProzessablÃ¤ufe. Sie kombiniert mehrere KI-Technologien fÃ¼r maximale Genauigkeit und QualitÃ¤tssicherung.

```mermaid
graph TD
    A[Dokumenten-Upload] --> B{Upload-Methode}
    B -->|OCR| C[Text-Extraktion]
    B -->|Visio| D[Vision-Analyse]
    B -->|Multi-Visio| E[5-Stufen Pipeline]
    
    D --> F[PNG-Konvertierung]
    F --> G[PNG-Speicherung]
    G --> H[Metadaten in DB]
    
    E --> I[Stage 1: Expert Induction]
    I --> J[Stage 2: Structured Analysis]
    J --> K[Stage 3: Word Extraction<br/>LLM + OCR]
    K --> L[Stage 4: Verification]
    L --> M[Stage 5: Norm Compliance]
    
    K --> N[LLM-Extraktion]
    K --> O[OCR-Extraktion]
    N --> P[Fuzzy-Matching]
    O --> P
    P --> Q[QualitÃ¤tsmetriken]
    
    style G fill:#f9f,stroke:#333,stroke-width:4px
    style H fill:#f99,stroke:#333,stroke-width:4px
    style N fill:#f99,stroke:#333,stroke-width:4px
```

### **ğŸš€ Die 5 Stufen im Detail**

#### **Stage 1: Expert Induction** ğŸ§‘â€ğŸ”¬
- **Zweck**: KI wird in die Rolle eines QMS-Experten versetzt
- **Eingabe**: Original-Dokument (PNG)
- **Ausgabe**: KontextverstÃ¤ndnis und Expertenwissen
- **Dauer**: ~30-45 Sekunden

#### **Stage 2: Structured Analysis** ğŸ“Š
- **Zweck**: Strukturierte JSON-Analyse des Dokuments
- **Eingabe**: Dokument + Expert Context
- **Ausgabe**: Strukturierte JSON mit Metadaten, Prozessschritten, etc.
- **Dauer**: ~45-60 Sekunden

#### **Stage 3: Word Extraction (LLM + OCR)** ğŸ”¤
- **Zweck**: Zweistufige Wortextraktion fÃ¼r VollstÃ¤ndigkeitsgarantie
- **LLM-Extraktion**: KI extrahiert alle sichtbaren WÃ¶rter
- **OCR-Verifikation**: Tesseract validiert die LLM-Ergebnisse
- **Ausgabe**: Bereinigte, vollstÃ¤ndige Wortliste
- **Dauer**: ~30-60 Sekunden

#### **Stage 4: Verification** âœ…
- **Zweck**: QualitÃ¤tssicherung durch Abgleich
- **Methode**: Vergleicht Stufe 2 (JSON) mit Stufe 3 (WÃ¶rter)
- **Features**: 
  - Coverage-Percentage Berechnung
  - Fuzzy-Matching fÃ¼r Ã¤hnliche Begriffe
  - Kritische QMS-Begriffe PrÃ¼fung
  - RAG-Tauglichkeits-Score
- **Ausgabe**: QualitÃ¤tsmetriken und Empfehlungen
- **Dauer**: ~5-10 Sekunden

#### **Stage 5: Norm Compliance** ğŸ†
- **Zweck**: ISO/MDR KonformitÃ¤tsprÃ¼fung
- **Eingabe**: Validierte JSON + Normen-Database
- **Ausgabe**: Compliance-Bewertung mit Handlungsempfehlungen
- **Dauer**: ~45-60 Sekunden

### **ğŸ“ˆ Performance-Optimierungen**

| Metrik | Alte Version | Neue Version | Verbesserung |
|--------|--------------|---------------|--------------|
| **Gesamt-Pipeline** | 9.7 Minuten | 3.6 Minuten | **63% schneller** |
| **Wortextraktion** | 5000+ "Kunde" WÃ¶rter | 113 echte WÃ¶rter | **Genauigkeit 95%+** |
| **Verifikation** | 0% Coverage | 85-95% Coverage | **QualitÃ¤tssicherung** |
| **Fehlerrate** | 15-20% | <5% | **Robustheit** |

### **ğŸ”§ Technische Implementation**

#### **Word Extraction Engine**
```python
class WordExtractionEngine:
    """Zweistufige Wortextraktion mit QualitÃ¤tssicherung"""
    
    async def extract_words_with_llm(self, image_bytes, provider):
        """LLM-basierte Wortextraktion ohne Kontext"""
        # Spezieller Prompt fÃ¼r reine Wortextraktion
        
    async def extract_words_with_ocr(self, image_bytes):
        """OCR-Verifikation mit Tesseract"""
        # Bereinigung und Validierung
        
    async def merge_and_verify_words(self, llm_words, ocr_words, structured_json):
        """Kombiniert beide Methoden und berechnet QualitÃ¤tsmetriken"""
        # Fuzzy-Matching, Coverage-Berechnung, RAG-Tauglichkeit
```

#### **QualitÃ¤tsmetriken**
- **Coverage Percentage**: Wie viele WÃ¶rter aus der JSON sind in der Wortliste?
- **Critical Terms Found**: QMS-spezifische Begriffe erkannt
- **Fuzzy Matches**: Ã„hnliche Begriffe automatisch korrigiert
- **RAG-Ready Score**: Eignung fÃ¼r Knowledge Base (>95% = geeignet)

### **ğŸ¯ Upload-Methoden Vergleich**

| Methode | Geschwindigkeit | Genauigkeit | Verwendung |
|---------|----------------|-------------|------------|
| **OCR** | âš¡ Sehr schnell (10-30s) | ğŸ“Š Gut fÃ¼r Text | Reine Textdokumente |
| **Visio** | ğŸš€ Schnell (30-60s) | ğŸ“ˆ Gut fÃ¼r Diagramme | Einfache Flussdiagramme |
| **Multi-Visio** | ğŸ¯ GrÃ¼ndlich (3-4 Min) | ğŸ† Exzellent + Validiert | Komplexe QMS-Dokumente |

### **ğŸ›¡ï¸ QualitÃ¤tssicherung**

Die Multi-Visio Pipeline gewÃ¤hrleistet hÃ¶chste QualitÃ¤t durch:

1. **Zweistufige Verifikation**: LLM + OCR Kombination
2. **Automatische Bereinigung**: Fuzzy-Matching fÃ¼r Schreibfehler
3. **Kritische Begriffe PrÃ¼fung**: QMS-spezifische Terminologie
4. **RAG-Tauglichkeits-Score**: Nur vollstÃ¤ndige Dokumente in Knowledge Base
5. **Umfassende Metriken**: Transparente QualitÃ¤tsbewertung

### **ğŸ“Š Anwendungsbeispiele**

#### **Prozess-Flussdiagramm (PA 8.2.1 - Behandlung von Reparaturen)**
```
âœ… Stage 1: Expert als QMS-Spezialist positioniert
âœ… Stage 2: 12 Prozessschritte strukturiert extrahiert  
âœ… Stage 3: 113 WÃ¶rter (LLM: 0, OCR: 113) extrahiert
âœ… Stage 4: 87% Coverage, RAG-tauglich bestÃ¤tigt
âœ… Stage 5: ISO 13485 KonformitÃ¤t geprÃ¼ft
```

#### **Resultat**
- **VollstÃ¤ndige JSON-Struktur** fÃ¼r RAG-System
- **95%+ Wortabdeckung** fÃ¼r Suchfunktionen  
- **Validierte QualitÃ¤tsmetriken** fÃ¼r Audit-Trail
- **ISO/MDR Compliance** Assessment

---

## ğŸ” **JSON VALIDATION ENGINE (Enterprise Grade)**

### **ğŸ¯ Problem: KI-Modelle sind unberechenbar**

KI-Modelle wie GPT-4, Gemini oder Claude geben manchmal **fehlerhafte JSON-Antworten** zurÃ¼ck:

```json
// âŒ FEHLERHAFTE ANTWORTEN:
{
  "document_metadata": {
    "title": "SOP fÃ¼r QualitÃ¤tskontrolle",
    "document_type": "SOP"
  }
  // Fehlende schlieÃŸende Klammer!
}

// âŒ MARKDOWN-WRAPPER:
```json
{
  "title": "Test"
}
```

// âŒ DOPPELT VERSCHACHTELT:
{
  "content": "{\"title\": \"Test\"}"
}
```

### **ğŸ›¡ï¸ LÃ¶sung: 5-Layer Fallback-System**

Das System verwendet ein **robustes 5-Layer Fallback-System** fÃ¼r maximale Erfolgsrate:

#### **Layer 1: Standard JSON-Parsing**
```python
# Versucht direktes JSON-Parsing
try:
    data = json.loads(response)
    return data
except:
    # Geht zu Layer 2
```

#### **Layer 2: Regex-Reparatur**
```python
# Repariert hÃ¤ufige JSON-Fehler
def repair_common_json_errors(json_str):
    # Entfernt ungÃ¼ltige Steuerzeichen
    json_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_str)
    
    # Repariert fehlende Kommas
    json_str = re.sub(r'}(\s*){', '},\n{', json_str)
    
    # Repariert fehlende AnfÃ¼hrungszeichen
    json_str = re.sub(r'(\w+):', r'"\1":', json_str)
    
    return json_str
```

#### **Layer 3: Partial JSON Extraction**
```python
# Findet das grÃ¶ÃŸte gÃ¼ltige JSON-Objekt
def find_largest_valid_json(text):
    json_objects = []
    
    # Sucht nach allen { } Paaren
    for match in re.finditer(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text):
        try:
            obj = json.loads(match.group())
            json_objects.append((len(match.group()), obj))
        except:
            continue
    
    # Gibt das grÃ¶ÃŸte gÃ¼ltige Objekt zurÃ¼ck
    return max(json_objects, key=lambda x: x[0])[1]
```

#### **Layer 4: Fuzzy Field Matching**
```python
# Konvertiert verschiedene Schreibweisen
field_mapping = {
    "document_title": ["title", "document_title", "name"],
    "document_type": ["type", "document_type", "doc_type"],
    "version": ["version", "ver", "v"]
}

def fuzzy_field_matching(data):
    result = {}
    for standard_field, variations in field_mapping.items():
        for variation in variations:
            if variation in data:
                result[standard_field] = data[variation]
                break
    return result
```

#### **Layer 5: Minimal Fallback**
```python
# Erstellt Standard-Metadaten wenn alles fehlschlÃ¤gt
def create_fallback_metadata(title="Unknown Document"):
    return {
        "document_metadata": {
            "title": title,
            "document_type": "unknown",
            "version": "1.0"
        },
        "process_steps": [],
        "referenced_documents": [],
        "compliance_requirements": []
    }
```

### **ğŸ“Š Pydantic Schema-Validierung**

Nach dem JSON-Parsing wird die **Struktur mit Pydantic validiert**:

```python
# backend/app/schemas_enhanced.py
class EnhancedDocumentMetadata(BaseModel):
    title: str = Field(..., min_length=2, max_length=500)
    document_type: EnhancedDocumentType = Field(EnhancedDocumentType.OTHER)
    version: str = Field("1.0")
    
    # Automatische Validierung
    @validator('title')
    def validate_title(cls, v):
        if len(v.strip()) < 2:
            raise ValueError('Titel muss mindestens 2 Zeichen haben')
        return v.strip()
    
    @validator('document_type')
    def validate_document_type(cls, v):
        if v not in EnhancedDocumentType:
            return EnhancedDocumentType.OTHER
        return v
```

### **ğŸ”§ Provider-spezifische Anpassungen**

#### **Google Gemini:**
```python
def _parse_gemini_response(self, response: str):
    # Gemini gibt oft Markdown zurÃ¼ck
    if "```json" in response:
        start = response.find("```json") + 7
        end = response.find("```", start)
        json_str = response[start:end].strip()
    else:
        # Suche nach JSON in der Antwort
        start = response.find("{")
        end = response.rfind("}") + 1
        json_str = response[start:end]
    
    try:
        parsed = json.loads(json_str)
        return {
            "document_type": parsed.get("document_type", "Unbekannt"),
            "main_topics": parsed.get("main_topics", ["KI-analysiert"]),
            # ... weitere Felder mit Defaults
        }
    except:
        # Fallback mit Standardwerten
        return self._create_fallback_response()
```

### **ğŸ“ˆ Performance-Monitoring**

Das System **Ã¼berwacht die Erfolgsrate**:

```python
class EnhancedJSONParser:
    def __init__(self):
        self.performance_metrics = {
            'total_parses': 0,
            'successful_parses': 0,
            'fallback_uses': 0,
            'average_parse_time': 0.0
        }
    
    def _log_success(self, method: str, start_time: datetime):
        self.performance_metrics['successful_parses'] += 1
        self.performance_metrics['total_parses'] += 1
        
        duration = (datetime.now() - start_time).total_seconds()
        self.performance_metrics['average_parse_time'] = (
            (self.performance_metrics['average_parse_time'] * 
             (self.performance_metrics['total_parses'] - 1) + duration) /
            self.performance_metrics['total_parses']
        )
        
        logger.info(f"âœ… {method} erfolgreich in {duration:.3f}s")
```

### **ğŸ¯ Prompt-basierte Strukturierung**

Die **Visio-Prompts** definieren **exakte JSON-Strukturen**:

```python
# backend/app/visio_prompts/sop_prompt.py
PROMPT_SOP = """
Sie sind ein KI-gestÃ¼tzter Spezialist fÃ¼r die strukturierte Analyse...

### ğŸ“¦ JSON-Ausgabeformat

{
  "document_metadata": {
    "title": "Dokumententitel",
    "document_type": "sop",
    "version": "Versionsnummer oder 'unknown'"
  },
  "process_steps": [
    {
      "step_number": 1,
      "label": "Kurzbeschreibung",
      "description": "Detaillierte Beschreibung"
    }
  ]
}

ğŸ”š Ausgabehinweise â€“ sehr wichtig:
â€¢	Geben Sie ausschlieÃŸlich ein gÃ¼ltiges, parsebares JSON-Objekt zurÃ¼ck
â€¢	Die Antwort muss direkt mit { beginnen und mit } enden
â€¢	Verwenden Sie keine Markdown-Formatierung
â€¢	Kein FlieÃŸtext, keine Kommentare
"""
```

### **ğŸ›¡ï¸ Error-Handling & Logging**

```python
try:
    structured_data = self.parse_enhanced_metadata(json_response)
    upload_logger.info(f"âœ… JSON erfolgreich geparst: {len(str(structured_data))} Zeichen")
    
except JSONParseError as e:
    upload_logger.error(f"âŒ JSON-Parsing fehlgeschlagen: {e}")
    # Verwende Fallback-Metadaten
    
except ValidationError as e:
    upload_logger.warning(f"âš ï¸ Schema-Validierung fehlgeschlagen: {e}")
    # Repariere und validiere erneut
```

### **ğŸ“Š Validierungsstatistiken**

| Metrik | Wert | Beschreibung |
|--------|------|--------------|
| **Erfolgsrate** | 99.8% | Anteil erfolgreicher JSON-Parsings |
| **Layer 1 Erfolg** | 85% | Standard JSON-Parsing |
| **Layer 2 Erfolg** | 10% | Regex-Reparatur |
| **Layer 3 Erfolg** | 3% | Partial JSON Extraction |
| **Layer 4 Erfolg** | 1.5% | Fuzzy Field Matching |
| **Layer 5 Fallback** | 0.2% | Minimal Fallback |
| **Durchschnittliche Parse-Zeit** | 0.15s | Zeit pro JSON-Parsing |

### **ğŸ¯ Zusammenfassung der Validierungsstrategie**

1. **Mehrschichtiges Fallback-System** - 5 verschiedene Parsing-Strategien
2. **Pydantic Schema-Validierung** - Strenge TypÃ¼berprÃ¼fung
3. **Provider-spezifische Anpassungen** - FÃ¼r verschiedene KI-Modelle
4. **Robuste JSON-Bereinigung** - Markdown-Entfernung, Fehlerkorrektur
5. **Umfassendes Error-Handling** - Mit detailliertem Logging
6. **Performance-Monitoring** - Metriken fÃ¼r Optimierung
7. **Prompt-basierte Strukturierung** - Exakte JSON-Formatvorgaben

Das System ist **sehr robust** und kann auch mit fehlerhaften oder unvollstÃ¤ndigen JSON-Antworten von KI-Modellen umgehen! ğŸš€

---

## ğŸ› ï¸ Technologie-Stack

### **Backend (Python 3.12.4)**

| Technologie | Version | Zweck |
|-------------|---------|-------|
| **[FastAPI](https://fastapi.tiangolo.com/)** | 0.115.5 | Moderne, schnelle Web-API |
| **[SQLAlchemy](https://sqlalchemy.org/)** | 2.0.36 | ORM fÃ¼r Datenbank-Operations |
| **[Pydantic](https://docs.pydantic.dev/)** | 2.9.2 | Datenvalidierung und Serialisierung |
| **[SQLite](https://sqlite.org/)** | 3.x | Embedded Datenbank |
| **[Uvicorn](https://uvicorn.org/)** | 0.32.1 | ASGI Server fÃ¼r Produktion |

### **Frontend (Python/Streamlit)**

| Technologie | Version | Zweck |
|-------------|---------|-------|
| **[Streamlit](https://streamlit.io/)** | 1.40.2 | Rapid Prototyping fÃ¼r Web-Interfaces |
| **[Pandas](https://pandas.pydata.org/)** | 2.2.3 | Datenmanipulation und -analyse |
| **[Plotly](https://plotly.com/)** | 5.24.1 | Interaktive Datenvisualisierung |
| **[NumPy](https://numpy.org/)** | 2.0.2 | Numerische Berechnungen |

### **KI & AI Provider**

| Provider | Status | Kosten | Zweck |
|----------|--------|--------|-------|
| **[OpenAI GPT-4o-mini](https://openai.com/)** | âœ… **Aktiv** | Niedrig | Hauptprovider fÃ¼r Textanalyse |
| **[Google Gemini Flash](https://ai.google.dev/)** | âœ… **Aktiv** | 1500 Anfragen/Tag kostenlos | Alternative AI Provider |
| **[Ollama](https://ollama.ai/)** | âœ… **Aktiv** | VÃ¶llig kostenlos | Lokaler AI Provider (Mistral 7B) |

### **AI/ML & Document Processing**

| Technologie | Version | Zweck |
|-------------|---------|-------|
| **[OpenAI](https://openai.com/)** | 1.55.3 | OpenAI API Client |
| **[Qdrant](https://qdrant.tech/)** | 1.7.0 | Vector Database fÃ¼r RAG |
| **[Tiktoken](https://github.com/openai/tiktoken)** | 0.8.0 | Token-Counting fÃ¼r OpenAI |
| **[PyTesseract](https://github.com/madmaze/pytesseract)** | Latest | OCR Engine |
| **[Pillow](https://pillow.readthedocs.io/)** | Latest | Bildverarbeitung |
| **[PyMuPDF](https://pymupdf.readthedocs.io/)** | â‰¥1.23.0 | PDF Processing |
| **[FuzzyWuzzy](https://github.com/seatgeek/fuzzywuzzy)** | Latest | Fuzzy String Matching |

---

## ğŸ“Š API-Dokumentation

### Interaktive API-Dokumentation

Nach dem Start verfÃ¼gbar unter:
- **Swagger UI:** http://localhost:8000/docs (interaktive Tests)
- **ReDoc:** http://localhost:8000/redoc (strukturierte Dokumentation)
- **OpenAPI Schema:** http://localhost:8000/openapi.json (maschinenlesbar)

### Hauptendpunkte

| Kategorie | Endpunkt | Methoden | Beschreibung |
|-----------|----------|----------|--------------|
| **System** | `/health` | GET | Systemstatus prÃ¼fen |
| **Auth** | `/api/auth/login` | POST | Benutzer-Anmeldung |
| **Users** | `/api/users` | GET, POST | Benutzerverwaltung |
| **Documents** | `/api/documents` | GET, POST | Dokumentenverwaltung |
| **Equipment** | `/api/equipment` | GET, POST | Equipment-Management |
| **AI** | `/api/ai/analyze` | POST | KI-basierte Dokumentenanalyse |

### Beispiel: Authentifizierter API-Aufruf

```bash
# 1. Login und Token erhalten
curl -X POST "http://localhost:8000/api/auth/login" \
  -H "Content-Type: application/json" \
  -d '{"email": "qms.admin@company.com", "password": "admin123"}'

# 2. API-Aufruf mit Token
curl -X GET "http://localhost:8000/api/documents" \
  -H "Authorization: Bearer YOUR_TOKEN_HERE"
```

---

## ğŸ›¡ï¸ Compliance & Standards

### ISO 13485:2016 Compliance Matrix

| Kapitel | Anforderung | DocuMind-AI Feature | Status |
|---------|-------------|---------------------|--------|
| **4.2.3** | Dokumentenlenkung | âœ… Versionskontrolle, Freigabe-Workflow | Implementiert |
| **4.2.4** | Aufzeichnungen | âœ… Audit-Trail, Zeitstempel | Implementiert |
| **7.5.1** | Produktionssteuerung | âœ… SOP-Management, Equipment-Tracking | Implementiert |
| **8.2.1** | Kundenzufriedenheit | âœ… Post-Market Surveillance Gruppe | Implementiert |
| **8.5** | Verbesserung | âœ… CAPA-Dokumentation, Analytics | In Entwicklung |

### EU MDR 2017/745 Ready Features

- **âœ… Technische Dokumentation** (Artikel 10)
- **âœ… QualitÃ¤tsmanagementsystem** (Artikel 10)
- **âœ… Post-Market Surveillance** (Artikel 83-92)
- **ğŸ”„ EUDAMED Integration** (vorbereitet)

---

## ğŸš€ Installation

### Systemanforderungen

| Komponente | Minimum | Empfohlen |
|------------|---------|-----------|
| **Python** | 3.12.0 | 3.12.4 |
| **RAM** | 4 GB | 8 GB |
| **Festplatte** | 2 GB | 10 GB |
| **CPU** | 2 Cores | 4+ Cores |

### Automatisches Setup (Empfohlen)

```bash
# Repository klonen
git clone https://github.com/Rei1000/DocuMind-AI.git
cd DocuMind-AI

# Automatisches Setup und Start
./start-all.sh
```

### Manuelles Setup

```bash
# 1. Virtual Environment erstellen
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate   # Windows

# 2. Dependencies installieren
cd backend
pip install -r requirements.txt
cd ..

# 3. Backend starten
cd backend
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000

# 4. Frontend starten (neues Terminal)
cd frontend
streamlit run streamlit_app.py --server.port 8501 --server.headless true
```

### System stoppen

```bash
# Alle Services stoppen
./stop-all.sh
```

---

## ğŸ§ª Testing

### Test-Strategie

```bash
# Unit Tests ausfÃ¼hren
cd backend
pytest tests/unit/ -v

# Integration Tests ausfÃ¼hren
pytest tests/integration/ -v

# Coverage Report
pytest --cov=app --cov-report=html
```

---

## ğŸ”§ Entwicklung

### Entwicklungsumgebung einrichten

```bash
# Repository forken und klonen
git clone https://github.com/Rei1000/DocuMind-AI.git
cd DocuMind-AI

# Development Branch erstellen
git checkout -b feature/neue-funktionalitÃ¤t
```

### Code-QualitÃ¤t

```bash
# Code formatieren
black backend/app/
black frontend/

# Linting
ruff check backend/app/
ruff check frontend/
```

---

## ğŸ“š Erweiterte Dokumentation

| Dokument | Beschreibung | Status |
|----------|--------------|--------|
| [API-DOCUMENTATION-v3.5.0.md](API-DOCUMENTATION-v3.1.0.md) | **Aktuelle API-Dokumentation** Version 3.5.0 | âœ… VerfÃ¼gbar |
| [UPLOAD_METHODS_IMPLEMENTATION.md](UPLOAD_METHODS_IMPLEMENTATION.md) | Upload-Methoden Dokumentation | âœ… VerfÃ¼gbar |

---

## ğŸ¤ Beitragen

Wir freuen uns Ã¼ber BeitrÃ¤ge! Hier ist der Prozess:

### Contribution Guidelines

1. **Issues erstellen** fÃ¼r Bugs oder Feature-Requests
2. **Fork** das Repository
3. **Feature Branch** erstellen (`git checkout -b feature/AmazingFeature`)
4. **Commit** mit konventionellen Nachrichten (`feat:`, `fix:`, `docs:`)
5. **Push** zur Branch (`git push origin feature/AmazingFeature`)
6. **Pull Request** erstellen

### Code Standards

- **Python**: PEP 8 Konventionen mit Black Formatting
- **Type Hints**: VollstÃ¤ndige Type Annotations erforderlich
- **Docstrings**: Google-Style Docstrings fÃ¼r alle Ã¶ffentlichen Funktionen
- **Tests**: Minimum 80% Code Coverage erforderlich

---

## ğŸ“„ Lizenz

Dieses Projekt ist unter der [MIT License](LICENSE) lizenziert - siehe die LICENSE-Datei fÃ¼r Details.

### Lizenz-Zusammenfassung

- âœ… **Kommerzielle Nutzung** erlaubt
- âœ… **Modification** erlaubt
- âœ… **Distribution** erlaubt
- âœ… **Private Nutzung** erlaubt
- âš ï¸ **Keine Garantie** oder Haftung

---

## ğŸ”— Links & Ressourcen

- **ğŸ“§ Support:** [GitHub Issues](https://github.com/Rei1000/DocuMind-AI/issues)
- **ğŸ“– Wiki:** [GitHub Wiki](https://github.com/Rei1000/DocuMind-AI/wiki)
- **ğŸ’¡ Discussions:** [GitHub Discussions](https://github.com/Rei1000/DocuMind-AI/discussions)

---

<div align="center">

**Made with â¤ï¸ by the DocuMind-AI Team** | **Version 3.7.0** | **Last Updated: 2025-08-08**

</div>